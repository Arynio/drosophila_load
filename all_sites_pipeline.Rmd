---
title: "all_sites_version"
output: html_document
date: "2022-11-16"
---


In this script we'll perform an additional calling with all pools together (gen 0 - 140), and then we'll perform all subsequent analyses while keeping not only those sites which were segregating in Pb-000, but all (appropriate) sites.

#1. Generate BAMs with isolated autosomes:
##Gens0-40: samtools_isolate_chr_gen0-40.sh
```{R, engine='bash'}

CHR=$1

module load samtools/1.4.1
BAMLIST=$(ls -v *multirealigned.bam)
mkdir -p /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/4separate/multi_${CHR}
for bam in ${BAMLIST[@]}
  do
  echo "${bam}"
  samtools view -o /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/4separate/multi_${CHR}/${bam/.bam/_${CHR}.bam} ${bam} ${CHR}
  done

#Launch this as follows:
## cd /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/3processed/
## qsub -cwd -l h=compute-0-9 /share/rdata/ramon.pouso/POOLS/Scripts/samtools_isolate_chr_gen0-40.sh CHR #where CHR should be replaced with 2L, 2R, 3L, 3R or 4

```

##Gen140: samtools_isolate_chr_gen140.sh
```{R, engine='bash'}

CHR=$1

module load samtools/1.4.1
BAMLIST=$(ls -v *multirealigned.bam)
mkdir -p /share/rdata/ramon.pouso/POOLS/gen140/gen140/5processed/${CHR}_isolated
for bam in ${BAMLIST[@]}
  do
  echo "${bam}"
  samtools view -o /share/rdata/ramon.pouso/POOLS/gen140/gen140/5processed/${CHR}_isolated/${bam/.bam/_${CHR}.bam} ${bam} ${CHR}
  done

#Launch this as follows:
## cd /share/rdata/ramon.pouso/POOLS/gen140/gen140/5processed/
## qsub -cwd -l h=compute-0-9 /share/rdata/ramon.pouso/POOLS/Scripts/samtools_isolate_chr_gen140.sh CHR #where CHR should be replaced with 2L, 2R, 3L, 3R or 4

```

#2. Perform the CRISP calling:
##crisp_all_pools_chr_dani.sh
```{R, engine='bash'}

CHR=$1

module load crisp/1.0
cd /share/rdata/ramon.pouso/POOLS/gen140/gen140/6variants/not_masked/
BAMLIST=$(cat <(ls -v /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/4separate/multi_${CHR}/*${CHR}.bam) <(ls -v /share/rdata/ramon.pouso/POOLS/gen140/gen140/5processed/${CHR}_isolated/*${CHR}.bam)) #make sure that only the desired BAMs are in the folder
CRISP --ref /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta --VCF crisp_all_pools_gen0-140_${CHR}.vcf \
$(for bam in $BAMLIST; do echo --bam ${bam}" "; done) -p 160 > crisp_all_pools_gen0-140_${CHR}.log

#Launch this as follows:
## cd /share/rdata/ramon.pouso/POOLS/gen140/gen140/6variants/not_masked/
## qsub -cwd -l h=compute-0-9 /share/rdata/ramon.pouso/POOLS/Scripts/crisp_all_pools_chr_dani.sh CHR #where CHR should be replaced with 2L, 2R, 3L, 3R or 4

```

##crisp_all_pools_autosomes_dani.sh
```{R, engine='bash'}

#Launch CRISP with all pools from all generations, for autosomes:
module load crisp/1.0

cd /share/rdata/ramon.pouso/POOLS/gen140/gen140/6variants/not_masked/
BAMLIST=$(cat <(ls -v /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/4separate/multi_autosomic/*autosomic.bam) <(ls -v /share/rdata/ramon.pouso/POOLS/gen140/gen140/5processed/autosomic_isolated/*autosomic.bam)) #make sure that only the desired BAMs are in the folder
CRISP --ref /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta --VCF crisp_all_pools_gen0-140_autosomes.vcf \
$(for bam in $BAMLIST; do echo --bam ${bam}" "; done) -p 160 > crisp_all_pools_gen0-140_autosomes.log

#Launch this as follows:
## cd /share/rdata/ramon.pouso/POOLS/gen140/gen140/6variants/not_masked/
## qsub -cwd -l h=compute-0-9 /share/rdata/ramon.pouso/POOLS/Scripts/crisp_all_pools_autosomes_dani.sh 

```

##crisp_all_pools_Xchr_dani.sh
```{R, engine='bash'}

#Launch CRISP with all pools from all generations, for Xchr:
module load crisp/1.0

cd /share/rdata/ramon.pouso/POOLS/gen140/gen140/6variants/not_masked/
BAMLIST=$(cat <(ls -v /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/4separate/multi_x_chrom/*x.bam) <(ls -v /share/rdata/ramon.pouso/POOLS/gen140/gen140/5processed/x_isolated/*x.bam)) #make sure that only the desired BAMs are in the folder
CRISP --ref /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta --VCF crisp_all_pools_gen0-140_Xchr.vcf \
$(for bam in $BAMLIST; do echo --bam ${bam}" "; done) -p 80 > crisp_all_pools_gen0-140_Xchr.log

#Launch this as follows:
## cd /share/rdata/ramon.pouso/POOLS/gen140/gen140/6variants/not_masked/
## qsub -cwd -l h=compute-0-9 /share/rdata/ramon.pouso/POOLS/Scripts/crisp_all_pools_Xchr_dani.sh

```

#3. Combine and process the VCFs:
##Compress and index the VCFs, and combine them:
```{bash}

module load bcftools/1.9
module load gcc/7.2.0
module add gcc/7.2.0

#I moved everything to the following folder:
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants

#First, extract the common part of the sample names:
bcftools query -l crisp_all_pools_gen0-140_autosomes.vcf | rev | cut -d'_' -f2- | rev > sample_names.list

#Next, fix the sample names, and compress and index the VCFs:
##2L:
bcftools reheader --samples sample_names.list crisp_all_pools_gen0-140_2L.vcf | /DATA/APPS/freebayes/25.03.19/SeqLib/htslib/bgzip -c > crisp_all_pools_gen0-140_2L.vcf.gz
/DATA/APPS/freebayes/25.03.19/SeqLib/htslib/tabix -p vcf crisp_all_pools_gen0-140_2L.vcf.gz
##2R:
bcftools reheader --samples sample_names.list crisp_all_pools_gen0-140_2R.vcf | /DATA/APPS/freebayes/25.03.19/SeqLib/htslib/bgzip -c > crisp_all_pools_gen0-140_2R.vcf.gz
/DATA/APPS/freebayes/25.03.19/SeqLib/htslib/tabix -p vcf crisp_all_pools_gen0-140_2R.vcf.gz
##3L:
bcftools reheader --samples sample_names.list crisp_all_pools_gen0-140_3L.vcf | /DATA/APPS/freebayes/25.03.19/SeqLib/htslib/bgzip -c > crisp_all_pools_gen0-140_3L.vcf.gz
/DATA/APPS/freebayes/25.03.19/SeqLib/htslib/tabix -p vcf crisp_all_pools_gen0-140_3L.vcf.gz
##3R:
bcftools reheader --samples sample_names.list crisp_all_pools_gen0-140_3R.vcf | /DATA/APPS/freebayes/25.03.19/SeqLib/htslib/bgzip -c > crisp_all_pools_gen0-140_3R.vcf.gz
/DATA/APPS/freebayes/25.03.19/SeqLib/htslib/tabix -p vcf crisp_all_pools_gen0-140_3R.vcf.gz
##X:
bcftools reheader --samples sample_names.list crisp_all_pools_gen0-140_Xchr.vcf | /DATA/APPS/freebayes/25.03.19/SeqLib/htslib/bgzip -c > crisp_all_pools_gen0-140_Xchr.vcf.gz
/DATA/APPS/freebayes/25.03.19/SeqLib/htslib/tabix -p vcf crisp_all_pools_gen0-140_Xchr.vcf.gz

#Next, concatenate all files and keep only those sites within the previously selected orthologous regions.
bcftools concat crisp_all_pools_gen0-140_2L.vcf.gz crisp_all_pools_gen0-140_2R.vcf.gz crisp_all_pools_gen0-140_3L.vcf.gz crisp_all_pools_gen0-140_3R.vcf.gz crisp_all_pools_gen0-140_Xchr.vcf.gz | bedtools intersect -a stdin -b /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.bed -header > crisp_all_pools_gen0-140.all_sites.orthologs.confident.vcf

```

##Filter the combined VCF:
```{bash}

module load bcftools/1.9
module load gcc/7.2.0
module add gcc/7.2.0
module load vcftools/0.1.17

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants

#Keep only biallelic SNPs:
vcftools --vcf crisp_all_pools_gen0-140.all_sites.orthologs.confident.vcf --remove-indels --recode --recode-INFO-all --out crisp_all_pools_gen0-140.recode_snps.gen0-140_all_sites.orthologs.confident.vcf
grep '^#' crisp_all_pools_gen0-140.recode_snps.gen0-140_all_sites.orthologs.confident.vcf.recode.vcf > crisp_all_pools_gen0-140.recode_snps.gen0-140_all_sites.orthologs.confident.vcf
grep -v '^#' crisp_all_pools_gen0-140.recode_snps.gen0-140_all_sites.orthologs.confident.vcf.recode.vcf | awk '!($5 ~ /,/) { print }' >> crisp_all_pools_gen0-140.recode_snps.gen0-140_all_sites.orthologs.confident.vcf

#And edit some problematic spaces in the header (otherwise vcftools won't be able to deal with them later on):
sed -i 's/Description=" >/Description=">/g' crisp_all_pools_gen0-140.recode_snps.gen0-140_all_sites.orthologs.confident.vcf

#Mask variant files to remove repetitive regions:
qsub -cwd -l h=compute-0-9 /share/rdata/ramon.pouso/Scripts/vcf_mask_bed.sh crisp_all_pools_gen0-140.recode_snps.gen0-140_all_sites.orthologs.confident.vcf crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident /share/rdata/ramon.pouso/reference/indexed_reference/dmel-r6.14_mask.bed

mv crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.recode.vcf crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.vcf

#Next, apply the high depth and EMfail filters. On the one hand, we'll retrieve all sites with depth higher than the average + 3SD for each of the following pools: gen0, gen20, and gen30 of the base population. On the other, we'll retrieve sites with the flag EMfail. Finally we'll filter all of them out from the VCF.
rm crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filter_raw.bed
touch crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filter_raw.bed
##Extract sites with excess DP:
POP_LIST=$(bcftools query -l crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.vcf | grep "BT" | cut -d'_' -f1)
for POP in ${POP_LIST[@]}
  do
  VCF_COL=$((9 + $(bcftools query -l crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.vcf | grep -n "^$POP" | cut -d':' -f1)))
  ###Autosomic:
  AVG_AUTO=$(grep "mean coverageData" /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/qualitycontrol/"$POP"*_multirealigned_autosomic_stats/genome_results.txt | awk -F"= |X" '{printf ("%s\n",$2)}')
  SD_AUTO=$(grep "std coverageData" /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/qualitycontrol/"$POP"*_multirealigned_autosomic_stats/genome_results.txt | awk -F"= |X" '{printf ("%s\n",$2)}')
  FILTER_AUTO=$(echo $AVG_AUTO + 3*$SD_AUTO | bc)
  grep -v '#' crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.vcf | cut -f-2,$VCF_COL | awk -v filter="$FILTER_AUTO" -F"\t|:" '{if ($1 != "X" && $5 >= filter) printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' >> crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filter_raw.bed
  ###Xchr:
  AVG_X=$(grep "mean coverageData" /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/qualitycontrol/"$POP"*_multirealigned_x_stats/genome_results.txt | awk -F"= |X" '{printf ("%s\n",$2)}')
  SD_X=$(grep "std coverageData" /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/qualitycontrol/"$POP"*_multirealigned_x_stats/genome_results.txt | awk -F"= |X" '{printf ("%s\n",$2)}')
  FILTER_X=$(echo $AVG_X + 3*$SD_X | bc)
  grep -v '#' crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.vcf | cut -f-2,$VCF_COL | awk -v filter="$FILTER_X" -F"\t|:" '{if ($1 == "X" && $5 >= filter) printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' >> crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filter_raw.bed
  done
##Extract sites with EMfail flag:
grep -v '#' crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.vcf | grep "EMfail" | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' >> crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filter_raw.bed
##Sort sites and remove duplicates:
sort -k1,1 -k2,2n crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filter_raw.bed | uniq > crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filter_sorted.bed
##Finally, remove from the VCF all sites identified in the previous steps:
bedtools subtract -a crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.vcf -b crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filter_sorted.bed -header > crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.vcf

```

#4. Use est-sfs to infer ancestral and derived alleles.
##README.
```{bash}

#The outgroup BAMs and genome fastas are already prepared (see chunks 1 and 2 in the polarisation.Rmd script).

```

##Prepare SNP counts dataset:
```{R, engine='bash'}

#est-sfs will be fed the counts of Pb-000, Pb-020, and Pb-030. So first we need to extract those counts:
mkdir -p /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline/
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/

POP_LIST=$(bcftools query -l crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.vcf | grep "BT" | cut -d'_' -f1)
for POP in ${POP_LIST[@]}
  do
  VCF_COL=$((9 + $(bcftools query -l crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.vcf | grep -n "^$POP" | cut -d':' -f1)))
  grep -v '#' crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.vcf | cut -f1-2,4-5,$VCF_COL | awk -F"\t|:|," '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$8+$10+$12,$9+$11+$13)}' > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline/"$POP"_allele_counts.txt
  done

#And then combine the counts:
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline/

bedtools intersect -a <(bedtools intersect -a LBT0_allele_counts.txt -b BT20_allele_counts.txt -wa -wb) -b BT30_allele_counts.txt -wa -wb | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6+$13+$20,$7+$14+$21)}' > gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.bed

```

##Extract the outgroup state:
###extract_state.sh
```{R, engine='bash'}

module load gcc/7.2.0
module add gcc/7.2.0
bedtools getfasta -fi $1 -bed $2 -tab -fo $3

awk -F"\t|:|-" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' $3 > $4

# $1 is the input fasta, $2 the bed with the coordinates of interest, $3 the output file in txt format, and $4 the output file transformed back to bed format.

```

###Execution:
####For SNPs:
```{R, engine='bash'}

#The outgroup fasta with the structure of the melanogaster reference has been obtained in the polarisation.Rmd script using samtools mpileup and pu2fa.

#For simulans:
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline

/share/rdata/ramon.pouso/outgroups/Scripts/extract_state.sh /share/rdata/ramon.pouso/outgroups/simulans/3processed/bwa_simulans_iso_rmdup_mq30_rg_multirealigned_major.fasta gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.bed ./gen0-140_all_sites.orthologs.confident.DP_EM_filtered.simulans_state.txt ./gen0-140_all_sites.orthologs.confident.DP_EM_filtered.simulans_state.bed

#Check:
awk '$4=="N"' gen0-140_all_sites.orthologs.confident.DP_EM_filtered.simulans_state.bed | wc -l #125914 Ns out of 1293698 sites.

#For yakuba:
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline

/share/rdata/ramon.pouso/outgroups/Scripts/extract_state.sh /share/rdata/ramon.pouso/outgroups/yakuba/3processed/bwa_yakuba_iso_rmdup_mq30_rg_multirealigned_major.fasta gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.bed ./gen0-140_all_sites.orthologs.confident.DP_EM_filtered.yakuba_state.txt ./gen0-140_all_sites.orthologs.confident.DP_EM_filtered.yakuba_state.bed

#Check:
awk '$4=="N"' gen0-140_all_sites.orthologs.confident.DP_EM_filtered.yakuba_state.bed | wc -l #415500 Ns out of 1293698 sites.

```

####For monomorphic positions (orthologs):
```{R, engine='bash'}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline/
module load gcc/7.2.0
module add gcc/7.2.0

#First generate a bed file for those positions that are excluded from the final dataset (i.e. monomorphic positions).
bedtools subtract -a /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.bed -b gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.bed > gen0-140_all_sites.orthologs.confident.DP_EM_filtered.rest_of_genome.bed

#For melanogaster:
bedtools getfasta -fi /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta -bed gen0-140_all_sites.orthologs.confident.DP_EM_filtered.rest_of_genome.bed -tab | cut -f2 | fold -w1 > gen0-140_all_sites.orthologs.confident.DP_EM_filtered.rest_of_genome.melanogaster_state.txt

#For simulans:
bedtools getfasta -fi /share/rdata/ramon.pouso/outgroups/simulans/3processed/bwa_simulans_iso_rmdup_mq30_rg_multirealigned_major.fasta -bed gen0-140_all_sites.orthologs.confident.DP_EM_filtered.rest_of_genome.bed -tab | cut -f2 | fold -w1 > gen0-140_all_sites.orthologs.confident.DP_EM_filtered.rest_of_genome.simulans_state.txt

awk '$1=="N"' gen0-140_all_sites.orthologs.confident.DP_EM_filtered.rest_of_genome.simulans_state.txt | wc -l #10564167

#For yakuba:
bedtools getfasta -fi /share/rdata/ramon.pouso/outgroups/yakuba/3processed/bwa_yakuba_iso_rmdup_mq30_rg_multirealigned_major.fasta -bed gen0-140_all_sites.orthologs.confident.DP_EM_filtered.rest_of_genome.bed -tab | cut -f2 | fold -w1 > gen0-140_all_sites.orthologs.confident.DP_EM_filtered.rest_of_genome.yakuba_state.txt

awk '$1=="N"' gen0-140_all_sites.orthologs.confident.DP_EM_filtered.rest_of_genome.yakuba_state.txt | wc -l #22130841

```

##Build the est-sfs input:
###Retrieve sequences from orthologous regions:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline
module load gcc/7.2.0
module add gcc/7.2.0

#Generate bed file with all orthologous regions and the respective reference state:
##For melanogaster:
bedtools getfasta -fi /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta -bed /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.bed -tab | awk -F"\t|:|-" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > dmel_dsim_dyak_orthologs.db_coord_sorted.melanogaster_state.intervals.bed

#Check: total number of sites in the orthologous regions:
#awk '{print $3-$2}' dmel_dsim_dyak_orthologs.db_coord_sorted.melanogaster_state.intervals.bed | paste -sd+ | bc #85919923

##For simulans:
bedtools getfasta -fi /share/rdata/ramon.pouso/outgroups/simulans/3processed/bwa_simulans_iso_rmdup_mq30_rg_multirealigned_major.fasta -bed /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.bed -tab | awk -F"\t|:|-" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > dmel_dsim_dyak_orthologs.db_coord_sorted.simulans_state.intervals.bed

##For yakuba:
bedtools getfasta -fi /share/rdata/ramon.pouso/outgroups/yakuba/3processed/bwa_yakuba_iso_rmdup_mq30_rg_multirealigned_major.fasta -bed /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.bed -tab | awk -F"\t|:|-" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > dmel_dsim_dyak_orthologs.db_coord_sorted.yakuba_state.intervals.bed

#Check: total number of sites in the intervals: 85919923 (correct).
#Check: total number of positions in chr2L in these intervals is 14942364

#Then split the intervals in bins of 1 bp:
SPECIES=(yakuba) #melanogaster #simulans #yakuba
rm dmel_dsim_dyak_orthologs.db_coord_sorted.${SPECIES}_state.positions.bed
while read CHROMOSOME START END SEQUENCE;
  do
  START_COL=$(seq $START $(($END-1)))
  END_COL=$(seq $(($START+1)) $END)
  N_ROW=$(seq $START $(($END-1)) | wc -l)
  CHR_COL=$(yes $CHROMOSOME | head -n$N_ROW)
  SEQ_COL=$(echo $SEQUENCE | fold -w1)
  paste <(printf %s "$CHR_COL") <(printf %s "$START_COL") <(printf %s "$END_COL") <(printf %s "$SEQ_COL") >> dmel_dsim_dyak_orthologs.db_coord_sorted.${SPECIES}_state.positions.bed
  done < dmel_dsim_dyak_orthologs.db_coord_sorted.${SPECIES}_state.intervals.bed
  
#Check: total number of lines (positions) is 85919923 (correct), and in chr2L is 14942364 (correct).

#Check: 10690081 Ns (12.4%) in simulans, and 22546341 Ns (26.2%) in yakuba out of 85919923 orthologous positions. 

```

###Format SNPs:
####Format data from the focal species:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline
#First extrapolate counts to a total number of copies of 180 per site, so that est-sfs can run (all sites are required to have the same number of copies, and such number cannot be above 199). Error sites where the count is 0 for both REF and ALT alleles will be reinterpreted as monomorphic for the reference. At the same time, sites with a minor allele with very low frequencies would be reinterpreted as monomorphic sites due to rounding effects while extrapolating. Thus, an eighth column is created to classify variable sites (1) and monomorphic sites (0; note that all sites in this dataset come from the global VCF and thus are variable at the level of the entire dataset; these are only monomorphic for the subset comprised of Pb-000, Pb-020 and Pb-030). After extrapolation, variable sites ($8==1) which now seem to be monomorphic ($6==0 or $7==0) due to a rounding effect will be converted from 180:0 (or 0:180) to 179:1 (or 1:179).
awk -F"\t" '{if ($6==0 && $7==0) printf ("%s\t%s\t%s\t%s\t%s\t%.0f\t%.0f\t%s\n", $1,$2,$3,$4,$5,180,0,0); else if ($6==0 || $7==0) printf ("%s\t%s\t%s\t%s\t%s\t%.0f\t%.0f\t%s\n", $1,$2,$3,$4,$5,180*$6/($6+$7),180*$7/($6+$7),0); else printf ("%s\t%s\t%s\t%s\t%s\t%.0f\t%.0f\t%s\n", $1,$2,$3,$4,$5,180*$6/($6+$7),180*$7/($6+$7),1)}' gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.bed | awk -F"\t" '{if ($6==0 && $8==1) printf ("%s\t%s\t%s\t%s\t%s\t%.0f\t%.0f\n", $1,$2,$3,$4,$5,1,179); else if ($7==0 && $8==1) printf ("%s\t%s\t%s\t%s\t%s\t%.0f\t%.0f\n", $1,$2,$3,$4,$5,179,1); else printf ("%s\t%s\t%s\t%s\t%s\t%.0f\t%.0f\n", $1,$2,$3,$4,$5,$6,$7)}' > gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.bed

#Then format counts:
awk '{                                       
if ($4=="A" && $5=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,$6,$7,0,0);
else if ($4=="A" && $5=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,$6,0,$7,0);
else if ($4=="A" && $5=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,$6,0,0,$7);
else if ($4=="C" && $5=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,$7,$6,0,0);
else if ($4=="C" && $5=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,$6,$7,0);
else if ($4=="C" && $5=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,$6,0,$7);
else if ($4=="G" && $5=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,$7,0,$6,0);
else if ($4=="G" && $5=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,$7,$6,0);
else if ($4=="G" && $5=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,$6,$7);
else if ($4=="T" && $5=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,$7,0,0,$6);
else if ($4=="T" && $5=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,$7,0,$6);
else if ($4=="T" && $5=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,$7,$6);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,0,0);
}' gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.bed > gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.focalsp_counts.bed

```

####Format data from the outgroup species:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline
#Next, format the outgroup species data:
##Simulans:
awk '{if ($4=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,1,0,0,0);
else if ($4=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,1,0,0);
else if ($4=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,1,0);
else if ($4=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,0,1);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,0,0);
}' gen0-140_all_sites.orthologs.confident.DP_EM_filtered.simulans_state.bed > gen0-140_all_sites.orthologs.confident.DP_EM_filtered.simulans_state.simulans_counts.bed

##Yakuba:
awk '{if ($4=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,1,0,0,0);
else if ($4=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,1,0,0);
else if ($4=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,1,0);
else if ($4=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,0,1);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,0,0);
}' gen0-140_all_sites.orthologs.confident.DP_EM_filtered.yakuba_state.bed > gen0-140_all_sites.orthologs.confident.DP_EM_filtered.yakuba_state.yakuba_counts.bed

```

####Join the focal species and the outgroup data:
```{bash}

#The bed files for the final SNP set were generated in the whole-genome section above.
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline
module load gcc/7.2.0
module add gcc/7.2.0

#Join these files:
bedtools intersect -a gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.focalsp_counts.bed -b gen0-140_all_sites.orthologs.confident.DP_EM_filtered.simulans_state.simulans_counts.bed -wb | bedtools intersect -a stdin -b gen0-140_all_sites.orthologs.confident.DP_EM_filtered.yakuba_state.yakuba_counts.bed -wb | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$12)}' > gen0-140_all_sites.orthologs.confident.DP_EM_filtered.joined_counts.bed

#Check: it has 1293698 lines (positions), same as all other counts file, so it's correct.

grep $'\t'"0,0,0,0" gen0-140_all_sites.orthologs.confident.DP_EM_filtered.joined_counts.bed | wc -l #it has 437631 (33.83%) sites with no info in at least one outgroup, of which 125914 (9.73%) have no info in simulans, and 415500 (32.12%) have no info in yakuba. 103783 have no info in neither outgroup, and 856067 (66.17%) have all info. 333848 (25.81%) are missing info in one outgroup but not the other (these are the ones that will be kept for the est-sfs analysis, together with those with no missing info, which comprise 91.98% of all sites in the file).

```

###Format monomorphic:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline
module load gcc/7.2.0
module add gcc/7.2.0

##Melanogaster:
bedtools subtract -a dmel_dsim_dyak_orthologs.db_coord_sorted.melanogaster_state.positions.bed -b gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.focalsp_counts.bed | awk '{if ($4=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,180,0,0,0);
else if ($4=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,180,0,0);
else if ($4=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,180,0);
else if ($4=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,0,180);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,0,0);
}' > gen0-140_all_sites.rest_of_genome.orthologs.confident.DP_EM_filtered.melanogaster_state.melanogaster_counts.bed

##Simulans and yakuba:
SPECIES=(yakuba) #simulans #yakuba
bedtools subtract -a dmel_dsim_dyak_orthologs.db_coord_sorted.${SPECIES}_state.positions.bed -b gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_100.focalsp_counts.bed | awk '{if ($4=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,1,0,0,0);
else if ($4=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,1,0,0);
else if ($4=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,1,0);
else if ($4=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,0,1);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\n", $1,$2,$3,0,0,0,0);
}' > gen0-140_all_sites.rest_of_genome.orthologs.confident.DP_EM_filtered.${SPECIES}_state.${SPECIES}_counts.bed

#Check: they all have 84626225 lines (positions), which is the correct difference between 85919923 (all orthologous regions) and 1293698 (selected orthologous SNPs).

#Join these files:
##Option A: bedtools (safer but very slow, and might throw errors).
cd /share/rdata/ramon.pouso/polarisation/estsfs/input_pipeline/orthologs
bedtools intersect -a final_snp_set.rest_of_genome.orthologs.melanogaster_state.melanogaster_counts.bed -b final_snp_set.rest_of_genome.orthologs.simulans_state.simulans_counts.bed -wb | bedtools intersect -a stdin -b final_snp_set.rest_of_genome.orthologs.yakuba_state.yakuba_counts.bed -wb | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$12)}' > final_snp_set.rest_of_genome.orthologs.joined_counts.bed

##Option B: paste (make sure coordinates are maintained in the same row).
paste <(cat gen0-140_all_sites.rest_of_genome.orthologs.confident.DP_EM_filtered.melanogaster_state.melanogaster_counts.bed) <(cat gen0-140_all_sites.rest_of_genome.orthologs.confident.DP_EM_filtered.simulans_state.simulans_counts.bed) <(cat gen0-140_all_sites.rest_of_genome.orthologs.confident.DP_EM_filtered.yakuba_state.yakuba_counts.bed) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$12)}' > gen0-140_all_sites.rest_of_genome.orthologs.confident.DP_EM_filtered.joined_counts.bed

#Check: it has 84626225 lines (positions), so it's correct. Of these, 61253911 (72.38%) have all information, 23372314 (27.62%) are missing info in at least one outgroup. 10564167 (12.48%) are missing info in simulans, and 22130841 (26.15%) are missing info in yakuba. 9322694 (11.02%) are missing info in both outgroups. 14049620 (16.6%) are missing info in one outgroup but not the other (these are the ones that will be kept for the est-sfs analysis, together with those with no missing info, which comprise 88.98% of all sites in the file).

```

###Build the input file:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline
module load gcc/7.2.0
module add gcc/7.2.0

#Combine the SNPs and the monomorphic sites, and remove SNPs with no outgroup info at all, as well as monomorphic sites with missing info from both outgroups:
##First make this check:
cat gen0-140_all_sites.orthologs.confident.DP_EM_filtered.joined_counts.bed gen0-140_all_sites.rest_of_genome.orthologs.confident.DP_EM_filtered.joined_counts.bed | sort -k1,1 -k2,2n | wc -l 
###Check: it has 85919923 lines (positions), which is the sum of 1293698 (SNPs) and 84626225 (monomorphic), so it's correct.

##Then, prepare the file:
cat <(awk '!($5=="0,0,0,0" && $6=="0,0,0,0") {print $0}' gen0-140_all_sites.orthologs.confident.DP_EM_filtered.joined_counts.bed) <(grep -v $'\t'"0,0,0,0" gen0-140_all_sites.rest_of_genome.orthologs.confident.DP_EM_filtered.joined_counts.bed) | sort -k1,1 -k2,2n > gen0-140_all_sites_plus_rest_of_genome.orthologs.confident.DP_EM_filtered.joined_counts.bed
###Check: it has 62443826 lines (positions).
cat <(awk '$5=="0,0,0,0" && $6=="0,0,0,0" {print $0}' gen0-140_all_sites.orthologs.confident.DP_EM_filtered.joined_counts.bed) <(grep $'\t'"0,0,0,0" gen0-140_all_sites.rest_of_genome.orthologs.confident.DP_EM_filtered.joined_counts.bed) | wc -l
###Check: it has 23476097 lines (positions), which together with the complementary file (62443826) add to 85919923 (correct!). It keeps 333848 SNP sites with information missing from one outgroup (but not the other).

#Generate the est-sfs input (one per chromosome):
CHROMOSOMES=$(cut -f1 gen0-140_all_sites_plus_rest_of_genome.orthologs.confident.DP_EM_filtered.joined_counts.bed | uniq)
for chr in ${CHROMOSOMES[@]}
  do
  echo "$chr"
  awk -v chr=$chr '($1==chr) {printf ("%s\t%s\t%s\n", $4,$5,$6)}' gen0-140_all_sites_plus_rest_of_genome.orthologs.confident.DP_EM_filtered.joined_counts.bed > gen0-140_all_sites_plus_rest_of_genome.orthologs.confident.DP_EM_filtered.joined_counts.chr${chr}.est_sfs_input.txt
  done

#And copy the files to CESGA, where est-sfs will be run:
scp -p gen0-140_all_sites_plus_rest_of_genome.orthologs.confident.DP_EM_filtered.joined_counts.chr*est_sfs_input.txt uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/all_sites_pipeline/estsfs_analysis/

```

##Polarise with est-sfs:
###Chromosome-level:
####est-sfs_chr_array.all_sites.sh:
```{bash}

#!/bin/bash
#SBATCH -p thinnodes
#SBATCH -J estsfs
#SBATCH -o estsfs_%A_%a.out
#SBATCH -t 01:00:00              # Run time (hh:mm:ss)
#SBATCH -c 6
#SBATCH --mem-per-cpu=10GB
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com

# Load any necessary modules
# Loading modules in the script ensures a consistent environment.
module load cesga/2020 est-sfs/2.03
#ulimit -s unlimited

# Retrieve files:
FILENAME=`sed -n ${SLURM_ARRAY_TASK_ID}p </mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/all_sites_pipeline/estsfs_analysis/filelist.txt`
echo $FILENAME
#echo "this is chunk number" ${SLURM_ARRAY_TASK_ID} > /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/all_sites_pipeline/estsfs_analysis/${FILENAME/.txt/.out}
SFS_OUTPUT=$(echo "$FILENAME" | sed "s/est_sfs_input./rate6.uSFS./")
PVAL_OUTPUT=$(echo "$FILENAME" | sed "s/est_sfs_input./rate6.pval./")

# Run the task:
est-sfs /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/est-sfs-release-2.03/config-rate6.txt /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/all_sites_pipeline/estsfs_analysis/$FILENAME /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/est-sfs-release-2.03/seedfile.txt /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/all_sites_pipeline/estsfs_analysis/$SFS_OUTPUT /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/all_sites_pipeline/estsfs_analysis/$PVAL_OUTPUT

#Store this file as: /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/est-sfs-release-2.03/est-sfs_chr_array.all_sites.sh

```

####Send an array-job for all chromosomes:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/all_sites_pipeline/estsfs_analysis

ls gen0-140_all_sites_plus_rest_of_genome.orthologs.confident.DP_EM_filtered.joined_counts.chr*.est_sfs_input.txt > filelist.txt
sbatch --array=1-6 /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/est-sfs-release-2.03/est-sfs_chr_array.all_sites.sh

```

##Extract the ancestral information:
###Combine relevant information:
```{bash}

#First download the files from CESGA, where est-sfs was run:
mkdir -p /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline
scp -p uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/all_sites_pipeline/estsfs_analysis/gen0-140_all_sites_plus_rest_of_genome.orthologs.confident.DP_EM_filtered.joined_counts.chr*rate6.*.txt ./

#Then define the configuration mode, and the common part of the filenames:
module load gcc/7.2.0
module add gcc/7.2.0
CONFIG=(rate6) #rate6 #kimura
NAME="gen0-140_all_sites_plus_rest_of_genome.orthologs.confident.DP_EM_filtered"
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline

#Combine all output files into a single one:
cat ${NAME}.joined_counts.chr*.${CONFIG}.pval.txt > ${NAME}.joined_counts.${CONFIG}.pval.txt #I checked manually that files were concatenated in the proper order.

#Recover the coordinates:
paste <(awk '{printf ("%s\t%s\t%s\n", $1,$2,$3)}' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline/${NAME}.joined_counts.bed) <(awk '$1!=0 {printf ("%s\n", $3)}' ${NAME}.joined_counts.${CONFIG}.pval.txt) > ${NAME}.joined_counts.${CONFIG}.pval.bed #62443826 lines, same as the input

#Reorder alleles (major in col 5, minor in col 6; if equal, A>C>G>T is how est-sfs prioritizes the alleles), only for sites with variants:
bedtools intersect -a ${NAME}.joined_counts.${CONFIG}.pval.bed -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline/${NAME/_plus_rest_of_genome/}.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.bed -wb | awk '{if ($10>$11) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$9); 
else if ($10<$11) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$9,$8);
else if ($10==$11 && $8=="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$9);
else if ($10==$11 && $9=="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$9,$8);
else if ($10==$11 && $8=="C" && $9!="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$9);
else if ($10==$11 && $9=="C" && $8!="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$9,$8);
else if ($10==$11 && $8=="G" && $9=="T") printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$9);
else if ($10==$11 && $9=="G" && $8=="T") printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$9,$8);
}' > ${NAME/_plus_rest_of_genome/}.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived.${CONFIG}.pval.bed #it has 1189915 lines, which is the correct result (the melanogaster input had 1293698 lines, but 103783 were removed due to lack of info for both outgroups).

#Complete information:
##First retrieve the melano REF alleles:
bedtools intersect -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.vcf -b ${NAME/_plus_rest_of_genome/}.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived.${CONFIG}.pval.bed | awk '{printf ("%s\t%s\t%s\t%s\n", $1,$2-1,$2,$4)}' > ${NAME/_plus_rest_of_genome/}.reference_allele.bed
##Then combine all relevant info:
bedtools intersect -a ${NAME/_plus_rest_of_genome/}.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived.${CONFIG}.pval.bed -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/input_pipeline/${NAME/_plus_rest_of_genome/}.joined_counts.bed -wb | bedtools intersect -a stdin -b ${NAME/_plus_rest_of_genome/}.reference_allele.bed -wb | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$10,$11,$12,$16)}' > ${NAME/_plus_rest_of_genome/}.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.${CONFIG}.pval.bed

#Check behaviour of sites whose polarisation changed between datasets due to rounding effects:
##New dataset (extrapolated to 180) vs. original dataset:
bedtools intersect -a <(awk -F"\t" '{if ($4>=0.90000) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$5,$10,$4); else if ($4<0.10000) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$6,$10,$4)}' gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.rate6.pval.bed) -b <(awk -F"\t" '{if ($4>=0.90000) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$5,$10,$4); else if ($4<0.10000) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$6,$10,$4)}' /share/rdata/ramon.pouso/polarisation/estsfs/output/final_snp_set.orthologs.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_100.ancestral_vs_derived_complete.${CONFIG}.pval.bed) -wa -wb | awk '$4!=$10 {print $0}' | less -S #Out of those sites present in both datasets, there are 1858 sites which changed polarisation between the original dataset and the current one. In addition, there's 165796 more sites in the new dataset than in the old one. There's 1015945 sites common to both datasets. There's 173970 present in the new one but missing in the old one. And there's 8174 present in the old one but not in the new one (they were dropped due to filters).

#Extract pval and AF information for each site in order to investigate the patterns:
bedtools intersect -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.vcf -b ${NAME/_plus_rest_of_genome/}.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.${CONFIG}.pval.bed | awk -F"\t|;" '{printf ("%s\t%s\t%s\t%s\n", $1,$2-1,$2,$15)}' | awk -F"\t|=" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$5)}' > af_distribution.txt

bedtools intersect -a ${NAME/_plus_rest_of_genome/}.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.${CONFIG}.pval.bed -b af_distribution.txt -wb | awk '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$14)}' > pval_af_distribution.txt

```

###Extract the ancestral alleles:
```{bash}

module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline
CONFIG=(rate6) #rate6 #kimura
NAME="gen0-140_all_sites_plus_rest_of_genome.orthologs.confident.DP_EM_filtered"

#Extract the ancestral alleles as inferred by est-sfs (column 4) and the melano reference alleles (column 5) for sites where the pval is >0.9 or <0.1.
awk -F"\t" '{if ($4>=0.90000) printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$5,$10);
else if ($4<0.10000) printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$6,$10)}' ${NAME/_plus_rest_of_genome/}.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.${CONFIG}.pval.bed > ${NAME/_plus_rest_of_genome/}.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.confident.${CONFIG}.pval.bed #1116933 (72982 ambiguous sites have been dropped, and before that 103783 sites with missing info in both outgroups were also removed. Numbers are correct considering that the DP_EM_filtered VCF has 1293698 sites).

#Check final polarisation of confident sites vs. previous datasets:
##Sites common to both datasets which maintain the ancestral state inferrence:
bedtools intersect -a gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_100.ancestral_vs_derived_complete.confident.rate6.pval.bed -b /share/rdata/ramon.pouso/polarisation/estsfs/output/final_snp_set.orthologs.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_100.ancestral_vs_derived_complete.confident.rate6.pval.bed -wa -wb | awk '$4==$9' | wc -l #948021
##Sites common to both datasets which have a different ancestral state inferrence:
bedtools intersect -a gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_100.ancestral_vs_derived_complete.confident.rate6.pval.bed -b /share/rdata/ramon.pouso/polarisation/estsfs/output/final_snp_set.orthologs.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_100.ancestral_vs_derived_complete.confident.rate6.pval.bed -wa -wb | awk '$4!=$9' | wc -l #2020
##Sites which are included in the new dataset, but not in the original one:
bedtools subtract -a gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_100.ancestral_vs_derived_complete.confident.rate6.pval.bed -b /share/rdata/ramon.pouso/polarisation/estsfs/output/final_snp_set.orthologs.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_100.ancestral_vs_derived_complete.confident.rate6.pval.bed -wa | wc -l #168046
##Sites which are missing from the new dataset, but were in the original one:
bedtools subtract -a /share/rdata/ramon.pouso/polarisation/estsfs/output/final_snp_set.orthologs.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_100.ancestral_vs_derived_complete.confident.rate6.pval.bed -b gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_100.ancestral_vs_derived_complete.confident.rate6.pval.bed -wa | wc -l #9468

#Filter only those sites where the ancestral allele is different from the melano reference:
awk '$4!=$5 {print $0}' ${NAME/_plus_rest_of_genome/}.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.confident.${CONFIG}.pval.bed > ${NAME/_plus_rest_of_genome/}.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.confident_inconsistent.${CONFIG}.pval.bed #306215 sites will need to be altered in the VCF.

```

###Generate ancestral state fasta reference.
####Transform reference fasta to tab format:
```{bash}

cd /share/rdata/ramon.pouso/reference/indexed_reference/

#Transform fasta to tab (not really tab separated, only the last column) format to ease the editing.
/share/rdata/ramon.pouso/seqkit fx2tab dmel-all-chromosome-r6.14.fasta > dmel-all-chromosome-r6.14.tab

```

####ancestral_fasta.sh
```{bash}

#Run it as follows: qsub -cwd -l h=compute-0-9 -t 1-5 /share/rdata/ramon.pouso/reference/indexed_reference/ancestral_fasta.sh

cd /share/rdata/ramon.pouso/reference/indexed_reference/

#Retrieve scaffold corresponding to the current array level:
CHROMOSOME=`sed -n ${SGE_TASK_ID}p <(cut -f1 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline/gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.confident_inconsistent.rate6.pval.bed | sort | uniq)`

#Generate input files:
##Bed with to-change alleles for the scaffold:
echo "generating input file for chromosome" $CHROMOSOME
awk -v chr=$CHROMOSOME '$1==chr' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline/gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.confident_inconsistent.rate6.pval.bed > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline/gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.confident_inconsistent.rate6.pval.chr${CHROMOSOME}.bed
##Tab-reference for the scaffold:
grep -w "ID=$CHROMOSOME;" dmel-all-chromosome-r6.14.tab > ${CHROMOSOME}.dmel-all-chromosome-r6.14.tab

#Next, edit the melano fasta in order to generate the ancestral fasta:
##First loop over the inconsistent variants (those for which the polarisation is the reverse), grep the scaffold which they belong to, edit the base, and use that file as the input for the next variant in the same scaffold:
COUNTER=0
TOTAL=$(wc -l < /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline/gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.confident_inconsistent.rate6.pval.chr${CHROMOSOME}.bed)
echo "editing fasta for chromosome" $CHROMOSOME
while read -r SCAFFOLD START STOP ANCESTRAL REFERENCE; do
  #Print the sequence replacing only the current variant, and replace the previous input with this output:
  awk -v stop=$STOP -v ancestral=$ANCESTRAL -F"\t" '{printf ("%s\t%s%s%s\n", $1,substr($2,1,stop-1),ancestral,substr($2,stop+1))}' $SCAFFOLD.dmel-all-chromosome-r6.14.tab > $SCAFFOLD.tmp && mv $SCAFFOLD.tmp $SCAFFOLD.dmel-all-chromosome-r6.14.tab
  ((COUNTER++))
  if [ $(( $COUNTER % 1000 )) == 0 ]
    then
    echo "processed $COUNTER sites out of $TOTAL"
  fi
 done < /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline/gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.confident_inconsistent.rate6.pval.chr${CHROMOSOME}.bed
touch chr${CHROMOSOME}.finished
echo "finished processing chromosome" $CHROMOSOME

```

####Combine all scaffolds back into the ancestral fasta:
```{bash}

cd /share/rdata/ramon.pouso/reference/indexed_reference/
#Check if the editing of the last scaffold is now complete, and if so, append all scaffolds to generate the new ancestral file (containing only the modified scaffolds).
if [ $(ls chr*.finished | wc -l) == 5 ]
  then
  cat *.dmel-all-chromosome-r6.14.tab > ancestral_dmel-all-chromosome-r6.14.tab
  else
  echo "keep waiting"
fi
#rm chr*.finished
#rm *.dmel-all-chromosome-r6.14.tab

#Next, include all the other scaffolds, i.e. those that remained unchanged:
grep -v -w -f <(cut -f1 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline/gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.confident_inconsistent.rate6.pval.bed | sort | uniq | awk '{print "ID="$0";"}') dmel-all-chromosome-r6.14.tab | awk -F"\t" '{printf ("%s\t%s\n", $1,$2)}' >> ancestral_dmel-all-chromosome-r6.14.tab #Check that it has 1870 lines, same as dmel-all-chromosome-r6.14.tab

#Next convert the file back to fasta format:
#sort -k1,1 ANCESTRAL.23.tab | awk '{printf ("%s  %s %s\t%s\n", $1,$2,$3,$4)}' > ANCESTRAL_sorted.23.tab
/share/rdata/ramon.pouso/seqkit tab2fx <(awk -F"\t| " '{printf ("%s\t%s\n",$1,$10)}' ancestral_dmel-all-chromosome-r6.14.tab) > ancestral_dmel-all-chromosome-r6.14.fa

#Finally, obtain the (bgzip) compressed version of the fasta, and its index file:
module load samtools/1.4.1 
/DATA/APPS/freebayes/25.03.19/SeqLib/htslib/bgzip -c ancestral_dmel-all-chromosome-r6.14.fa > ancestral_dmel-all-chromosome-r6.14.fa.gz
samtools faidx ancestral_dmel-all-chromosome-r6.14.fa.gz


#Chech if it worked fine. Cols 3 and 4 should be identical, and different from cols 5 and 6, which should also be the same:
rm kaka.borrar
while read -r SCAFFOLD START STOP ANCESTRAL REFERENCE; do
  OLD=$(grep "ID=$SCAFFOLD;" dmel-all-chromosome-r6.14.tab | awk -F"\t" '{printf ("%s\n", $2)}' | cut -c$STOP)
  NEW=$(grep "$SCAFFOLD" ancestral_dmel-all-chromosome-r6.14.tab | awk -F"\t" '{printf ("%s\n", $2)}' | cut -c$STOP)
  echo -e "$SCAFFOLD\t$STOP\t$REFERENCE\t$OLD\t$ANCESTRAL\t$NEW" >> kaka.borrar
 done < /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline/gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.confident_inconsistent.rate6.pval.bed
#Seems like all key positions have changed correctly, while random ones are still the same.

```

###Index the ancestral state fasta reference.
```{bash}

cd /share/rdata/ramon.pouso/reference/indexed_reference/
module load samtools/1.4.1

samtools faidx ancestral_dmel-all-chromosome-r6.14.fa
samtools dict ancestral_dmel-all-chromosome-r6.14.fa -o ancestral_dmel-all-chromosome-r6.14.dict

```

#5. Polarise the VCFs.
##Filter polarisable sites and fill the ancestral allele data:
```{bash}

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/

#Keep only SNPs that were successfully filtered (this was done in previous steps), and for which the ancestral inference is available and highly confident.
bedtools intersect -a crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.vcf -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/est-sfs/output_pipeline/gen0-140_all_sites.orthologs.confident.DP_EM_filtered.sum_gen0_gen20_gen30_allele_counts.extrapolated_to_180.ancestral_vs_derived_complete.confident.rate6.pval.bed -header > crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.vcf

#Launch fill-aa.sh (locally, not with qsub due to problems with PERL5LIB) in order to fill the VCF with the ancestral alleles:
/share/rdata/ramon.pouso/Scripts/fill-aa.sh crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.vcf

```

##fill-aa.sh
```{bash}

#Code to annotate the AA (ancestral alleles) subfield from the INFO field in the VCF. Save it as: /share/rdata/ramon.pouso/Scripts/fill-aa.sh
module load vcftools/0.1.17 
module load samtools/1.4.1 
export PERL5LIB=/DATA/APPS/vcftools/0.1.17/lib/site_perl/5.24.1/
cat $1 | fill-aa -a /share/rdata/ramon.pouso/reference/indexed_reference/ancestral_dmel-all-chromosome-r6.14.fa.gz > ${1/.vcf/.aafilled.vcf}

#Run it as follows: qsub -cwd -l h=compute-0-9 /share/rdata/ramon.pouso/Scripts/fill-aa.sh $1

```

##Polarise the AA-filled VCF:
```{bash}

module load bcftools/1.9
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/

#Polarize the VCF:
FILE=crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.aafilled.vcf
N_IND=$(bcftools query -l $FILE | wc -l)
ID_FIRST=$(bcftools query -l $FILE | head -n1)
N_FIRST=$(grep -v '##' $FILE | grep '#' | tr "\t" "\n" | grep -n $ID_FIRST | cut -d':' -f1)
grep -v '#' $FILE | awk -F"\t|AA=" '$4==$9' > ${FILE/.vcf/.consistent.vcf}
grep -v '#' $FILE | awk -F"\t|AA=" '$5==$9' | awk -F";AF=|;EMstats=" '{printf ("%s;AF=%s;EMstats=%s\n", $1,1-$2,$3)}' > ${FILE/.vcf/.inconsistent.vcf}
cut -f-$((N_FIRST-1)) ${FILE/.vcf/.inconsistent.vcf} | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$5,$4,$6,$7,$8,$9,$10)}' > ${FILE/.vcf/.inconsistent.polarized.vcf}
for col in $(seq $N_FIRST $((N_FIRST+N_IND-1)))
  do
  echo "processing individual in column number" $col
  paste ${FILE/.vcf/.inconsistent.polarized.vcf} <(cut -f$col ${FILE/.vcf/.inconsistent.vcf} | awk -F":|," '{printf ("%s:%s:%s:%s,%s:%s,%s:%s,%s\n", $1,$2,$3,$5,$4,$7,$6,$9,$8)}') > ${FILE/.vcf/.inconsistent.temp}
  mv ${FILE/.vcf/.inconsistent.temp} ${FILE/.vcf/.inconsistent.polarized.vcf}
  done
cat <(grep '#' $FILE) ${FILE/.vcf/.consistent.vcf} ${FILE/.vcf/.inconsistent.polarized.vcf} | bcftools sort > ${FILE/.aafilled.vcf/.polarized.vcf}

```

#6. Carry out general annotation with ANNOVAR:
##Build the drosophila database.
###Good complete version (changes codes in the UCSC database).
```{R, engine='bash'}

#First, copy the original version of the database (and rename it as "old_annovar_database") so that any new changes do not overwrite the original version.
cd /share/rdata/ramon.pouso/reference/indexed_reference
scp -pr annovar_database old_annovar_database

cd annovar_database/ancestral_dm6/

#Note: any code involving annotate_variation.pl won't work because apparently the server blocks its attempts to download files from an external website, so I had to replace it with alternative code.

#The following commented section doesn't need to be repeated:
<!-- #First download, uncompress and rename the gene database: -->
<!-- wget https://hgdownload.cse.ucsc.edu/goldenPath/dm6/database/refGene.txt.gz -->
<!-- gunzip -c refGene.txt.gz > dm6_refGene.txt -->

<!-- #Next, download the chromosome names equivalence file (aka "alias" or "dictionary"), which we'll need to edit the gene database so that the scaffolds use the same nomenclature as our files: -->
<!-- wget https://hgdownload.cse.ucsc.edu/goldenPath/dm6/bigZips/dm6.chromAlias.txt -->
<!-- nano dm6.chromAlias.txt #edit it to add "mitochondrion_genome" in the fourth column for the row that starts with chrM. -->

<!-- #Then we can replace all database names with the UCSC names, which are used in our VCFs and fasta files. -->
<!-- DB_CODES=$(cut -f3 dm6_refGene.txt | sort | uniq) -->
<!-- for old_code in ${DB_CODES[@]} -->
<!--   do -->
<!--   new_code=$(awk -v old=$old_code '$1==old' /share/rdata/ramon.pouso/reference/indexed_reference/annovar_database/ancestral_dm6/dm6.chromAlias.txt | cut -f4) -->
<!--   echo "${old_code} -> ${new_code}" -->
<!--   sed -i -e "s/\<$old_code\>/$new_code/g" dm6_refGene.txt -->
<!--   done -->

<!-- diff <(cut -f-2,4- dm6_refGene.txt) <(cut -f-2,4- refGene.txt) #checks whether the previous loop modified any other field. Since no lines are returned, both files are identical (outside of the 3rd column, which was changed). -->

#The following has to be repeated, since the new polarisation means that the ancestral genome has changed:
#Copy the ancestral fasta (obtained in the polarisation.Rmd script) to the aproppriate folder:
scp -p /share/rdata/ramon.pouso/reference/indexed_reference/ancestral_dmel-all-chromosome-r6.14.fa dm6_seq/dm6_ancestral_dmel-all-chromosome-r6.14.fa

#Next, use annovar to build the gene database:
module load annovar/4.19
retrieve_seq_from_fasta.pl dm6_refGene.txt -seqfile dm6_seq/dm6_ancestral_dmel-all-chromosome-r6.14.fa -format refGene -outfile dm6_refGeneMrna.fa

```

###Good non-redundant version (changes codes in the UCSC database).
```{R, engine='bash'}

#This version is a clone of the good complete version from which we'll remove all isoforms except for the longest one. Hence this is the "non-redundant" or "main isoforms" version of the annovar database, which we'll use to simplify the subsequent PROVEAN annotation.

#The following commented section doesn't need to be repeated:
<!-- #First, download the .gtf gene database from the UCSC: -->
<!-- cd /share/rdata/ramon.pouso/reference/indexed_reference/ -->
<!-- wget https://hgdownload.soe.ucsc.edu/goldenPath/dm6/bigZips/genes/dm6.refGene.gtf.gz -->
<!-- gunzip dm6.refGene.gtf.gz -->

<!-- #Then extract the list of transcripts, calculate their size, and keep the largest one for each chromosome. -->
<!-- awk -F"\t|gene_id |; transcript_id |;  gene_name " '($1 == "chr2L" || $1 == "chr2R" || $1 == "chr3L" || $1 == "chr3R" || $1 == "chr4" || $1 == "chrX") && $3=="transcript" {printf ("%s\t%s\t%s\t%s\n"),$1,$5-$4,$10,$11}' dm6.refGene.gtf | sed 's/"//g' | sort -k1,1 -k3,3 -k2,2nr | sort -k3,3 -u | sort -k1,1 -k3,3 > dm6nr.refGene.txt -->
<!-- grep -Ff <(cut -f4 dm6nr.refGene.txt) dm6.refGene.gtf > dm6nr.refGene.gtf -->

#Next, clone the previous ancestral database and rename it and some of its files to include the code "nr" (non-redundant):
cd /share/rdata/ramon.pouso/reference/indexed_reference/annovar_database/
#scp -pr ancestral_dm6 nr_ancestral_dm6
cd nr_ancestral_dm6
mv dm6_seq dm6nr_seq
mv dm6nr_seq/dm6_ancestral_dmel-all-chromosome-r6.14.fa dm6nr_seq/dm6nr_ancestral_dmel-all-chromosome-r6.14.fa
mv dm6.chromAlias.txt dm6nr.chromAlias.txt
rm dm6_refGeneMrna.fa

#Then subset the dm6 annovar database so that only main isoforms are kept, and remove the original database.
grep -Ff <(cut -f4 /share/rdata/ramon.pouso/reference/indexed_reference/dm6nr.refGene.txt) dm6_refGene.txt > dm6nr_refGene.txt
rm dm6_refGene.txt

#Next, use annovar to build the gene database:
module load annovar/4.19
retrieve_seq_from_fasta.pl dm6nr_refGene.txt -seqfile dm6nr_seq/dm6nr_ancestral_dmel-all-chromosome-r6.14.fa -format refGene -outfile dm6nr_refGeneMrna.fa

```

##Annotate the VCFs.
###Non-redundant version.
```{R, engine='bash'}

module load annovar/4.19
module load gcc/7.2.0 
module add gcc/7.2.0 


cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/
FILE=crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.vcf

#First convert from VCF to table (annovar can't deal with the particular format of the pool. VCFs).
convert2annovar.pl -format vcf4old --outfile ${FILE/.vcf/.annovar} $FILE

#Next, annotate the table. The resulting file is automatically labelled as .vcf by the programme, even though it really isn't a VCF.
table_annovar.pl ${FILE/.vcf/.annovar} /share/rdata/ramon.pouso/reference/indexed_reference/annovar_database/nr_ancestral_dm6 -vcfinput --outfile ${FILE/.vcf/.nr_annovar} -buildver dm6nr --protocol refGene --operation g

#Convert the annotated table to a .bed.
mv ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.vcf ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.tab
awk -F"\t|;ANNOVAR_DATE" '{printf ("%s\t%s\t%s\tANNOVAR_DATE%s\n"),$1,$2-1,$3,$9}' ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.tab > ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.bed

#Then intersect the polarized VCF with the annotated BED and edit it to obtain the annotated VCF:
grep '^#' $FILE > ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.vcf
bedtools intersect -a $FILE -b ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.bed -wb | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s;%s\n"),$1,$2-1,$2,$3,$4,$5,$6,$7,$8,$NF}' | bedtools intersect -a stdin -b $FILE -wb | cut -f1,3-9,18- >> ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.vcf

```

#7. Carry out SIFT annotation:
##Install the programme and download the database.
```{R, engine='bash'}

#Doesn't need to be repeated:
<!-- https://sift.bii.a-star.edu.sg/sift4g/SIFT4G_codes.html -->
<!-- https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB#DBfromGTF -->

<!-- #I'm following instructions from https://sift.bii.a-star.edu.sg/sift4g/Commandline.html -->

<!-- mkdir -p /share/rdata/ramon.pouso/reference/indexed_reference/sift_database/ -->
<!-- cd /share/rdata/ramon.pouso/reference/indexed_reference/sift_database/ -->

<!-- #First download and uncompress the database. -->
<!-- wget https://sift.bii.a-star.edu.sg/sift4g/public//Drosophila_melanogaster/BDGP6.83.zip --no-check-certificate -->
<!-- jar xf BDGP6.83.zip #The unzipped folder will have three files for each chromosome: a compressed chromosome file (.gz); a regions file (.regions); a chromosome statistics file (.txt). -->

<!-- #Then download the jar file to execute the programme. -->
<!-- wget -P /share/rdata/ramon.pouso https://github.com/pauline-ng/SIFT4G_Annotator/raw/master/SIFT4G_Annotator.jar -->

```

##Generate custom ancestral drosophila database:
```{R, engine='bash'}

#I'm following instructions from: https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB#DBfromGTF

#The following commented lines don't need to be processed again:
<!-- #First, install sift4g: -->
<!-- cd $LUSTRE -->
<!-- mkdir -p sift4g_annotation -->
<!-- cd sift4g_annotation -->
<!-- git clone --recursive https://github.com/rvaser/sift4g.git sift4g -->
<!-- cd sift4g/ -->
<!-- make -->

<!-- #Next download the UniProt ref90 protein database: -->
<!-- cd /mnt/lustre/scratch/home/uvi/bg/dkr/sift4g_annotation/sift_prot_db -->
<!-- wget https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/uniref90.fasta.gz -->
<!-- gunzip uniref90.fasta.gz -->

<!-- #Next, copy the database-builder scripts: -->
<!-- git clone https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB.git scripts_to_build_SIFT_db -->
<!-- cd scripts_to_build_SIFT_db/test_files/ -->

<!-- #Edit the target species config file: -->
<!-- scp homo_sapiens-test.txt nr_ancestral_dm6.config.txt -->
<!-- nano nr_ancestral_dm6.config.txt #edit each of the following fields following instructions from https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB#configFile: -->
<!-- PARENT_DIR=/mnt/lustre/scratch/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/test_files/nr_ancestral_dm6 -->
<!-- ORG=ancestral_drosophila_melanogaster -->
<!-- ORG_VERSION=nr_ancestral_dm6 -->
<!-- SIFT4G_PATH=/mnt/lustre/scratch/home/uvi/bg/dkr/sift4g_annotation/sift4g/bin/sift4g -->
<!-- PROTEIN_DB=/mnt/lustre/scratch/home/uvi/bg/dkr/sift4g_annotation/sift_prot_db/uniref90.fasta -->
<!-- MITO_GENETIC_CODE_TABLE=5 -->
<!-- MITO_GENETIC_CODE_TABLENAME=Invertebrate Mitochondrial -->

<!-- #Create directory for the target species, and copy the target species files (reference fasta and annotation file): -->
<!-- mkdir -p nr_ancestral_dm6 -->
<!-- cd nr_ancestral_dm6 -->
<!-- #Put genomic fasta file in chr-src, and split it by chromosome: -->
<!-- mkdir -p chr-src -->

#First copy the old database and rename it as "old_nr_ancestral_dm6" so that new changes don't overwrite the original content (very slow!!!):
cd $LUSTRE/sift4g_annotation/scripts_to_build_SIFT_db/test_files
scp -pr nr_ancestral_dm6 old_nr_ancestral_dm6

#Next, edit all paths within the config file (since everything is now in CESGA FT3 rather than FT2, the path is a bit different and "nlsas/" needs to be added after "scratch/")
nano nr_ancestral_dm6.config.txt #edit

#Copy the new genomic fasta file to chr-src, and split it by chromosome:
cd nr_ancestral_dm6
scp -p ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/reference/indexed_reference/ancestral_dmel-all-chromosome-r6.14.fa.gz chr-src/
cd chr-src/
gunzip ancestral_dmel-all-chromosome-r6.14.fa.gz
awk 'BEGIN {O="";} /^>/ { O=sprintf("%s.fa",substr($0,2));} {if(O!="") print >> O;}' ancestral_dmel-all-chromosome-r6.14.fa
rm ancestral_dmel-all-chromosome-r6.14.fa
rm *.gz #delete the old files
#Put gene annotation file in gene-annotation-src:
cd ..
mkdir -p gene-annotation-src
scp -p ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/reference/indexed_reference/dm6nr.refGene.gtf gene-annotation-src/
gunzip gene-annotation-src/dm6nr.refGene.gtf.gz
awk -F"\t" '{OFS = FS} { gsub(/chr/,"", $1); print }' gene-annotation-src/dm6nr.refGene.gtf | gzip > gene-annotation-src/dm6nr.refGene.gtf.gz #remove the "chr" part from the chromosome names in the .gtf file, since it's using a different nomenclature than the .fa file and it was crashing the programme.
rm gene-annotation-src/dm6nr.refGene.gtf

#Next remove the files and folders which will be redone:
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/test_files/nr_ancestral_dm6
rm -r SIFT_predictions
rm -r singleRecords*
rm -r nr_ancestral_dm6
rm -r subst/
rm -r fasta/
rm all_prot.fasta
rm *log
rm Log2.txt

******************>

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db

#Finally, build the database using the following command:
sbatch make-SIFT-db-all.sh #But first store in make-SIFT-db-all.sh the following lines:

#!/bin/bash
#SBATCH -p thinnodes
#SBATCH -n 2
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=24
#SBATCH --mem-per-cpu=10GB
#SBATCH -J make-SIFT-db-all
#SBATCH -o make-SIFT-db-all_%A.out
#SBATCH -t 16:00:00 # execution time
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db
perl make-SIFT-db-all.pl -config /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/test_files/nr_ancestral_dm6.config.txt

#I encountered this bug: https://github.com/rvaser/sift4g/issues/10 and edited the code as suggested here. However I kept running into the same problem until I realised that the programme doesn't remove the all_prot.fasta file, so it keeps appending the wrong sequences. Notwithstanding, even after manually removing it, I kept running into the alignment issues. So I posted a message in the linked issue, and followed rvaser's instructions over there.

#Since the first steps of the pipeline are working fine and don't need to be repeated, I downloaded https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/3877234/make-SIFT-db-starting_from_SIFT4G.pl.txt and used this script for subsequent attempts:
sbatch make-SIFT-db-starting_from_SIFT4G.sh #But first store in make-SIFT-db-starting_from_SIFT4G.sh the following lines:

#!/bin/bash
#SBATCH -p thinnodes
#SBATCH -n 2 --ntasks-per-node=1 --cpus-per-task=24
#SBATCH --mem-per-cpu=10GB
#SBATCH -J make-SIFT-db-starting_from_SIFT4G
#SBATCH -o make-SIFT-db-starting_from_SIFT4G_%A.out
#SBATCH -t 16:00:00 # execution time
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/
perl make-SIFT-db-starting_from_SIFT4G.pl.txt -config /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/test_files/nr_ancestral_dm6.config.txt

#Next I kept running into some extra errors while populating the databases, so I posted yet another issue: https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/53 . According to Pauline, these error messages matter not.

```

##Run the programme:
####nr version:
#####Upload the VCFs and the SIFT4G jar file to CESGA:
```{R, engine='bash'}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation
mv annotation/ old_annotation/

#In CESGA, create the destination folders:
mkdir -p /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/annotation/pools_gen0-140/

#From the cluster, copy the following files:
##ANNOVAR-annotated VCF:
scp -p /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/annotation/pools_gen0-140/
##SIFT4G jar file:
#scp -p /share/rdata/ramon.pouso/sift4g/SIFT4G_Annotator_v2.4.jar uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/sift4g/

```

#####Annotate the files:
```{R, engine='bash'}

#Launch it as follows for each VCF (don't copy them from here to the terminal; invisible spaces will break it):
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/annotation/pools_gen0-140
java -jar /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/sift4g/SIFT4G_Annotator_v2.4.jar -c -t -i crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf -d /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/test_files/nr_ancestral_dm6/nr_ancestral_dm6/ -r ./

#If this doesn't work from the standard interactive shell in CESGA, then request dedicated interactive nodes, and run the former core from there. E.g.: compute -c 2 --mem 20

```

#####Download the VCFs from CESGA:
```{R, engine='bash'}

#From the cluster, copy the following files:
scp -p uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/annotation/pools_gen0-140/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno_SIFTpredictions.vcf /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/

```

##Analyse the output:
###Default thresholds:
```{bash}

#It's important to select the relevant annotation per site when there is more than one. Extract the name of the gene from the annovar part, then also from the sift part, and keep only the matching one!

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/
VCF=crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno_SIFTpredictions.vcf

#One entry: 
grep -v '^#' $VCF | grep 'nonsynonymous_SNV' | grep 'SIFT' | awk '!($5 ~ ",")' | awk -F";Gene\\\\.refGene=|;GeneDetail\\\\.refGene=|;AAChange\\\\.refGene=|;ALLELE_END|;SIFTINFO=|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$9,$11,$13)}' | awk 'BEGIN{FS=OFS="\t"} {gsub(":","_", $4);gsub("\\(","_");gsub("\\)","_");print}' | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$10)}' | grep -v "," > ${VCF/.vcf/.clean.txt}
#Multiple entries:
grep -v '^#' $VCF | grep 'nonsynonymous_SNV' | grep 'SIFT' | awk '!($5 ~ ",")' | awk -F";Gene\\\\.refGene=|;GeneDetail\\\\.refGene=|;AAChange\\\\.refGene=|;ALLELE_END|;SIFTINFO=|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$9,$11,$13)}' | awk 'BEGIN{FS=OFS="\t"} {gsub(":","_", $4);gsub("\\(","_");gsub("\\)","_");print}' | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$10)}' | grep "," | sed 's/,/\t/g' | awk '{for(i=6;i<=NF;i++){if($i ~ $5){printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$i)}}}' >> ${VCF/.vcf/.clean.txt}

#Classify the mutations in deleterious and tolerated categories:
module load gcc/7.2.0
module add gcc/7.2.0
grep "DELETERIOUS" ${VCF/.vcf/.clean.txt} | bedtools sort > gen0-140_all_sites_missense_variants_SIFT_scores_deleterious.bed #15595 (23.5% of the total 66486)
grep "TOLERATED" ${VCF/.vcf/.clean.txt} | bedtools sort > gen0-140_all_sites_missense_variants_SIFT_scores_tolerated.bed #50774 (76.4% of the total 66486)

#Check genes with parentheses:
#grep -v '^#' $VCF | grep 'synonymous_SNV' | grep 'SIFT' | awk -F";Gene\\\\.refGene=|;GeneDetail\\\\.refGene=|;AAChange\\\\.refGene=|;ALLELE_END|;SIFTINFO=|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$9,$11,$13)}' | awk -F"\t" '{gsub(/:/,"_", $4); print}' | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$10)}' | awk '$5 ~ "\\("' | grep "," | sed 's/,/\t/g' | awk -F"\t" '{gsub("\\(","_");gsub("\\)","_");print}' | awk '{for(i=6;i<=NF;i++){if($i ~ $5){printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$i)}}}' | less -S

#Check consistency between the current and the old VCFs:
##Both deleterious:
bedtools intersect -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/gen0-140_all_sites_missense_variants_SIFT_scores_deleterious.bed -b /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/5variants/multirealigned/POOLS_gen0-40_missense_variants_SIFT_scores_deleterious.bed | wc -l #14061
#Both tolerated:
bedtools intersect -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/gen0-140_all_sites_missense_variants_SIFT_scores_tolerated.bed -b /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/5variants/multirealigned/POOLS_gen0-40_missense_variants_SIFT_scores_tolerated.bed | wc -l #46908
##Deleterious in new dataset, tolerated in the old one (gen0-40):
bedtools intersect -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/gen0-140_all_sites_missense_variants_SIFT_scores_deleterious.bed -b /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/5variants/multirealigned/POOLS_gen0-40_missense_variants_SIFT_scores_tolerated.bed | wc -l #26
##Tolerated in the old dataset (gen0-40), deleterious in the new one:
bedtools intersect -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/gen0-140_all_sites_missense_variants_SIFT_scores_tolerated.bed -b /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/5variants/multirealigned/POOLS_gen0-40_missense_variants_SIFT_scores_deleterious.bed | wc -l #16
##Deleterious exclusive to the new dataset:
bedtools subtract -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/gen0-140_all_sites_missense_variants_SIFT_scores_deleterious.bed -b /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/5variants/multirealigned/POOLS_gen0-40_missense_variants_SIFT_scores_deleterious.bed | wc -l #1534
##Tolerated exclusive to the new dataset:
bedtools subtract -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/gen0-140_all_sites_missense_variants_SIFT_scores_tolerated.bed -b /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/5variants/multirealigned/POOLS_gen0-40_missense_variants_SIFT_scores_tolerated.bed | wc -l #3866

#Looks good.

```

###≤0.01 vs >0.05:
```{bash}

#It's important to select the relevant annotation per site when there is more than one. Extract the name of the gene from the annovar part, then also from the sift part, and keep only the matching one!

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/
VCF=crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno_SIFTpredictions.vcf

#One entry: 
grep -v '^#' $VCF | grep 'nonsynonymous_SNV' | grep 'SIFT' | awk '!($5 ~ ",")' | awk -F";Gene\\\\.refGene=|;GeneDetail\\\\.refGene=|;AAChange\\\\.refGene=|;ALLELE_END|;SIFTINFO=|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$9,$11,$13)}' | awk 'BEGIN{FS=OFS="\t"} {gsub(":","_", $4);gsub("\\(","_");gsub("\\)","_");print}' | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$10)}' | grep -v "," > ${VCF/.vcf/.clean.txt}
#Multiple entries:
grep -v '^#' $VCF | grep 'nonsynonymous_SNV' | grep 'SIFT' | awk '!($5 ~ ",")' | awk -F";Gene\\\\.refGene=|;GeneDetail\\\\.refGene=|;AAChange\\\\.refGene=|;ALLELE_END|;SIFTINFO=|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$9,$11,$13)}' | awk 'BEGIN{FS=OFS="\t"} {gsub(":","_", $4);gsub("\\(","_");gsub("\\)","_");print}' | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$10)}' | grep "," | sed 's/,/\t/g' | awk '{for(i=6;i<=NF;i++){if($i ~ $5){printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$i)}}}' >> ${VCF/.vcf/.clean.txt}

#Classify the mutations in deleterious and tolerated categories:
module load gcc/7.2.0
module add gcc/7.2.0
grep "DELETERIOUS" ${VCF/.vcf/.clean.txt} | awk -F"\t|\\\\|" 'BEGIN{OFS="\t"} {printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$14)}' | awk '$6<=0.01' | bedtools sort > gen0-140_all_sites_missense_variants_SIFT_scores_001deleterious.bed #9890 instead of 15595 with the default threshold
#grep "TOLERATED" ${VCF/.vcf/.clean.txt} | bedtools sort > gen0-140_all_sites_missense_variants_SIFT_scores_tolerated.bed

```

###≤0.05 vs >0.20:
```{bash}

#It's important to select the relevant annotation per site when there is more than one. Extract the name of the gene from the annovar part, then also from the sift part, and keep only the matching one!

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/
VCF=crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno_SIFTpredictions.vcf

#One entry: 
grep -v '^#' $VCF | grep 'nonsynonymous_SNV' | grep 'SIFT' | awk '!($5 ~ ",")' | awk -F";Gene\\\\.refGene=|;GeneDetail\\\\.refGene=|;AAChange\\\\.refGene=|;ALLELE_END|;SIFTINFO=|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$9,$11,$13)}' | awk 'BEGIN{FS=OFS="\t"} {gsub(":","_", $4);gsub("\\(","_");gsub("\\)","_");print}' | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$10)}' | grep -v "," > ${VCF/.vcf/.clean.txt}
#Multiple entries:
grep -v '^#' $VCF | grep 'nonsynonymous_SNV' | grep 'SIFT' | awk '!($5 ~ ",")' | awk -F";Gene\\\\.refGene=|;GeneDetail\\\\.refGene=|;AAChange\\\\.refGene=|;ALLELE_END|;SIFTINFO=|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$9,$11,$13)}' | awk 'BEGIN{FS=OFS="\t"} {gsub(":","_", $4);gsub("\\(","_");gsub("\\)","_");print}' | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$10)}' | grep "," | sed 's/,/\t/g' | awk '{for(i=6;i<=NF;i++){if($i ~ $5){printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$i)}}}' >> ${VCF/.vcf/.clean.txt}

#Classify the mutations in deleterious and tolerated categories:
module load gcc/7.2.0
module add gcc/7.2.0
#grep "DELETERIOUS" ${VCF/.vcf/.clean.txt} | bedtools sort > gen0-140_all_sites_missense_variants_SIFT_scores_deleterious.bed
grep "TOLERATED" ${VCF/.vcf/.clean.txt} | awk -F"\t|\\\\|" 'BEGIN{OFS="\t"} {printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$14)}' | awk '$6>=0.20' | bedtools sort > gen0-140_all_sites_missense_variants_SIFT_scores_020tolerated.bed #34901 instead of 50774 with the default threshold 

```

#8. Carry out PROVEAN annotation.
##Copy the previous dataset to another folder:
```{bash}

#Inside uvibgdkr@ft3.cesga.es:
scp -pr /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation /mnt/netapp2/Store_uni/home/uvi/bg/dkr/ #Move the original dataset of the project to $STORE.

```

##Prepare necessary files to build the database.
###Prepare list of genes with new or changed missense mutations.
```{bash}

#This and the next step will be performed in the cluster, but the rest in CESGA. The idea here is to obtain the list of mutations which have changed (due to a different polarisation) or have been included for the first time in the new dataset:
mkdir -p /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean
module load gcc/7.2.0
module add gcc/7.2.0

VCF="/share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf"

#Extract list of sites which are annotated as exonic and nonsynonymous, and convert to bed format:
grep -e 'refGene=exonic;.*nonsynonymous' $VCF > pools_individuals_nonsynonymous_vcf.txt
awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$4,$5)}' pools_individuals_nonsynonymous_vcf.txt > pools_individuals_nonsynonymous_vcf.bed

#Convert the old dataset to bed format:
awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$4,$5)}' /share/rdata/ramon.pouso/provean/pools_individuals_nonsynonymous_vcf.txt | sort -k1,1 -k2,2n | uniq > /share/rdata/ramon.pouso/provean/pools_individuals_nonsynonymous_vcf.bed

#Extract list of sites exclusive to the new dataset, plus those whose polarisation changed between datasets:
bedtools subtract -a pools_individuals_nonsynonymous_vcf.bed -b /share/rdata/ramon.pouso/provean/pools_individuals_nonsynonymous_vcf.bed > pools_individuals_nonsynonymous_vcf.diff.bed
bedtools intersect -a pools_individuals_nonsynonymous_vcf.bed -b /share/rdata/ramon.pouso/provean/pools_individuals_nonsynonymous_vcf.bed -wa -wb | awk '$4 != $9' | cut -f-5 >> pools_individuals_nonsynonymous_vcf.diff.bed
sort -k1,1 -k2,2n pools_individuals_nonsynonymous_vcf.diff.bed > pools_individuals_nonsynonymous_vcf.diff_sorted.bed && mv pools_individuals_nonsynonymous_vcf.diff_sorted.bed pools_individuals_nonsynonymous_vcf.diff.bed

#Generate list with coordinates, gene and transcript names, and aminoacid changes:
bedtools intersect -a $VCF -b pools_individuals_nonsynonymous_vcf.diff.bed | awk -F"\t|;AAChange.refGene=|;ALLELE_END" '{printf ("%s\t%s\t%s\n", $1,$2,$9)}' | awk -F"\t|:|," '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$7)}' | awk -F"\t" '{OFS = FS} { gsub(/p\./,"", $5); print }' | grep -v "RNA" | sort -k1,1 -k2,2n | uniq > pools_individuals_nonsynonymous_gene_names.txt

#Generate the same list for all missense sites in the VCF (and not just the new/changed ones), which will be necessary later on:
bedtools intersect -a $VCF -b pools_individuals_nonsynonymous_vcf.bed | awk -F"\t|;AAChange.refGene=|;ALLELE_END" '{printf ("%s\t%s\t%s\n", $1,$2,$9)}' | awk -F"\t|:|," '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$7)}' | awk -F"\t" '{OFS = FS} { gsub(/p\./,"", $5); print }' | grep -v "RNA" | sort -k1,1 -k2,2n | uniq > pools_individuals_nonsynonymous_gene_names_complete.txt

#Sanity checks:
cut -f3 pools_individuals_nonsynonymous_gene_names.txt | sort -u | wc -l #3232 genes
cut -f4 pools_individuals_nonsynonymous_gene_names.txt | sort -u | wc -l #3232 transcripts
#If the number of unique gene names and transcript names is the same, the script worked. In a previous version both numbers were different, which allowed me to discover that some genes with parenthesis in their names were introducing bugs. I modified the code to the current version, and now everything checks.

scp pools_individuals_nonsynonymous_gene_names.txt uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
scp pools_individuals_nonsynonymous_gene_names_complete.txt uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

```

###Prepare annotation and fasta files.
```{bash}

cd /share/rdata/ramon.pouso/reference/indexed_reference/

#Upload the non-redundant version of the .gtf file obtained in the ANNOVAR section:
scp dm6nr.refGene.gtf uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

#Upload the ancestral version of the .fa file obtained in the polarisation script:
scp ancestral_dmel-all-chromosome-r6.14.fa uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

```

##Build Provean database.
###Generate for each gene a file with its aminoacid changes (in the format required by Provean).
```{bash}

#This analysis will be run from here on in CESGA, in the following path:
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

#Extract all variants from each gene and store them in variant files.
mkdir -p genes_variants
GENES=$(cat pools_individuals_nonsynonymous_gene_names.txt | cut -f 3 | sort -u)
for gen in ${GENES[@]}
  do
  echo "$gen"
  awk -v gene_name=$gen '$3 == gene_name {print $5}' pools_individuals_nonsynonymous_gene_names.txt > genes_variants/"$gen".var
  done
  
#Replace parentheses with low dashes, since provean.sh isn't able to parse files with brackets in their name. Also remove square brackets.
cd genes_variants
GENES=$(ls *\(*)
for old_name in ${GENES[@]}
  do
  echo "$old_name"
  new_name=$(echo "$old_name" | sed -e 's/(/_/g;s/)/_/g;s/\[//g;s/\]//g')
  echo "$new_name"
  mv "$old_name" "$new_name"
  done

```

###Generate for each gene a fasta file with its protein sequence.
####Retrieve the whole nucleotide sequence.
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

#First generate a more readable version of the non-redundant annotation file, which keeps only necessary data, and transforms coordinates from 1-based (GTF format) to 0-based (BED format):
awk -F'\t|gene_id \"|"; transcript_id |; exon_id "|"; gene_name' '($1 == "chr2L" || $1 == "chr2R" || $1 == "chr3L" || $1 == "chr3R" || $1 == "chr4" || $1 == "chrX") && $3=="CDS" {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n"),$1,$4-1,$5,$7,$8,$10,$12}' dm6nr.refGene.gtf > dm6nr.refGene.txt

#Then cross it with the list of genes with nonsynonymous variants to obtain coordinates for all CDS from all genes that will be analysed with Provean. I tried to do it faster using grep -Fwf but some genes have special characters (such as "-") which are not considered part of a word, so it introduces some mistakes. SO it's best to use this loop instead:
GENES=$(cat pools_individuals_nonsynonymous_gene_names.txt | cut -f 3 | sort -u)
COUNTER=0
rm pools_individuals_nonsynonymous.cds_list.dm6nr.refGene.txt
for gen in ${GENES[@]}
  do
  #echo "${gen}"
  awk -v gene_name=$gen '$6 == gene_name' dm6nr.refGene.txt >> pools_individuals_nonsynonymous.cds_list.dm6nr.refGene.txt
  ((COUNTER++))
  if [ $(( $COUNTER % 100 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $(echo "$GENES" | wc -l)"
  fi
  done
awk -F"\t" '{OFS = FS} { gsub(/chr/,"", $1); print }' pools_individuals_nonsynonymous.cds_list.dm6nr.refGene.txt > pools_individuals_nonsynonymous.cds_list.dm6nr.refGene.bed #Remove the "chr" from the chromosome names to convert them into the same format that the fasta uses.

  ##Sanity checks:
  cut -f6 pools_individuals_nonsynonymous.cds_list.dm6nr.refGene.bed | uniq | wc -l #3192 genes instead of the 3232 found in pools_individuals_nonsynonymous_gene_names.txt because some of the genes in the annovar database are not included in the UCSC .gtf file. 
  comm -3 <(cut -f3 pools_individuals_nonsynonymous_gene_names.txt | sort -u) <(cut -f6 pools_individuals_nonsynonymous.cds_list.dm6nr.refGene.bed | sort -u) | wc -l #40, which is the correct result of 10612-10502. 
  comm -3 <(cut -f3 pools_individuals_nonsynonymous_gene_names.txt | sort -u) <(cut -f6 pools_individuals_nonsynonymous.cds_list.dm6nr.refGene.bed | sort -u) | less -S #All results are displayed in the first column, which means that all missing entries are missing in the second file, and none from the second file are missing in the first one.

#Retrieve reference sequences for all CDS (from the ancestral fasta to account for polarisation).
module load bedtools/2.30.0
rm ancestral_dmel-all-chromosome-r6.14.fa.fai
bedtools getfasta -fi ancestral_dmel-all-chromosome-r6.14.fa -bed pools_individuals_nonsynonymous.cds_list.dm6nr.refGene.bed -fo pools_individuals_nonsynonymous.cds_sequence.fa

  ##Sanity checks:
  grep -v '>' pools_individuals_nonsynonymous.cds_sequence.fa | wc -l #15348, which is the same number of CDS (lines) in the file pools_individuals_nonsynonymous.cds_list.dm6nr.refGene.bed.

#Paste each CDS' sequence with the rest of the information.
paste pools_individuals_nonsynonymous.cds_list.dm6nr.refGene.bed <(grep -v '>' pools_individuals_nonsynonymous.cds_sequence.fa) > pools_individuals_nonsynonymous.cds_list_and_sequence.dm6nr.refGene.bed

  ##Sanity checks:
  awk '{printf ("%s\t%s\n"),$3-$2,length($8)}' pools_individuals_nonsynonymous.cds_list_and_sequence.dm6nr.refGene.bed | awk '$1==$2' | wc -l #15348, which means that all retrieved sequences have the correct length (the same as the difference between their start and their end points).

#Fuse all exons from each gene and store them in a file together with the gene name and the strand information.
GENES=$(cat pools_individuals_nonsynonymous.cds_list_and_sequence.dm6nr.refGene.bed | cut -f 6 | sort -u)
TOTAL=$(echo "$GENES" | wc -l)
COUNTER=0
rm pools_individuals_nonsynonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed
for gen in ${GENES[@]}
  do
  #echo "${gen}"
  STRAND=$(awk -F"\t" -v gen=$gen '$6 == gen' pools_individuals_nonsynonymous.cds_list_and_sequence.dm6nr.refGene.bed | shuf -n1 | cut -f 4)
  CODING_SEQUENCE=$(awk -F"\t" -v gen=$gen '$6 == gen {print $8}' pools_individuals_nonsynonymous.cds_list_and_sequence.dm6nr.refGene.bed | tr -d '\n')
  echo -e "$gen\t$STRAND\t$CODING_SEQUENCE" >> pools_individuals_nonsynonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed
  ((COUNTER++))
  if [ $(( $COUNTER % 50 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $(echo "$GENES" | wc -l)"
  fi
  done

#Translate the exons to proteins using an external website and store each protein in a fasta file:
mkdir -p genes_fasta
TOTAL=$(cat pools_individuals_nonsynonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed | wc -l)
COUNTER=0
while read -r GENE STRAND CODING_SEQUENCE; do
  #GENE=$(echo "$entry" | cut -f 1)
  echo $GENE
  #STRAND=$(echo "$entry" | cut -f 2)
  #echo $STRAND
  #CODING_SEQUENCE=$(echo "$entry" | cut -f 3)
  #echo $CODING_SEQUENCE
  if [ $STRAND == "+" ]
    then
    curl -s -d "dna_sequence=$CODING_SEQUENCE&output_format=fasta" -A "${GENE}" https://web.expasy.org/cgi-bin/translate/dna2aa.cgi | awk '/:5'\''3'\'' Frame 1$/,/:5'\''3'\'' Frame 2$/' | head -n-1 | sed -r '/^\s*$/d' | sed 's/-/X/g' > genes_fasta/"$GENE".fa #sends the DNA sequence to the expasy website, then selects the lines for the proper strand (here: +) between the header for Frame 1 and the header for Frame 2, then removes the header for Frame 2, then removes any empty line that may exist, then replaces any existing hyphen by an X (unknown aminoacid) so that Provean doesn't crash.
  elif [ $STRAND == "-" ]
    then
    curl -s -d "dna_sequence=$CODING_SEQUENCE&output_format=fasta" -A "${GENE}" https://web.expasy.org/cgi-bin/translate/dna2aa.cgi | awk '/:3'\''5'\'' Frame 1$/,/:3'\''5'\'' Frame 2$/' | head -n-1 | sed -r '/^\s*$/d' | sed 's/-/X/g' > genes_fasta/"$GENE".fa #sends the DNA sequence to the expasy website, then selects the lines for the proper strand (here: -) between the header for Frame 1 and the header for Frame 2, then removes the header for Frame 2, then removes any empty line that may exist, then replaces any existing hyphen by an X (unknown aminoacid) so that Provean doesn't crash.
  fi
  ((COUNTER++))
  if [ $(( $COUNTER % 2 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $TOTAL"
  fi
  sleep 1
  done < pools_individuals_nonsynonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed

```

####Convert to aminoacidic sequence.
#####nucleotide_to_aminoacid.sh
```{bash}

#!/bin/bash
#SBATCH -p thinnodes
#SBATCH -J nucleotide_to_aminoacid
#SBATCH -o nucleotide_to_aminoacid_%A.out
#SBATCH -t 00:05:00              # Run time (hh:mm:ss)
#SBATCH -c 6
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com

#Translate the exons to proteins using an external website and store each protein in a fasta file:

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

TOTAL=$(cat $1 | wc -l)
COUNTER=0
while read -r GENE STRAND CODING_SEQUENCE; do
  #GENE=$(echo "$entry" | cut -f 1)
  echo $GENE
  #STRAND=$(echo "$entry" | cut -f 2)
  #echo $STRAND
  #CODING_SEQUENCE=$(echo "$entry" | cut -f 3)
  #echo $CODING_SEQUENCE
  if [ $STRAND == "+" ]
    then
    curl -s -d "dna_sequence=$CODING_SEQUENCE&output_format=fasta" -A "${GENE}" https://web.expasy.org/cgi-bin/translate/dna2aa.cgi | awk '/:5'\''3'\'' Frame 1$/,/:5'\''3'\'' Frame 2$/' | head -n-1 | sed -r '/^\s*$/d' | sed 's/-/X/g' > genes_fasta/"$GENE".fa #sends the DNA sequence to the expasy website, then selects the lines for the proper strand (here: +) between the header for Frame 1 and the header for Frame 2, then removes the header for Frame 2, then removes any empty line that may exist, then replaces any existing hyphen by an X (unknown aminoacid) so that Provean doesn't crash.
  elif [ $STRAND == "-" ]
    then
    curl -s -d "dna_sequence=$CODING_SEQUENCE&output_format=fasta" -A "${GENE}" https://web.expasy.org/cgi-bin/translate/dna2aa.cgi | awk '/:3'\''5'\'' Frame 1$/,/:3'\''5'\'' Frame 2$/' | head -n-1 | sed -r '/^\s*$/d' | sed 's/-/X/g' > genes_fasta/"$GENE".fa #sends the DNA sequence to the expasy website, then selects the lines for the proper strand (here: -) between the header for Frame 1 and the header for Frame 2, then removes the header for Frame 2, then removes any empty line that may exist, then replaces any existing hyphen by an X (unknown aminoacid) so that Provean doesn't crash.
  fi
  ((COUNTER++))
  if [ $(( $COUNTER % 50 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $TOTAL"
  fi
  sleep 2
  done < $1

```

#####Send the job:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

PARALLEL=4
FILENAME=pools_individuals_nonsynonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed
TOTAL=$(wc -l < $FILENAME)
BLOCK_SIZE=$(echo "scale=0; $TOTAL/$PARALLEL" | bc)
for ((i=1; i<PARALLEL; i++))
  do
  START=$((((i-1))*BLOCK_SIZE+1))
  echo $START
  END=$((BLOCK_SIZE*i))
  echo $END
  sed -n "${START},${END}p" $FILENAME > ${FILENAME/.bed/.chunk_${i}.bed}
  done
START=$((((i-1))*BLOCK_SIZE+1))
echo $START
echo $TOTAL
sed -n "${START},${TOTAL}p" $FILENAME > ${FILENAME/.bed/.chunk_${i}.bed}

for ((i=1; i<=PARALLEL; i++))
  do
  sbatch -J nucleotide_to_aminoacid -o nucleotide_to_aminoacid.chunk_${i}.%A.out cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/nucleotide_to_aminoacid.sh ${FILENAME/.bed/.chunk_${i}.bed}
  done

```

####Fix some gene names:
```{bash}

#Replace parentheses with low dashes, since provean.sh isn't able to parse files with brackets in their name. Also remove square brackets.
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/genes_fasta
GENES=$(ls *\(*)
for old_name in ${GENES[@]}
  do
  echo "$old_name"
  new_name=$(echo "$old_name" | sed -e 's/(/_/g;s/)/_/g;s/\[//g;s/\]//g')
  echo "$new_name"
  mv "$old_name" "$new_name"
  done

```

##Configure Provean:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/

#Provean didn't work in CESGA because it was linked with the most recent versions of ncbi-blast+ and the blast nr databases, so I downloaded the required version of both:
##blast+ v2.4.0:
wget https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/2.4.0/ncbi-blast-2.4.0+-x64-linux.tar.gz
#/mnt/lustre/scratch/home/uvi/bg/dkr
tar xvzf ncbi-blast-2.4.0+-x64-linux.tar.gz
##nr protein database v4
cd ncbi-blast-2.4.0+/
wget https://ftp.ncbi.nlm.nih.gov/blast/db/v4/nr_v4* /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/ncbi-blast-2.4.0+
tar xvzf nr_v4*

#Next, I copied the executable provean files to my local folder:
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
scp -p /mnt/netapp1/Optcesga_FT2_RHEL7/2020/software/Compiler/gcccore/system/provean/1.1.5/bin/provean ./
scp -p /mnt/netapp1/Optcesga_FT2_RHEL7/2020/software/Compiler/gcccore/system/provean/1.1.5/bin/provean.sh ./ 
nano provean.sh #Then I edited the configuration paths in the provean.sh files to match the following:
####################
# CONFIGURATION
####################
# Specify the path to database and program
#
BLAST_DB="/mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/ncbi-blast-2.4.0+/blastdb_v4nr/nr"
PSIBLAST="/mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/ncbi-blast-2.4.0+/bin/psiblast"
CD_HIT="/opt/cesga/2020/software/Compiler/gcccore/system/cd-hit/4.8.1/bin/cd-hit"
BLASTDBCMD="/mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/ncbi-blast-2.4.0+/bin/blastdbcmd"
# END CONFIGURATION
####################

```

##Run Provean.
###Prepare the list of genes and the output folder:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
cut -f1 pools_individuals_nonsynonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed > gene_list.txt
mkdir -p provean_output
mkdir -p genes_support

```

###Parallel runs (N=10) of all genes:
####Choose the partition number:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
PARALLEL=10 #define the desired value, and the script will do the rest

FILENAME=gene_list.txt
TOTAL=$(wc -l < $FILENAME)
BLOCK_SIZE=$(echo "scale=0; $TOTAL/$PARALLEL" | bc)
for ((i=1; i<PARALLEL; i++))
  do
  START=$((((i-1))*BLOCK_SIZE+1))
  echo $START
  END=$((BLOCK_SIZE*i))
  echo $END
  sed -n "${START},${END}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}
  done
START=$((((i-1))*BLOCK_SIZE+1))
echo $START
echo $TOTAL
sed -n "${START},${TOTAL}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}

```

####Scripts:
#####fatnode: parallel_provean.sh
```{bash}

#!/bin/bash
#SBATCH -p fatnode
#SBATCH -J provean_parallel
#SBATCH -o provean_parallel.%A.chunk_%a.out
#SBATCH -t 100:00:00              # Run time (hh:mm:ss)
#SBATCH -c 16
#SBATCH --mem-per-cpu=10GB
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
module load gcccore/system provean/1.1.5

# Retrieve files:
FILENAME=gene_list.txt
echo "Running provean; chunk number" ${SLURM_ARRAY_TASK_ID}
TOTAL=$(wc -l < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt})
COUNTER=0

while read -r GENE; do
#  if [ ! -f provean_output/${GENE}.provean ]
#    then
    echo "Processing gene $GENE"
    /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/provean.sh --num_threads $SLURM_CPUS_PER_TASK -q genes_fasta/"$GENE".fa -v genes_variants/"$GENE".var --save_supporting_set genes_support/"$GENE".sss > provean_output/"$GENE".provean
#    else
#    echo "$GENE already processed"
#  fi
  ((COUNTER++))
  if [ $(( $COUNTER % 10 )) == 0 ]
    then
    echo "Processed $COUNTER genes out of $TOTAL"
  fi
  done < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt}

```

####Send the array-job:
#####fatnode:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
PARALLEL=10 #define the desired value (same as in the "Choose the partition number" section):
sbatch --array=1-$PARALLEL /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/parallel_provean.sh

#sbatch --array=10,20 /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/parallel_provean.sh #For listing specific chunks, use a comma.

```

####Retrieve unfinished genes and launch them (N=20):
#####Choose chunks:
```{bash}

#Once all chunks of a particular job have finished, run this script to retrieve the list of genes which could not be processed before the queue finished, and group them in new input blocks:

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
JOB_ID=1265450 #Introduce the finished job id.
START=1 #Introduce the first chunk.
END=10 #Introduce the last chunk.
PARALLEL=20 #define the number of new partitions.

#First remove incomplete genes:
rm provean_parallel.$JOB_ID.chunk_${START}_to_chunk_${END}.remaining.out
for ((i=START; i<=END; i++))
  do
  ls provean_parallel.$JOB_ID.chunk_${i}.out >> provean_parallel.$JOB_ID.chunk_${START}_to_chunk_${END}.remaining.out
  done

GENE_LISTS=$(cat provean_parallel.$JOB_ID.chunk_${START}_to_chunk_${END}.remaining.out)
for gene_list in ${GENE_LISTS[@]}
  do
  if grep -q "TIME LIMIT" $gene_list; then
    INTERRUPTED_GENE=$(grep "Processing gene" $gene_list | tail -n1 | cut -d' ' -f3)
    echo "removing interrupted $INTERRUPTED_GENE.provean from $gene_list"
    #rm provean_output/$INTERRUPTED_GENE.provean
    fi
  done

#Then extract all unfinished genes:
rm gene_list.chunk_${START}_to_chunk_${END}.remaining.txt
  while read -r GENE
    do
    if [[ $(find "provean_output/${GENE}.provean" -mtime +50 -print) ]] || [ ! -f provean_output/${GENE}.provean ]
      then #if [ ! -f provean_output/${GENE}.provean ]
      echo $GENE
      echo ${GENE} >> gene_list.chunk_${START}_to_chunk_${END}.remaining.txt
    fi
    done < gene_list.txt

#And generate new partitions:
FILENAME=gene_list.chunk_${START}_to_chunk_${END}.remaining.txt
TOTAL=$(wc -l < $FILENAME)
BLOCK_SIZE=$(echo "scale=0; $TOTAL/$PARALLEL" | bc)
for ((i=1; i<PARALLEL; i++))
  do
  START=$((((i-1))*BLOCK_SIZE+1))
  echo $START
  END=$((BLOCK_SIZE*i))
  echo $END
  sed -n "${START},${END}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}
  done
START=$((((i-1))*BLOCK_SIZE+1))
echo $START
echo $TOTAL
sed -n "${START},${TOTAL}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}

```

#####Scripts:
######clk nodes: parallel_provean_remaining_clk.sh
```{bash}

#!/bin/bash
#SBATCH -C clk
#SBATCH -J provean_parallel_remaining
#SBATCH -o provean_parallel_remaining.%A.chunk_%a.out
#SBATCH -t 168:00:00              # Run time (hh:mm:ss)
#SBATCH -c 4
#SBATCH --mem-per-cpu=20GB
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
module load gcccore/system provean/1.1.5

#Retrieve files:
FILENAME=$1
echo "Running provean; chunk number" ${SLURM_ARRAY_TASK_ID}
TOTAL=$(wc -l < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt})
COUNTER=0

while read -r GENE; do
#  if [ ! -f provean_output/${GENE}.provean ]
#    then
    echo "Processing gene $GENE"
    /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/provean.sh --num_threads $SLURM_CPUS_PER_TASK -q genes_fasta/"$GENE".fa -v genes_variants/"$GENE".var --save_supporting_set genes_support/"$GENE".sss > provean_output/"$GENE".provean
#    else
#    echo "$GENE already processed"
#  fi
  ((COUNTER++))
  if [ $(( $COUNTER % 10 )) == 0 ]
    then
    echo "Processed $COUNTER genes out of $TOTAL"
  fi
  done < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt}

```

#####Send the array-jobs:
######clk nodes:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
START=1 #Introduce the first chunk (same as in the "Choose chunks" section).
END=10 #Introduce the last chunk (same as in the "Choose chunks" section).
PARALLEL=20 #define the desired value:

sbatch --array=1-$PARALLEL /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/parallel_provean_remaining_clk.sh gene_list.chunk_${START}_to_chunk_${END}.remaining.txt

```

####Retrieve again unfinished genes and launch them (N=20):
#####Choose chunks:
```{bash}

#Once all chunks of a particular job have finished, run this script to retrieve the list of genes which could not be processed before the queue finished, and group them in new input blocks:

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
JOB_ID=1457429 #Introduce the finished job id.
START=1 #Introduce the first chunk.
END=20 #Introduce the last chunk.
PARALLEL=20 #define the number of new partitions.

#First remove incomplete genes:
rm provean_parallel_remaining.$JOB_ID.chunk_${START}_to_chunk_${END}.remaining.out
for ((i=START; i<=END; i++))
  do
  ls provean_parallel_remaining.$JOB_ID.chunk_${i}.out >> provean_parallel_remaining.$JOB_ID.chunk_${START}_to_chunk_${END}.remaining.out
  done

GENE_LISTS=$(cat provean_parallel_remaining.$JOB_ID.chunk_${START}_to_chunk_${END}.remaining.out)
for gene_list in ${GENE_LISTS[@]}
  do
  if grep -Eq "TIME LIMIT|CANCELLED" $gene_list; then
    INTERRUPTED_GENE=$(grep "Processing gene" $gene_list | tail -n1 | cut -d' ' -f3)
    echo "removing interrupted $INTERRUPTED_GENE.provean from $gene_list"
    #rm provean_output/$INTERRUPTED_GENE.provean
    fi
  done

#Then extract all unfinished genes:
rm gene_list_remaining.chunk_${START}_to_chunk_${END}.remaining.txt
  while read -r GENE
    do
    if [[ $(find "provean_output/${GENE}.provean" -mtime +100 -print) ]] || [ ! -f provean_output/${GENE}.provean ]
      then #if [ ! -f provean_output/${GENE}.provean ]
      echo $GENE
      echo ${GENE} >> gene_list_remaining.chunk_${START}_to_chunk_${END}.remaining.txt
    fi
    done < gene_list.txt

sed -i '/(/d' gene_list_remaining.chunk_${START}_to_chunk_${END}.remaining.txt #Remove the genes with parenthesis, which have been processed apart (see last Provean run in this script).

#And generate new partitions:
FILENAME=gene_list_remaining.chunk_${START}_to_chunk_${END}.remaining.txt
TOTAL=$(wc -l < $FILENAME)
BLOCK_SIZE=$(echo "scale=0; $TOTAL/$PARALLEL" | bc)
for ((i=1; i<PARALLEL; i++))
  do
  START=$((((i-1))*BLOCK_SIZE+1))
  echo $START
  END=$((BLOCK_SIZE*i))
  echo $END
  sed -n "${START},${END}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}
  done
START=$((((i-1))*BLOCK_SIZE+1))
echo $START
echo $TOTAL
sed -n "${START},${TOTAL}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}

```

#####Scripts:
######clk nodes: parallel_provean_remaining_remaining_clk.sh
```{bash}

#!/bin/bash
#SBATCH -C clk
#SBATCH -J provean_parallel_remaining_remaining
#SBATCH -o provean_parallel_remaining_remaining.%A.chunk_%a.out
#SBATCH -t 168:00:00              # Run time (hh:mm:ss)
#SBATCH -c 10
#SBATCH --mem-per-cpu=10GB
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
module load gcccore/system provean/1.1.5

#Retrieve files:
FILENAME=$1
echo "Running provean; chunk number" ${SLURM_ARRAY_TASK_ID}
TOTAL=$(wc -l < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt})
COUNTER=0

while read -r GENE; do
if [[ $(find "provean_output/${GENE}.provean" -mtime +100 2>/dev/null) ]] || [ ! -f provean_output/${GENE}.provean ]
    then
    echo "Processing gene $GENE"
    /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/provean.sh --num_threads $SLURM_CPUS_PER_TASK -q genes_fasta/"$GENE".fa -v genes_variants/"$GENE".var --save_supporting_set genes_support/"$GENE".sss > provean_output/"$GENE".provean
    else
    echo "$GENE already processed"
  fi
  ((COUNTER++))
  if [ $(( $COUNTER % 10 )) == 0 ]
    then
    echo "Processed $COUNTER genes out of $TOTAL"
  fi
  done < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt}

```

#####Send the array-jobs:
######clk nodes:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
START=1 #Introduce the first chunk (same as in the "Choose chunks" section).
END=20 #Introduce the last chunk (same as in the "Choose chunks" section).
PARALLEL=20 #define the desired value:

sbatch --array=1-$PARALLEL /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/parallel_provean_remaining_remaining_clk.sh gene_list_remaining.chunk_${START}_to_chunk_${END}.remaining.txt

```

###Parallel runs (N=10) of all genes in reverse order:
####Choose the partition number:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
PARALLEL=10 #define the desired value, and the script will do the rest

FILENAME=gene_list.txt
FILELIST=$(ls -v ${FILENAME/.txt/.chunk_*.txt} | grep -v 'remaining')
for FILE in ${FILELIST[@]}
  do
  tac $FILE > ${FILE/.chunk/.rev_chunk}
  done

```

####Scripts:
#####clk nodes: parallel_provean_remaining_rev_clk.sh
```{bash}

#!/bin/bash
#SBATCH -C clk
#SBATCH -J provean_parallel_rev
#SBATCH -o provean_parallel_rev.%A.chunk_%a.out
#SBATCH -t 168:00:00              # Run time (hh:mm:ss)
#SBATCH -c 10
#SBATCH --mem-per-cpu=10GB
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
module load gcccore/system provean/1.1.5

#Retrieve files:
FILENAME=$1
echo "Running provean; chunk number" ${SLURM_ARRAY_TASK_ID}
TOTAL=$(wc -l < ${FILENAME/.txt/.rev_chunk_${SLURM_ARRAY_TASK_ID}.txt})
COUNTER=0

while read -r GENE; do
if [[ $(find "provean_output/${GENE}.provean" -mtime +100 2>/dev/null) ]] || [ ! -f provean_output/${GENE}.provean ]
    then
    echo "Processing gene $GENE"
    /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/provean.sh --num_threads $SLURM_CPUS_PER_TASK -q genes_fasta/"$GENE".fa -v genes_variants/"$GENE".var --save_supporting_set genes_support/"$GENE".sss > provean_output/"$GENE".provean
    else
    echo "$GENE already processed"
  fi
  ((COUNTER++))
  if [ $(( $COUNTER % 10 )) == 0 ]
    then
    echo "Processed $COUNTER genes out of $TOTAL"
  fi
  done < ${FILENAME/.txt/.rev_chunk_${SLURM_ARRAY_TASK_ID}.txt}

```

####Send the array-jobs:
#####clk nodes:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
START=1 #Introduce the first chunk (same as in the "Choose chunks" section).
END=10 #Introduce the last chunk (same as in the "Choose chunks" section).
PARALLEL=10 #define the desired value:

sbatch --array=1-$PARALLEL /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/parallel_provean_remaining_rev_clk.sh gene_list.txt

#sbatch --array=10,20 /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/parallel_provean_remaining_thin.sh gene_list.txt #For listing specific chunks, use a comma.

```

####Remove incomplete genes:
```{bash}

cd /mnt/lustre/scratch/home/uvi/bg/dkr/provean_annotation
JOB_ID=1457429 #Introduce the finished job id.
START=1 #Introduce the first chunk.
END=20 #Introduce the last chunk.

rm provean_parallel_remaining.$JOB_ID.chunk_${START}_to_chunk_${END}.out
for ((i=START; i<=END; i++))
  do
  ls provean_parallel_remaining.$JOB_ID.chunk_${i}.out >> provean_parallel_remaining.$JOB_ID.chunk_${START}_to_chunk_${END}.out
  done

GENE_LISTS=$(cat provean_parallel_remaining.$JOB_ID.chunk_${START}_to_chunk_${END}.out)
for gene_list in ${GENE_LISTS[@]}
  do
  if grep -Eq "TIME LIMIT|CANCELLED" $gene_list
    then
    INTERRUPTED_GENE=$(grep "Processing gene" $gene_list | tail -n1 | cut -d' ' -f3)
    echo "removing interrupted $INTERRUPTED_GENE.provean from $gene_list"
    rm provean_output/$INTERRUPTED_GENE.provean
  fi
  done

```

###Single run of genes with parentheses in their names:
####Generate the input file:
```{bash}

#Although I fixed all gene names in the fasta folder, the input list for provean comes from another source which doesn't have them fixed, so genes with parenthesis are failing in the parallel runs. Here I'll launch another process for those genes:

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
grep "(" gene_list.txt | sed -e 's/(/_/g;s/)/_/g;s/\[//g;s/\]//g' > parentheses_gene_list.txt

```

####Scripts:
#####clk nodes: onethread_provean.sh
```{bash}

#!/bin/bash
#SBATCH -C clk
#SBATCH -J provean_onethread
#SBATCH -o provean_onethread.%A.out
#SBATCH -t 168:00:00              # Run time (hh:mm:ss)
#SBATCH -c 10
#SBATCH --mem-per-cpu=10GB
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
module load gcccore/system provean/1.1.5

#Retrieve files:
FILENAME=$1
echo "Running provean"
TOTAL=$(wc -l < ${FILENAME})
COUNTER=0

while read -r GENE; do
  echo "Processing gene $GENE"
  rm provean_output/"$GENE".provean
  /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/provean.sh --num_threads $SLURM_CPUS_PER_TASK -q genes_fasta/"$GENE".fa -v genes_variants/"$GENE".var --save_supporting_set genes_support/"$GENE".sss > provean_output/"$GENE".provean
  ((COUNTER++))
  if [ $(( $COUNTER % 10 )) == 0 ]
    then
    echo "Processed $COUNTER genes out of $TOTAL"
  fi
  done < ${FILENAME}

```

####Send the array-jobs:
#####clk nodes:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

sbatch /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/onethread_provean.sh parentheses_gene_list.txt

```

###Triple run of genes with psiblast error codes:
####Generate the input file and choose chunks:
```{bash}

#Gather genes which have produced a "failed" or "error" code when running on Provean. Here we'll try to process them once again, but with more resources.
PARALLEL=3

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
grep -i -B 1 -Ew 'failed|error' *out | grep -w "gene" | cut -d' ' -f3 | sort -u > error_gene_list.txt

while read -r GENE; do
  echo $GENE
  rm provean_output/"$GENE".provean
done < error_gene_list.txt

FILENAME=error_gene_list.txt
TOTAL=$(wc -l < $FILENAME)
BLOCK_SIZE=$(echo "scale=0; $TOTAL/$PARALLEL" | bc)
for ((i=1; i<PARALLEL; i++))
  do
  START=$((((i-1))*BLOCK_SIZE+1))
  echo $START
  END=$((BLOCK_SIZE*i))
  echo $END
  sed -n "${START},${END}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}
  done
START=$((((i-1))*BLOCK_SIZE+1))
echo $START
echo $TOTAL
sed -n "${START},${TOTAL}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}

```

####Scripts:
#####clk nodes: parallel_provean_error_genes_clk.sh
```{bash}

#!/bin/bash
#SBATCH -C clk
#SBATCH -J parallel_provean_error_genes
#SBATCH -o parallel_provean_error_genes.%A.chunk_%a.out
#SBATCH -t 168:00:00              # Run time (hh:mm:ss)
#SBATCH -c 16
#SBATCH --mem-per-cpu=10GB
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
module load gcccore/system provean/1.1.5

#Retrieve files:
FILENAME=$1
echo "Running provean; chunk number" ${SLURM_ARRAY_TASK_ID}
TOTAL=$(wc -l < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt})
COUNTER=0

while read -r GENE; do
if [[ $(find "provean_output/${GENE}.provean" -mtime +100 2>/dev/null) ]] || [ ! -f provean_output/${GENE}.provean ]
    then
    echo "Processing gene $GENE"
    /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/provean.sh --num_threads $SLURM_CPUS_PER_TASK -q genes_fasta/"$GENE".fa -v genes_variants/"$GENE".var --save_supporting_set genes_support/"$GENE".sss > provean_output/"$GENE".provean
    else
    echo "$GENE already processed"
  fi
  ((COUNTER++))
  if [ $(( $COUNTER % 10 )) == 0 ]
    then
    echo "Processed $COUNTER genes out of $TOTAL"
  fi
  done < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt}

```

####Send the array-jobs:
#####clk nodes:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
PARALLEL=3 #define the desired value:

sbatch --array=1-$PARALLEL /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/parallel_provean_error_genes_clk.sh error_gene_list.txt

```

###Calculate average time:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/provean_output
rm duration.txt
for file in $(find *.provean -mtime -100)
  do
  if grep -q SCORE $file; then
    #echo $file
    START=$(grep "\[" $file | head -n1 | awk -F'\\[|\\]' '{print $2}')
    FINISH=$(grep "\[" $file | tail -n1 | awk -F'\\[|\\]' '{print $2}')
    if [[ $FINISH > $START ]]
      then
      DURATION=$(( $(date -d "$FINISH" "+%s") - $(date -d "$START" "+%s") ))
      else
      DURATION=$(( $(date -d "$FINISH" "+%s") + 86400 - $(date -d "$START" "+%s") ))
      if [[ $DURATION < 0 ]]
        then
        DURATION=$(($DURATION + 86400))
      fi
    fi
    echo -e "${file/.provean/}\t$DURATION" >> duration.txt
  fi
  done

echo "$(find *.provean -mtime -100 | wc -l) genes have been or are being processed"
N_GENES_RAW=$(wc -l < duration.txt)
echo "$N_GENES_RAW genes have been processed"

#Remove negative values (due to day change) since they are the result of bad calculation:
#awk -F"\t" '{OFS = FS} { sub(/-./,"", $2); print }' duration.txt > duration_fixed.txt
#awk -F"\t" '{OFS = FS} !($2 ~ /-/) { print }' duration.txt > duration_fixed.txt
#mv duration_fixed.txt duration.txt

N_GENES=$(wc -l < duration.txt)
echo "calculating average using $N_GENES genes"
SUM=$(cut -f2 duration.txt | paste -sd+ | bc)
AVERAGE_DURATION_SECS=$(echo "scale=6; $SUM/$N_GENES" | bc)
echo "average seconds per gene equals $AVERAGE_DURATION_SECS, and average minutes per gene equals:"
echo "scale=6; $AVERAGE_DURATION_SECS/60" | bc

```

###Check whether files have been correctly processed:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/
GENES=$(cat gene_list.txt) #define file with the list of genes to check.
for GENE in ${GENES[@]}
  do
  if [ ! -f provean_output/${GENE}.provean ]
    then echo "$GENE NOT PROCESSED YET *************"
    else 
      if grep -q "PROVEAN scores" provean_output/${GENE}.provean
        then echo $GENE "done"
      elif grep -q "No variations entered" provean_output/${GENE}.provean
        then echo $GENE "no valid variation ***"
        else echo $GENE "processing or interrupted ***************************************"
      fi
  fi
  done

#CG12426 seems to be the only gene which remains interrupted, so I'll launch it locally.

```

##Process the Provean output and separate tolerated from deleterious.
```{bash}

#From the cluster:
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean
VCF=/share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf
grep '^#' $VCF > pools_individuals_nonsynonymous.vcf
grep -e 'refGene=exonic;.*nonsynonymous' $VCF >> pools_individuals_nonsynonymous.vcf #66610
scp pools_individuals_nonsynonymous.vcf uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

#From CESGA:
module load bedtools/2.30.0 

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
VCF=pools_individuals_nonsynonymous.vcf #66610
sort -f -k3,3 -k5,5 pools_individuals_nonsynonymous_gene_names.txt > pools_individuals_nonsynonymous_gene_names.gene_aa_sorted.txt

#Combine info for each gene and mutation:
rm missense_variants_provean_scores.gene_aa_sorted.txt
COUNTER=0
GENE_LIST=$(ls provean_output/*.provean | awk -F "/|\\\\.provean" '{print $2}')
TOTAL=$(ls provean_output/*.provean | wc -l)
for gen in ${GENE_LIST[@]}
  do
  echo "${gen}"
  join -i -1 5 -2 1 <(awk -v gene=$gen '$3==gene' pools_individuals_nonsynonymous_gene_names.gene_aa_sorted.txt) <(grep -Ev '#|\[' provean_output/"$gen".provean | sort -f -k1,1) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $2,$3,$4,$5,$1,$6)}' >> missense_variants_provean_scores.gene_aa_sorted.txt
  ((COUNTER++))
  if [ $(( $COUNTER % 100 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $TOTAL"
  fi
  done

#Combine the information for the new/changed mutations in this dataset, with the previously obtained information for the rest of mutations:
bedtools intersect -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b $VCF > missense_variants_provean_scores.new_ones.bed #5340 (new output)
bedtools subtract -a $VCF -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) | wc -l #61270 (positions in the VCF but not in the new output)
bedtools subtract -a $VCF -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -header | bedtools intersect -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b stdin > missense_variants_provean_scores.old_ones.bed #59696 (positions in the new VCF but not in the new output, which are also included in the old output)
cat missense_variants_provean_scores.new_ones.bed missense_variants_provean_scores.old_ones.bed | awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$3,$4,$5,$6,$7)}' | sort -k3,3 > missense_variants_provean_scores.gene_aa_sorted_complete.txt #65036 (which is the correct result of 5340 + 59696)

#If these numbers aren't clear, see the following sanity checks and explanations:

#Sanity checks:
##Inputs:
awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/pools_individuals_nonsynonymous_gene_names.txt | sort -k1,1 -k2,2n | uniq | wc -l #61965 (original input)
awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5)}' pools_individuals_nonsynonymous_gene_names.txt | sort -k1,1 -k2,2n | uniq | wc -l #5474 (new input)
bedtools intersect -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/pools_individuals_nonsynonymous_gene_names.txt | sort -k1,1 -k2,2n | uniq) -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5)}' pools_individuals_nonsynonymous_gene_names.txt | sort -k1,1 -k2,2n | uniq) | wc -l #90 (mutations in both, i.e., those with a polarisation change)
bedtools subtract -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/pools_individuals_nonsynonymous_gene_names.txt | sort -k1,1 -k2,2n | uniq) -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5)}' pools_individuals_nonsynonymous_gene_names.txt | sort -k1,1 -k2,2n | uniq) | wc -l #61875 (mutations in the old dataset which haven't been repeated in the new one)
bedtools subtract -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5)}' pools_individuals_nonsynonymous_gene_names.txt | sort -k1,1 -k2,2n | uniq) -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/pools_individuals_nonsynonymous_gene_names.txt | sort -k1,1 -k2,2n | uniq) | wc -l #5384 (mutations exclusive to the new dataset)
#So, in short, out of 5474 mutations in the Provean input of the original dataset, 90 were already in the old one (polarisation changes), while the remaining 5384 are new. Because Provean hasn't been able to process certain genes, the numbers in the output files should be a bit lower than these.

##Outputs:
awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq | wc -l #60509 (original output)
awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq | wc -l #5340 (new output)
bedtools intersect -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) | wc -l #87 (mutations in both, i.e., those with a polarisation change)
bedtools subtract -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) | wc -l #60422 (mutations in the old dataset which haven't been repeated in the new one)
bedtools subtract -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) | wc -l #5253 (mutations exclusive to the new dataset)
#So, in short, out of 5340 mutations in the Provean output of the original dataset, 87 were already in the old one (polarisation changes), while the remaining 5253 are new.

#All sites in the new output, plus all sites in the old output except for those in the new one.
cat <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) <(bedtools subtract -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq)) | sort -k1,1 -k2,2n | uniq > missense_variants_provean_scores.gene_aa_sorted.new_plus_old_not_in_new.txt #65762
#Now remove those sites which are no longer in the new VCF (due to different filtering, etc.):
bedtools intersect -a missense_variants_provean_scores.gene_aa_sorted.new_plus_old_not_in_new.txt -b $VCF > missense_variants_provean_scores.gene_aa_sorted.new_plus_old_not_in_new.filtered_by_vcf.bed #65036

#All sites in the old output except for those in the new one:
bedtools subtract -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) | wc -l #60422
#All sites in the old output except for those in the new one, which are also included in the new VCF (some sites from the old dataset were dropped from the new VCF due to filters, etc.):
bedtools intersect -a <(bedtools subtract -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq)) -b $VCF | wc -l #59696

#Thus, the final output has 59696 sites which remain unchanged from the old output, plus 5340 sites in the new output, from which 5253 are completely new, and 87 have had a polarisation change.

#Now let's repat the process for the genes with parentheses in their names, which weren't included neither in the old dataset nor in the new one so far:
#Combine info for each gene and mutation:
rm /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.parentheses_gene_aa_sorted.txt
rm missense_variants_provean_scores.parentheses_gene_aa_sorted.txt
COUNTER=0
GENE_LIST=$(cat <(cut -f3 pools_individuals_nonsynonymous_gene_names.gene_aa_sorted.txt | grep "(" | sort | uniq) <(cut -f3 /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/pools_individuals_nonsynonymous_gene_names.gene_aa_sorted.txt | grep "(" | sort | uniq))
TOTAL=$(echo "${GENE_LIST}" | wc -l)
for gen in ${GENE_LIST[@]}
  do
  gen_bis=$(echo "${gen}" | tr '()' '__')
  #Old dataset:
  join -i -1 5 -2 1 <(awk -v gene=$gen '$3==gene' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/pools_individuals_nonsynonymous_gene_names.gene_aa_sorted.txt) <(grep -Ev '#|\[' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/provean_output/"$gen_bis".provean | sort -f -k1,1) | awk -v gene=$gen_bis '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $2,$3,gene,$5,$1,$6)}' >> /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.parentheses_gene_aa_sorted.txt
  #New dataset:
  join -i -1 5 -2 1 <(awk -v gene=$gen '$3==gene' pools_individuals_nonsynonymous_gene_names.gene_aa_sorted.txt) <(grep -Ev '#|\[' provean_output/"$gen_bis".provean | sort -f -k1,1) | awk -v gene=$gen_bis '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $2,$3,gene,$5,$1,$6)}' >> missense_variants_provean_scores.parentheses_gene_aa_sorted.txt
  ((COUNTER++))
  if [ $(( $COUNTER % 10 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $TOTAL"
  fi
  done

sort -k1,1 -k2,2n /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.parentheses_gene_aa_sorted.txt | uniq | awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' > /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.parentheses_gene_aa_sorted.bed #692
sort -k1,1 -k2,2n missense_variants_provean_scores.parentheses_gene_aa_sorted.txt | uniq | awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' > missense_variants_provean_scores.parentheses_gene_aa_sorted.bed #65

#All sites in the new output, plus all sites in the old output except for those in the new one.
cat missense_variants_provean_scores.parentheses_gene_aa_sorted.bed <(bedtools subtract -a /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.parentheses_gene_aa_sorted.bed -b missense_variants_provean_scores.parentheses_gene_aa_sorted.bed) | sort -k1,1 -k2,2n | uniq > missense_variants_provean_scores.parentheses_gene_aa_sorted.new_plus_old_not_in_new.bed #756
#Now remove those sites which are no longer in the new VCF (due to different filtering, etc.):
bedtools intersect -a missense_variants_provean_scores.parentheses_gene_aa_sorted.new_plus_old_not_in_new.bed -b $VCF > missense_variants_provean_scores.parentheses_gene_aa_sorted.new_plus_old_not_in_new.filtered_by_vcf.bed #750

cat missense_variants_provean_scores.gene_aa_sorted.new_plus_old_not_in_new.filtered_by_vcf.bed missense_variants_provean_scores.parentheses_gene_aa_sorted.new_plus_old_not_in_new.filtered_by_vcf.bed | sort -k1,1 -k2,2n | uniq > missense_variants_provean_scores.gene_aa_sorted.new_plus_old_not_in_new.filtered_by_vcf.complete.bed #65786

THRESHOLD=-2.5
awk -F"\t" -v thres=$THRESHOLD '$7 <= thres {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$7)}' missense_variants_provean_scores.gene_aa_sorted.new_plus_old_not_in_new.filtered_by_vcf.complete.bed | bedtools sort > missense_variants_provean_scores_deleterious.bed #11897 (18.1% of the total 65786)
awk -F"\t" -v thres=$THRESHOLD '$7 > thres {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$7)}' missense_variants_provean_scores.gene_aa_sorted.new_plus_old_not_in_new.filtered_by_vcf.complete.bed | bedtools sort > missense_variants_provean_scores_tolerated.bed #53889 (81.9% of the total 65786)

```

##Check how many missense mutations have Provean results:
```{bash}

module load bedtools/2.30.0
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5)}' pools_individuals_nonsynonymous_gene_names.txt | sort -k1,1 -k2,2n | uniq | wc -l #5474 (new) unique mutations in the input

awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq | wc -l #5340 (new) unique mutations in the output

#Mutations which were in the Provean input but not the output:
bedtools subtract -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5)}' pools_individuals_nonsynonymous_gene_names.txt | sort -k1,1 -k2,2n | uniq) -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) > pools_individuals_nonsynonymous_gene_names.unprocessed.txt #134 unprocessed or unretrieved mutations, which is the correct result for 5474 - 5340

#Mutations which were in the Provean output but not the input:
bedtools subtract -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5)}' pools_individuals_nonsynonymous_gene_names.txt | sort -k1,1 -k2,2n | uniq) | wc -l #0 artifacts

```

#9. Carry out 4-fold annotation.
##Prepare list of genes with synonymous mutations.
```{bash}

cd /share/rdata/ramon.pouso/4fold

rm pools_gen0-140_synonymous_vcf.txt
VCF="/share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf"

#Extract list of sites which are annotated as synonymous:
grep -e ';ExonicFunc.refGene=synonymous' $VCF >> pools_gen0-140_synonymous_vcf.txt

#Generate list with coordinates, gene and transcript names, and nucleotid changes:
awk -F"\t|;AAChange.refGene=|;ALLELE_END" '{printf ("%s\t%s\t%s\n", $1,$2,$9)}' pools_gen0-140_synonymous_vcf.txt | awk -F"\t|:|," '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$6)}' | awk -F"\t" '{OFS = FS} { gsub(/c\./,"", $5); print }' | grep -v "RNA" | sort -k3,3 -k1,1 -k2,2n > pools_gen0-140_synonymous_gene_names.txt

#Sanity checks:
cut -f3 pools_gen0-140_synonymous_gene_names.txt | sort -u | wc -l #12117 genes (3 less than in the previous dataset, because new genes that have been included due to the different polarisation are compensated by the exclusion of chr4 for this dataset)
cut -f4 pools_gen0-140_synonymous_gene_names.txt | sort -u | wc -l #12117 transcripts
#If the number of unique gene names and transcript names is the same, the script worked. In a previous version both numbers were different, which allowed me to discover that some genes with parenthesis in their names were introducing bugs. I modified the code to the current version, and now everything checks.

```

##Retrieve the whole nucleotide sequence.
```{bash}

cd /share/rdata/ramon.pouso/4fold

#First generate a more readable version of the non-redundant annotation file, which keeps only necessary data, and transforms coordinates from 1-based (GTF format) to 0-based (BED format):
#awk -F'\t|gene_id \"|"; transcript_id |; exon_id "|"; gene_name' '($1 == "chr2L" || $1 == "chr2R" || $1 == "chr3L" || $1 == "chr3R" || $1 == "chr4" || $1 == "chrX") && $3=="CDS" {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n"),$1,$4-1,$5,$7,$8,$10,$12}' /share/rdata/ramon.pouso/reference/indexed_reference/dm6nr.refGene.gtf > dm6nr.refGene.txt

#Then cross it with the list of genes with synonymous variants to obtain coordinates for all CDS from all genes of interest. I tried to do it faster using grep -Fwf but some genes have special characters (such as "-") which are not considered part of a word, so it introduces some mistakes. So it's best to use this loop instead:
GENES=$(cat pools_gen0-140_synonymous_gene_names.txt | cut -f 3 | sort -u)
COUNTER=0
rm pools_gen0-140_synonymous.cds_list.dm6nr.refGene.txt
for gen in ${GENES[@]}
  do
  #echo "${gen}"
  awk -v gene_name=$gen '$6 == gene_name' dm6nr.refGene.txt >> pools_gen0-140_synonymous.cds_list.dm6nr.refGene.txt
  ((COUNTER++))
  if [ $(( $COUNTER % 100 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $(echo "$GENES" | wc -l)"
  fi
  done
awk -F"\t" '{OFS = FS} { gsub(/chr/,"", $1); print }' pools_gen0-140_synonymous.cds_list.dm6nr.refGene.txt > pools_gen0-140_synonymous.cds_list.dm6nr.refGene.bed #Remove the "chr" from the chromosome names to convert them into the same format that the fasta uses.

  ##Sanity checks:
  cut -f6 pools_gen0-140_synonymous.cds_list.dm6nr.refGene.bed | uniq | wc -l #11997 genes instead of the 12117 found in pools_gen0-140_synonymous_gene_names.txt because some of the genes in the annovar database are not included in the UCSC .gtf file. 
  comm -3 <(cut -f3 pools_gen0-140_synonymous_gene_names.txt | sort -u) <(cut -f6 pools_gen0-140_synonymous.cds_list.dm6nr.refGene.bed | sort -u) | wc -l #120, which is the correct result of 12117-11997 
  comm -3 <(cut -f3 pools_gen0-140_synonymous_gene_names.txt | sort -u) <(cut -f6 pools_gen0-140_synonymous.cds_list.dm6nr.refGene.bed | sort -u) | less -S #All results are displayed in the first column, which means that all missing entries are missing in the second file, and none from the second file are missing in the first one.

#Retrieve reference sequences for all CDS (from the ancestral fasta to account for polarisation).
module load gcc/7.2.0
module add gcc/7.2.0
bedtools getfasta -fi /share/rdata/ramon.pouso/reference/indexed_reference/ancestral_dmel-all-chromosome-r6.14.fa -bed pools_gen0-140_synonymous.cds_list.dm6nr.refGene.bed -fo pools_gen0-140_synonymous.cds_sequence.fa

  ##Sanity checks:
  grep -v '>' pools_gen0-140_synonymous.cds_sequence.fa | wc -l #48418, which is the same number of CDS (lines) in the file pools_gen0-140_synonymous.cds_list.dm6nr.refGene.bed.

#Paste each CDS' sequence with the rest of the information.
paste pools_gen0-140_synonymous.cds_list.dm6nr.refGene.bed <(grep -v '>' pools_gen0-140_synonymous.cds_sequence.fa) > pools_gen0-140_synonymous.cds_list_and_sequence.dm6nr.refGene.bed

  ##Sanity checks:
  awk '{printf ("%s\t%s\n"),$3-$2,length($8)}' pools_gen0-140_synonymous.cds_list_and_sequence.dm6nr.refGene.bed | awk '$1==$2' | wc -l #48418, which means that all retrieved sequences have the correct length (the same as the difference between their start and their end points).

#Fuse all exons from each gene and store them in a file together with the gene name and the strand information.
GENES=$(cat pools_gen0-140_synonymous.cds_list_and_sequence.dm6nr.refGene.bed | cut -f 6 | sort -u)
TOTAL=$(echo "$GENES" | wc -l)
COUNTER=0
rm pools_gen0-140_synonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed
for gen in ${GENES[@]}
  do
  #echo "${gen}"
  STRAND=$(awk -F"\t" -v gen=$gen '$6 == gen' pools_gen0-140_synonymous.cds_list_and_sequence.dm6nr.refGene.bed | shuf -n1 | cut -f 4)
  CODING_SEQUENCE=$(awk -F"\t" -v gen=$gen '$6 == gen {print $8}' pools_gen0-140_synonymous.cds_list_and_sequence.dm6nr.refGene.bed | tr -d '\n')
  echo -e "$gen\t$STRAND\t$CODING_SEQUENCE" >> pools_gen0-140_synonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed
  ((COUNTER++))
  if [ $(( $COUNTER % 50 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $(echo "$GENES" | wc -l)"
  fi
  done

```

##Retrieve codons:
```{bash}

cd /share/rdata/ramon.pouso/4fold

#First join the synonymous variants and the gene information:
join -1 3 -2 1 <(sort -k3,3 pools_gen0-140_synonymous_gene_names.txt) pools_gen0-140_synonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $2, $3-1, $3, $1, $4, $6, $5, $7)}' > pools_gen0-140_synonymous.cds_list_and_sequence_combined.complete_info.dm6nr.refGene.bed #170325

#Then for each variant retrieve the codon it belongs to:
rm pools_gen0-140_synonymous.cds_list_and_sequence_combined.codons.dm6nr.refGene.bed
TOTAL=$(cat pools_gen0-140_synonymous.cds_list_and_sequence_combined.complete_info.dm6nr.refGene.bed | wc -l)
COUNTER=0
while read -r CHR START END GENE TRANSCRIPT STRAND SNP_CHANGE SEQUENCE; do
  SNP=$(echo "${SNP_CHANGE:1:${#SNP_CHANGE}-2}")
  if [ $STRAND == "+" ]
    then
    if [ $(( $SNP % 3 )) == 0 ]
      then 
      OLD_CODON=$(echo $SEQUENCE | cut -c$(($SNP-2))-$SNP)
      NEW_CODON=$(echo "${OLD_CODON:0:2}${SNP_CHANGE: -1}")
    elif [ $(( $SNP % 3 )) == 2 ]
      then 
      OLD_CODON=$(echo $SEQUENCE | cut -c$(($SNP-1))-$(($SNP+1)))
      NEW_CODON=$(echo "${OLD_CODON:0:1}${SNP_CHANGE: -1}${OLD_CODON:2:3}")
    elif [ $(( $SNP % 3 )) == 1 ]
      then 
      OLD_CODON=$(echo $SEQUENCE | cut -c$SNP-$(($SNP+2)))
      NEW_CODON=$(echo "${SNP_CHANGE: -1}${OLD_CODON:1:3}")
    fi
  elif [ $STRAND == "-" ]
    then
    REVERSE_SEQUENCE=$(echo $SEQUENCE | tr ACGT TGCA | rev) #this code obtains the reverse complementary sequence
    if [ $(( $SNP % 3 )) == 0 ]
      then 
      OLD_CODON=$(echo $REVERSE_SEQUENCE | cut -c$(($SNP-2))-$SNP)
      NEW_CODON=$(echo "${OLD_CODON:0:2}${SNP_CHANGE: -1}")
    elif [ $(( $SNP % 3 )) == 2 ]
      then 
      OLD_CODON=$(echo $REVERSE_SEQUENCE | cut -c$(($SNP-1))-$(($SNP+1)))
      NEW_CODON=$(echo "${OLD_CODON:0:1}${SNP_CHANGE: -1}${OLD_CODON:2:3}")
    elif [ $(( $SNP % 3 )) == 1 ]
      then 
      OLD_CODON=$(echo $REVERSE_SEQUENCE | cut -c$SNP-$(($SNP+2)))
      NEW_CODON=$(echo "${SNP_CHANGE: -1}${OLD_CODON:1:3}")
    fi
  fi
  echo -e "$CHR\t$START\t$END\t$GENE\t$TRANSCRIPT\t$STRAND\t$SNP_CHANGE\t$OLD_CODON\t$NEW_CODON" >> pools_gen0-140_synonymous.cds_list_and_sequence_combined.codons.dm6nr.refGene.bed
  ((COUNTER++))
  if [ $(( $COUNTER % 1000 )) == 0 ]
    then
    echo "processed $COUNTER SNPs out of" $TOTAL
  fi
done < pools_gen0-140_synonymous.cds_list_and_sequence_combined.complete_info.dm6nr.refGene.bed

```

##Extract 4-fold degenerate codons:
```{bash}

cd /share/rdata/ramon.pouso/4fold

#First, save the list of 4-fold degenerate codons (obtained from https://github.com/seenstevo/Four-fold_degenerate_bedmaker/blob/master/FFDS_bedmaker.py) to a file:
echo "CTT","CTA","CTG","CTC","GTT","GTC","GTA","GTG","TCT","TCC","TCA","TCG","CCT","CCC","CCA","CCG","ACT","ACC","ACA","ACG","GCT","GCC","GCA","GCG","CGT","CGC","CGA","CGG","GGT","GGC","GGA","GGG" | tr ',' '\n' > 4fold_codons.txt

#Then filter the file obtained in the previous section, which contains the codon for each variant in the dataset, and filter in only those which are 4-fold degenerate (i.e., those from the 4fold file which appear both in column 8 and column 9).
awk 'NR==FNR { A[$1]=1 ; next }; ($8 in A && $9 in A) { print }' 4fold_codons.txt pools_gen0-140_synonymous.cds_list_and_sequence_combined.codons.dm6nr.refGene.bed > pools_gen0-140_synonymous.cds_list_and_sequence_combined.4fold_codons.dm6nr.refGene.bed

cut -f-4 pools_gen0-140_synonymous.cds_list_and_sequence_combined.4fold_codons.dm6nr.refGene.bed > pools_gen0-140_synonymous_variants_4fold.bed #96846

#Note:
cut -f9 pools_gen0-140_synonymous.cds_list_and_sequence_combined.codons.dm6nr.refGene.bed | sort -u #this reveals that there are single-letter new codons, and (see next line)...
cut -f8 pools_gen0-140_synonymous.cds_list_and_sequence_combined.codons.dm6nr.refGene.bed | sort -u #this reveals that there are empty old codons.
#After analysing this up-stream, I concluded that these aren't due to an error in these sections' code. Instead, they owe to ANNOVAR using the transcripts instead of the CDS for its annotation procedures, which results in "empty" old codons (those after the stop codon) being replaced by the single SNP change that appears in the VCF. Fortunately this doesn't interfere in the identification of 4fold degenerate codons.

```

#10. Carry out recombination annotation.
##Copy and unzip the programmes.
```{bash}

#This section doesn't need to be repeated.

#From outside the server, copy to the server the two necessary programmes, which Humberto sent me by e-mail:

scp /Users/dani/Downloads/coordinates_converter.zip ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/recombination/
scp /Users/dani/Downloads/RRC2.zip ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/recombination/

#From inside the server, then unzip both files and their contents, and rename folders. This will be the path:
cd /share/rdata/ramon.pouso/recombination/

```

##Convert coordinates from the RRC files from dm5 to dm6:
```{bash}

#This section doesn't need to be repeated.

#Convert the RRC comeron coordinates to the format required by the coordinate converter:
cd /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables
mkdir -p dm5
mv Comeron_100kb_chr*.txt dm5
cd dm5
FILES=$(ls Comeron_100kb_chr*.txt | grep -v "chr4" | grep -v 'dm')
for file in ${FILES[@]}
  do
  echo $file
  FILENAME=$(echo $file | cut -d'_' -f3 | cut -d'.' -f1 | sed "s/chr//g")
  awk -v chr=$FILENAME '{printf ("%s:%s..%s\t%s\n",chr,$1,$1+99999,$2)}' <(head -n -1 $file) > ${file/.txt/.dm5.txt}
  awk -v chr=$FILENAME '{printf ("%s\t%s\t%s\t%s\n",chr,$1,$1+99999,$2)}' <(head -n -1 $file) > ${file/.txt/.dm5.bed}
  done

#Then save them in a file and use the following script to obtain the v5 to v6 conversion:
mkdir -p /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables/dm6
FILES=$(ls Comeron_100kb_chr*.txt | grep -v "chr4" | grep -v 'dm')
for file in ${FILES[@]}
  do
  echo ${file/.txt/.dm5.txt}
  new_name=$(echo ${file/.txt/.dm5_to_dm6.txt})
  cut -f1 ${file/.txt/.dm5.txt} | /share/rdata/ramon.pouso/recombination/coordinates_converter/bulkfile-scripts-master/dmel_r5_to_r6/dmel_r5_to_r6_converter.pl > /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables/dm6/$new_name
  grep -v '^#' /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables/dm6/$new_name | awk -F":|\\\\.\\\\.|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n",$1,$2,$3,$4,$5,$6)}' > /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables/dm6/${new_name/.txt/.bed}
  done

#Next use bedtools intersect to cross the file with old coordinates and recombination values with the file with both old and new coordinates:
cd /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables
module load gcc/7.2.0
module add gcc/7.2.0
FILES=$(ls dm5/Comeron_100kb_chr*.dm5.bed | grep -v "chr4" | cut -d'/' -f2)
for file in ${FILES[@]}
  do
  bedtools intersect -a dm5/$file -b dm6/${file/.dm5.bed/.dm5_to_dm6.bed} -wa -wb | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\n",$8,$9,$10,$4)}' > dm6/${file/.dm5.bed/.dm6.bed}
  cut -f2,4 dm6/${file/.dm5.bed/.dm6.bed} > ${file/.dm5.bed/.txt}
  done
cat dm6/Comeron_100kb_chr*.dm6.bed > dm6/Comeron_100kb_allchr.dm6.bed

#Later on I realised that there are 1-base gaps between all bins (because bedtools works with 0-based coordinates), so use this to fix it:
awk '{printf ("%s\t%s\t%s\t%s\n",$1,$2-1,$3,$4)}' dm6/Comeron_100kb_allchr.dm6.bed > dm6/Comeron_100kb_allchr.dm6.0based.bed

```

##Retrieve recombination value for each SNP:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants
module load gcc/7.2.0
module add gcc/7.2.0

FILE=crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.bed
bedtools intersect -a $FILE -b /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables/dm6/Comeron_100kb_allchr.dm6.0based.bed -wb | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\n",$1,$2,$3,$8)}' > ${FILE/.bed/.recombination.bed}

#Retrieve high recombination and low recombination quartiles.
TOTAL=$(wc -l < ${FILE/.bed/.recombination.bed})
QUARTILE=$((TOTAL/4))

shuf ${FILE/.bed/.recombination.bed} | sort -k4,4n | head -n$QUARTILE | sort -k1,1 -k2,2n > ${FILE/.bed/.low_recombination.bed}
shuf ${FILE/.bed/.recombination.bed} | sort -k4,4n | tail -n$QUARTILE | sort -k1,1 -k2,2n > ${FILE/.bed/.high_recombination.bed}

```

#11. Combine and import all annotations into the VCF.
##Process and combine SIFT and Provean output.
```{bash}

scp -p uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.gene_aa_sorted.new_plus_old_not_in_new.filtered_by_vcf.complete.bed /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean
scp -p uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores_tolerated.bed /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean
scp -p uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores_deleterious.bed /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean

module load gcc/7.2.0
module add gcc/7.2.0
#Both tolerated:
bedtools intersect -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean/missense_variants_provean_scores_tolerated.bed -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/gen0-140_all_sites_missense_variants_SIFT_scores_tolerated.bed | awk '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/missense_variants_provean_SIFT_tolerated.bed 
wc -l < /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/missense_variants_provean_SIFT_tolerated.bed #46120
#Both deleterious:
bedtools intersect -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean/missense_variants_provean_scores_deleterious.bed -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/gen0-140_all_sites_missense_variants_SIFT_scores_deleterious.bed | awk '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/missense_variants_provean_SIFT_deleterious.bed 
wc -l < /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/missense_variants_provean_SIFT_deleterious.bed #7786
#PROV tol, SIFT del:
bedtools intersect -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean/missense_variants_provean_scores_tolerated.bed -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/gen0-140_all_sites_missense_variants_SIFT_scores_deleterious.bed | wc -l #7598
#SIFT tol, PROV del:
bedtools intersect -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean/missense_variants_provean_scores_deleterious.bed -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/gen0-140_all_sites_missense_variants_SIFT_scores_tolerated.bed | wc -l #4084

```

##Import all annotations into the VCF.
```{bash}

module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/

VCF=crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf

rm ${VCF/vcf/custom_unsorted.vcf}
#Not fourfold (i.e. synonymous but not fourfold degenerate), which will be obtained first as the difference between all synonymous variants and the list of fourfold ones:
#grep -E '^#|ExonicFunc.refGene=synonymous_SNV;' $VCF | bedtools subtract -a stdin -b /share/rdata/ramon.pouso/4fold/pools_gen0-140_synonymous_variants_4fold.bed | awk '{printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' > /share/rdata/ramon.pouso/4fold/pools_gen0-140_synonymous_variants_NOT4fold.bed #this line doesn't need to be executed if the bed already exists.
bedtools intersect -a $VCF -b /share/rdata/ramon.pouso/4fold/pools_gen0-140_synonymous_variants_NOT4fold.bed | awk '{gsub("NP=44;","CUSTOM=non-fourfold;NP=44;"); print}' >> ${VCF/vcf/custom_unsorted.vcf}
#Fourfold:
bedtools intersect -a $VCF -b /share/rdata/ramon.pouso/4fold/pools_gen0-140_synonymous_variants_4fold.bed | awk '{gsub("NP=44;","CUSTOM=fourfold;NP=44;"); print}' >> ${VCF/vcf/custom_unsorted.vcf}
#Tolerated:
bedtools intersect -a $VCF -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/missense_variants_provean_SIFT_tolerated.bed | awk '{gsub("NP=44;","CUSTOM=tolerated;NP=44;"); print}' >> ${VCF/vcf/custom_unsorted.vcf}
#Deleterious:
bedtools intersect -a $VCF -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/missense_variants_provean_SIFT_deleterious.bed | awk '{gsub("NP=44;","CUSTOM=deleterious;NP=44;"); print}' >> ${VCF/vcf/custom_unsorted.vcf}
#LoF:
grep -E ';ExonicFunc.refGene=stopgain;|;ExonicFunc.refGene=stoploss;' $VCF | awk '{gsub("NP=44;","CUSTOM=LoF;NP=44;"); print}' >> ${VCF/vcf/custom_unsorted.vcf}

#Sort the VCF and add the headers:
cat <(grep "^#" $VCF) <(sort -k1,1 -k2,2n ${VCF/vcf/custom_unsorted.vcf}) > ${VCF/vcf/custom_complete.vcf}

```

#12. Split the VCFs at the pool level:
##Exclude AF=0:
###All sites:
```{R, engine='bash'}

mkdir -p /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

module load bcftools/1.9

VCF="/share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.vcf"
POOLS=$(bcftools query -l "${VCF}")
for p in ${POOLS[@]}
  do
  echo "${p}"
  #ID=$(echo "${p}")
  #POOL_NAME=$(echo "${p}")
  SAMPLE=$(echo "${p}" | cut -d'_' -f1 | sort | uniq)
  FIELD_NUMBER=$(grep "^#" $VCF | grep -v '##' | tr "\t" "\n" | grep -nw $p | cut -d':' -f1)
  if [[ "$SAMPLE" == "sample"* ]]
    then
    GEN=$(echo "${p}" | tr "_" "\n" | grep "gen")
    paste <(grep -v '^#' $VCF | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6,$7,$8)}') <(grep -v '^#' $VCF | cut -f$FIELD_NUMBER | awk -F":|," '{printf ("%s\t%s\n", $4+$6+$8,$5+$7+$9)}') | awk '$11 > 0' > "${SAMPLE}"_"${GEN}"_gen0-140_pool.txt
    else
    paste <(grep -v '^#' $VCF | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6,$7,$8)}') <(grep -v '^#' $VCF | cut -f$FIELD_NUMBER | awk -F":|," '{printf ("%s\t%s\n", $4+$6+$8,$5+$7+$9)}') | awk '$11 > 0' > "${SAMPLE}"_gen0-140_pool.txt
  fi
  done

mv LBT0_gen0-140_pool.txt LBT0_gen0_gen0-140_pool.txt
mv c1_gen0-140_pool.txt c1_gen5_gen0-140_pool.txt
mv BT20_gen0-140_pool.txt BT20_gen20_gen0-140_pool.txt
mv BT30_gen0-140_pool.txt BT30_gen30_gen0-140_pool.txt
mv c2_gen0-140_pool.txt c2_gen40_gen0-140_pool.txt
mv C1_gen0-140_pool.txt C1_gen140_gen0-140_pool.txt

#To rename all "provean_only" version of the files in order to not rewrite them, use:
#for pool in $(ls *_gen0-140_pool.txt); do echo $pool; mv $pool ${pool/_pool/_pool_provean_only}; done

```

###All sites (no custom annotation):
```{R, engine='bash'}

mkdir -p /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

module load bcftools/1.9

VCF="/share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf"
POOLS=$(bcftools query -l "${VCF}")
for p in ${POOLS[@]}
  do
  echo "${p}"
  #ID=$(echo "${p}")
  #POOL_NAME=$(echo "${p}")
  SAMPLE=$(echo "${p}" | cut -d'_' -f1 | sort | uniq)
  FIELD_NUMBER=$(grep "^#" $VCF | grep -v '##' | tr "\t" "\n" | grep -nw $p | cut -d':' -f1)
  if [[ "$SAMPLE" == "sample"* ]]
    then
    GEN=$(echo "${p}" | tr "_" "\n" | grep "gen")
    paste <(grep -v '^#' $VCF | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6,$7,$8)}') <(grep -v '^#' $VCF | cut -f$FIELD_NUMBER | awk -F":|," '{printf ("%s\t%s\n", $4+$6+$8,$5+$7+$9)}') | awk '$11 > 0' > "${SAMPLE}"_"${GEN}"_gen0-140_pool.nocustom.txt
    else
    paste <(grep -v '^#' $VCF | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6,$7,$8)}') <(grep -v '^#' $VCF | cut -f$FIELD_NUMBER | awk -F":|," '{printf ("%s\t%s\n", $4+$6+$8,$5+$7+$9)}') | awk '$11 > 0' > "${SAMPLE}"_gen0-140_pool.nocustom.txt
  fi
  done

mv LBT0_gen0-140_pool.nocustom.txt LBT0_gen0_gen0-140_pool.nocustom.txt
mv c1_gen0-140_pool.nocustom.txt c1_gen5_gen0-140_pool.nocustom.txt
mv BT20_gen0-140_pool.nocustom.txt BT20_gen20_gen0-140_pool.nocustom.txt
mv BT30_gen0-140_pool.nocustom.txt BT30_gen30_gen0-140_pool.nocustom.txt
mv c2_gen0-140_pool.nocustom.txt c2_gen40_gen0-140_pool.nocustom.txt
mv C1_gen0-140_pool.nocustom.txt C1_gen140_gen0-140_pool.nocustom.txt

#To rename all "provean_only" version of the files in order to not rewrite them, use:
#for pool in $(ls *_gen0-140_pool.txt); do echo $pool; mv $pool ${pool/_pool/_pool_provean_only}; done

```

###Low/High recombination sites:
```{R, engine='bash'}

REC="high" #low #high

module load gcc/7.2.0 
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

POOLS=$(ls *gen0-140_pool.txt)
for p in ${POOLS[@]}
  do
  echo "${p}"
  bedtools intersect -a ${p} -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.${REC}_recombination.bed > ${p/.txt/.${REC}_recombination.txt}
  done

#To rename all "provean_only" version of the files in order to not rewrite them, use:
#for pool in $(ls *gen0-140_pool*recombination.txt); do echo $pool; mv $pool ${pool/_pool/_pool_provean_only}; done

```

##Include AF=0:
```{R, engine='bash'}

mkdir -p /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

module load bcftools/1.9

VCF="/share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom.vcf"
POOLS=$(bcftools query -l "${VCF}")
for p in ${POOLS[@]}
  do
  echo "${p}"
  #ID=$(echo "${p}")
  #POOL_NAME=$(echo "${p}")
  SAMPLE=$(echo "${p}" | cut -d'_' -f1 | sort | uniq)
  FIELD_NUMBER=$(grep "^#" $VCF | grep -v '##' | tr "\t" "\n" | grep -nw $p | cut -d':' -f1)
  if [[ "$SAMPLE" == "sample"* ]]
    then
    GEN=$(echo "${p}" | tr "_" "\n" | grep "gen")
    paste <(grep -v '^#' $VCF | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6,$7,$8)}') <(grep -v '^#' $VCF | cut -f$FIELD_NUMBER | awk -F":|," '{printf ("%s\t%s\n", $4+$6+$8,$5+$7+$9)}') > "${SAMPLE}"_"${GEN}"_gen0-140_pool.all.txt
    else
    paste <(grep -v '^#' $VCF | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6,$7,$8)}') <(grep -v '^#' $VCF | cut -f$FIELD_NUMBER | awk -F":|," '{printf ("%s\t%s\n", $4+$6+$8,$5+$7+$9)}') > "${SAMPLE}"_gen0-140_pool.all.txt
  fi
  done

mv LBT0_gen0-140_pool.all.txt LBT0_gen0_gen0-140_pool.all.txt
mv c1_gen0-140_pool.all.txt c1_gen5_gen0-140_pool.all.txt
mv BT20_gen0-140_pool.all.txt BT20_gen20_gen0-140_pool.all.txt
mv BT30_gen0-140_pool.all.txt BT30_gen30_gen0-140_pool.all.txt
mv c2_gen0-140_pool.all.txt c2_gen40_gen0-140_pool.all.txt
mv C1_gen0-140_pool.all.txt C1_gen140_gen0-140_pool.all.txt

#To rename all "provean_only" version of the files in order to not rewrite them, use:
#for pool in $(ls *_gen0-140_pool.all.txt); do echo $pool; mv $pool ${pool/_pool/_pool_provean_only}; done

```

##Obtain depth distribution:
###Extract per site depth:
```{R, engine='bash'}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

rm all_samples_gen0-140_pool.all.depth_distribution.txt
POOLS=$(ls *gen0-140_pool.all.txt)
for p in ${POOLS[@]}
  do
  echo "${p}"
  SAMPLE=$(echo $p | cut -d'_' -f-2)
  grep -v "^X" "${p}" | awk -v sample="$SAMPLE" -F"\t" '{printf ("%s\t%s\n", $10+$11, sample)}' | sort -k1,1n | uniq -c >> all_samples_gen0-140_pool.all.depth_distribution.temp.txt
  done

#Remove leading white spaces and separate columns with tabs:
sed 's/^[ \t]*//' all_samples_gen0-140_pool.all.depth_distribution.temp.txt | sed 's/ /\t/g' > all_samples_gen0-140_pool.all.depth_distribution.txt && rm all_samples_gen0-140_pool.all.depth_distribution.temp.txt
  
#Download file:
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/all_samples_gen0-140_pool.all.depth_distribution.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

```

###Plot depth distribution:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))

depth_file <- read_tsv(paste0(wd_path,"all_samples_gen0-140_pool.all.depth_distribution.txt"), col_names=c("count","depth","pool"))

pools_depth_summary <- data_frame("pool"=character(0),"mean_depth"=character(0),"std_dev_depth"=character(0)) #next, create the empty dataframe
for (sample in unique(depth_file$pool)) {
  plot_data <- depth_file %>% filter(pool==sample)
  stats_data <- plot_data[rep(1:nrow(plot_data), plot_data$count),]
  row_data <- cbind(sample,mean(stats_data$depth),sd(stats_data$depth))
  colnames(row_data) <- c("pool","mean_depth","std_dev_depth")
  pools_depth_summary <- rbind(pools_depth_summary,row_data,stringsAsFactors=F)
  }
write_tsv(pools_depth_summary,paste0(wd_path,"pools_depth_summary.txt"))

plot_data <- depth_file %>% filter(pool=="sample1_gen40")
depth_distr_ggplot <- ggplot(data=plot_data, aes(depth,count)) +
#geom_histogram(aes(NM),binwidth=1) +
geom_col() +
#ggtitle(paste0("Depth distribution for ",pool)) +
ylab("count") +
#xlab("heritability") +
scale_x_continuous(breaks=seq(0,nrow(plot_data),2)) +
geom_vline(xintercept=sum(plot_data$depth * plot_data$count)/sum(plot_data$count)) +
theme_bw() +
theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_line(colour="black"),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=90, hjust=1),
      #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
      #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black"),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      #legend.key.size=unit(1.3,"cm"),
      legend.position=c(0.92,0.86),
      legend.title=element_blank()
)
depth_distr_ggplot
#ggsave(paste0(sample,"_NM_distribution.lr_ann.pdf"), width=20, height=20, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis_lcref/edit_distance_tests/")

```

#13. Retrieve counts.
##Total observed counts.
###Exclude AF=0 VCFs:
####Retrieve derived counts per category:
#####All sites:
```{R, engine='bash'}

REGION="autosomes" #all #autosomes #Xchr

#To rename all "provean_only" version of the files in order to not rewrite them, use:
#mv counts_pool_gen0-140_${REGION}_summary.txt counts_pool_gen0-140_${REGION}_summary.provean_only.txt
#for pool in $(ls *_gen0-140_pool_${REGION}.txt); do echo $pool; mv $pool ${pool/_pool/_pool_provean_only}; done

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
rm counts_pool_gen0-140_${REGION}_summary.txt
echo -e "sample\tgeneration\tnon-fourfold_V\tnon-fourfold_D\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > counts_pool_gen0-140_${REGION}_summary.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-140_pool.txt' -print`))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  NONFOURFOLD_V=$(grep "CUSTOM=non-fourfold;" $p | wc -l)
  NONFOURFOLD_D=$(grep "CUSTOM=non-fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
  MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
  MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
  LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$NONFOURFOLD_V\t$NONFOURFOLD_D\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> counts_pool_gen0-140_${REGION}_summary.txt
  done

#From the local environment:
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

#####All sites, exploring different Provean thresholds:
```{R, engine='bash'}

REGION="autosomes" #all #autosomes #Xchr

module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean

del_thres=-3.5
tol_thres=0

awk -F"\t" -v thres=$del_thres '$7 <= thres {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$7)}' missense_variants_provean_scores.gene_aa_sorted.new_plus_old_not_in_new.filtered_by_vcf.complete.bed | bedtools sort > missense_variants_provean_scores_deleterious_${del_thres}.bed #6732
awk -F"\t" -v thres=$tol_thres '$7 > thres {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$7)}' missense_variants_provean_scores.gene_aa_sorted.new_plus_old_not_in_new.filtered_by_vcf.complete.bed | bedtools sort > missense_variants_provean_scores_tolerated_${tol_thres}.bed #13619


cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

rm counts_pool_gen0-140_${REGION}_summary.tris.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\tsynonymous_V\tsynonymous_D\tmissense_V\tmissense_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > counts_pool_gen0-140_${REGION}_summary.tris.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-140_pool.txt' -print`))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
    grep -v "^X" ${pool/.txt/.nocustom.txt} > ${pool/.txt/_${REGION}.nocustom.txt}
  elif [ $REGION == "Xchr" ]
    then
    grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
    grep "^X" ${pool/.txt/.nocustom.txt} > ${pool/.txt/_${REGION}.nocustom.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  SYNONYMOUS_V=$(bedtools subtract -a ${p/.txt/.nocustom.txt} -b $p | grep "ExonicFunc.refGene=synonymous_SNV;" | wc -l)
  SYNONYMOUS_D=$(bedtools subtract -a ${p/.txt/.nocustom.txt} -b $p | grep "ExonicFunc.refGene=synonymous_SNV;" | awk '{print $11}' | paste -sd+ | bc)
  MISSENSE_V=$(grep "ExonicFunc.refGene=nonsynonymous_SNV;" ${p/.txt/.nocustom.txt} | wc -l)
  MISSENSE_D=$(grep "ExonicFunc.refGene=nonsynonymous_SNV;" ${p/.txt/.nocustom.txt} | awk '{print $11}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
  MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
  MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
  #bedtools intersect -a $p -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean/missense_variants_provean_scores_tolerated_${tol_thres}.bed > ${p/.txt/.tol.rm}
  #MISTOL_V=$(wc -l < ${p/.txt/.tol.rm})
  #MISTOL_D=$(awk '{print $11}' ${p/.txt/.tol.rm} | paste -sd+ | bc)
  #bedtools intersect -a $p -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean/missense_variants_provean_scores_deleterious_${del_thres}.bed > ${p/.txt/.del.rm}
  #MISDEL_V=$(wc -l < ${p/.txt/.del.rm})
  #MISDEL_D=$(awk '{print $11}' ${p/.txt/.del.rm} | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
  LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$SYNONYMOUS_V\t$SYNONYMOUS_D\t$MISSENSE_V\t$MISSENSE_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> counts_pool_gen0-140_${REGION}_summary.tris.txt
  done
rm *.rm

#From the local environment:
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.bis.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

#####All sites, segregating only (without fixed):
```{R, engine='bash'}

REGION="autosomes" #all #autosomes #Xchr

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
rm counts_pool_gen0-140_${REGION}_segregating_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > counts_pool_gen0-140_${REGION}_segregating_summary.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-140_pool_'${REGION}'.txt' -print`))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f2)
  awk -F";AF=|;EMstats=" '($2 <= 0.90) {print $0}' $pool > ${pool/.txt/_segregating.txt}
  p=${pool/.txt/_segregating.txt}
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
  MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
  MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
  LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> counts_pool_gen0-140_${REGION}_segregating_summary.txt
  done

#From the local environment:
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_segregating_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```


#####All sites, cov ≥35:
```{R, engine='bash'}

REGION="autosomes" #all #autosomes #Xchr
MINCOV=35

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
rm counts_pool_gen0-140_${REGION}_mincov${MINCOV}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > counts_pool_gen0-140_${REGION}_mincov${MINCOV}_summary.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-140_pool.txt' -print`))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    #grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    #grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | awk -v mincov=$MINCOV '$10+$11>=mincov' | wc -l)
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk -v mincov=$MINCOV '$10+$11>=mincov {print $11}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | awk -v mincov=$MINCOV '$10+$11>=mincov' | wc -l)
  MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk -v mincov=$MINCOV '$10+$11>=mincov {print $11}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | awk -v mincov=$MINCOV '$10+$11>=mincov' | wc -l)
  MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk -v mincov=$MINCOV '$10+$11>=mincov {print $11}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | awk -v mincov=$MINCOV '$10+$11>=mincov' | wc -l)
  LOF_D=$(grep "CUSTOM=LoF;" $p | awk -v mincov=$MINCOV '$10+$11>=mincov {print $11}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> counts_pool_gen0-140_${REGION}_mincov${MINCOV}_summary.txt
  done

#From the local environment:
REGION="autosomes" #all #autosomes #Xchr
MINCOV=35
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_mincov${MINCOV}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

#####Low/High recombination subset:
```{R, engine='bash'}

RECOMBINATION="high" #low #high
REGION="autosomes" #all #autosomes #Xchr

#To rename all "provean_only" version of the files in order to not rewrite them, use:
#mv counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.provean_only.txt
#for pool in $(ls *_gen0-140_pool.${RECOMBINATION}_recombination_${REGION}.txt); do echo $pool; mv $pool ${pool/_pool/_pool_provean_only}; done

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

rm counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt
echo -e "sample\tgeneration\tnon-fourfold_V\tnon-fourfold_D\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-140_pool.'${RECOMBINATION}'_recombination.txt' -print`))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  NONFOURFOLD_V=$(grep "CUSTOM=non-fourfold;" $p | wc -l)
  NONFOURFOLD_D=$(grep "CUSTOM=non-fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
  MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
  MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
  LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$NONFOURFOLD_V\t$NONFOURFOLD_D\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt
  done

#From the local environment:
RECOMBINATION="low" #low #high
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

```

###Include AF=0 VCFs:
####Retrieve ancestral counts per category:
```{R, engine='bash'}

REGION="autosomes" #all #autosomes #Xchr

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
rm ancestral_counts_pool_gen0-140_${REGION}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_A\ttolerated_V\ttolerated_A\tdeleterious_V\tdeleterious_A\tLoF_V\tLoF_A" > ancestral_counts_pool_gen0-140_${REGION}_summary.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-140_pool.all_'${REGION}'.txt' -print` | cut -d'/' -f2))
for pool in ${POOL_LIST[@]}
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    if [ ! -f ${pool/.txt/_${REGION}.txt} ]
      then
      grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    fi
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    if [ ! -f ${pool/.txt/_${REGION}.txt} ]
      then
      grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    fi
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | awk '$10 > 0' | wc -l)
  FOURFOLD_A=$(grep "CUSTOM=fourfold;" $p | awk '{print $10}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | awk '$10 > 0' | wc -l)
  MISTOL_A=$(grep "CUSTOM=tolerated;" $p | awk '{print $10}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | awk '$10 > 0' | wc -l)
  MISDEL_A=$(grep "CUSTOM=deleterious;" $p | awk '{print $10}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | awk '$10 > 0' | wc -l)
  LOF_A=$(grep "CUSTOM=LoF;" $p | awk '{print $10}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_A\t$MISTOL_V\t$MISTOL_A\t$MISDEL_V\t$MISDEL_A\t$LOF_V\t$LOF_A" >> ancestral_counts_pool_gen0-140_${REGION}_summary.txt
  done

#From the local environment:
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/ancestral_counts_pool_gen0-140_${REGION}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

####Retrieve total counts per category:
```{R, engine='bash'}

REGION="autosomes" #all #autosomes #Xchr

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
rm ancestralplusderived_counts_pool_gen0-140_${REGION}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_T\ttolerated_V\ttolerated_T\tdeleterious_V\tdeleterious_T\tLoF_V\tLoF_T" > ancestralplusderived_counts_pool_gen0-140_${REGION}_summary.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-140_pool.all.txt' -print` | cut -d'/' -f2))
for pool in ${POOL_LIST[@]}
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    if [ ! -f ${pool/.txt/_${REGION}.txt} ]
      then
      grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    fi
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    if [ ! -f ${pool/.txt/_${REGION}.txt} ]
      then
      grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    fi
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
  FOURFOLD_T=$(grep "CUSTOM=fourfold;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
  MISTOL_T=$(grep "CUSTOM=tolerated;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
  MISDEL_T=$(grep "CUSTOM=deleterious;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
  LOF_T=$(grep "CUSTOM=LoF;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_T\t$MISTOL_V\t$MISTOL_T\t$MISDEL_V\t$MISDEL_T\t$LOF_V\t$LOF_T" >> ancestralplusderived_counts_pool_gen0-140_${REGION}_summary.txt
  done

#From the local environment:
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/ancestralplusderived_counts_pool_gen0-140_${REGION}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

####Retrieve proportion of derived counts per category:
```{R, engine='bash'}

#Note: the proportions aren't exactly the same if the sum of $11 is used as numerator, and the sum of ($10 + $11) as denominator, probably due to some rounding artifacts?

REGION="autosomes" #all #autosomes #Xchr

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
rm proportion_pool_gen0-140_${REGION}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_P\ttolerated_V\ttolerated_P\tdeleterious_V\tdeleterious_P\tLoF_V\tLoF_P" > proportion_pool_gen0-140_${REGION}_summary.txt
POOL_LIST=$(ls -v `find . -name '*_gen0-140_pool.all.txt' -print` | cut -d'/' -f2)
for pool in ${POOL_LIST[@]}
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_VALID=$(grep "CUSTOM=fourfold;" $p | awk '($10 + $11) > 0' | wc -l)
  FOURFOLD_PROP_SUM=$(grep "CUSTOM=fourfold;" $p | awk '{if (($10 + $11) > 0) {print $11/($10 + $11)}}' | paste -sd+ | bc)
  FOURFOLD_PROP_AVE=$(echo "scale=3; $FOURFOLD_PROP_SUM/$FOURFOLD_VALID" | bc)
  MISTOL_VALID=$(grep "CUSTOM=tolerated;" $p | awk '($10 + $11) > 0' | wc -l)
  MISTOL_PROP_SUM=$(grep "CUSTOM=tolerated;" $p | awk '{if (($10 + $11) > 0) {print $11/($10 + $11)}}' | paste -sd+ | bc)
  MISTOL_PROP_AVE=$(echo "scale=3; $MISTOL_PROP_SUM/$MISTOL_VALID" | bc)
  MISDEL_VALID=$(grep "CUSTOM=deleterious;" $p | awk '($10 + $11) > 0' | wc -l)
  MISDEL_PROP_SUM=$(grep "CUSTOM=deleterious;" $p | awk '{if (($10 + $11) > 0) {print $11/($10 + $11)}}' | paste -sd+ | bc)
  MISDEL_PROP_AVE=$(echo "scale=3; $MISDEL_PROP_SUM/$MISDEL_VALID" | bc)
  LOF_VALID=$(grep "CUSTOM=LoF;" $p | awk '($10 + $11) > 0' | wc -l)
  LOF_PROP_SUM=$(grep "CUSTOM=LoF;" $p | awk '{if (($10 + $11) > 0) {print $11/($10 + $11)}}' | paste -sd+ | bc)
  LOF_PROP_AVE=$(echo "scale=3; $LOF_PROP_SUM/$LOF_VALID" | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_VALID\t$FOURFOLD_PROP_AVE\t$MISTOL_VALID\t$MISTOL_PROP_AVE\t$MISDEL_VALID\t$MISDEL_PROP_AVE\t$LOF_VALID\t$LOF_PROP_AVE" >> proportion_pool_gen0-140_${REGION}_summary.txt
  done

#From the local environment:
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/proportion_pool_gen0-140_${REGION}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

##Rarefied counts.
###Find valid sites and generate depth tables:
```{R, engine='bash'}

for index in {10..46}
do
  head -n1 all_samples_gen0-140_pool.all.depth_table.txt | cut -f$index
  tail -n+2 all_samples_gen0-140_pool.all.depth_table.txt | awk -v col=$index '{ sum += $col } END { if (NR > 0) print sum / NR }'
done




#After observing the depth distribution of all samples, we've decided to leave out 3 lines (1, 10, and 17) due to their lower depth. Pb-005 is also out from the analysis.
module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

#Create dataframe with the info from each site in the VCF:
echo -e "CHR\tSTART\tEND\tID\tANCESTRAL\tDERIVED\tQUAL\tFILTER\tINFO" > all_samples_gen0-140_pool.all.depth_table.txt
cut -f-9 LBT0_gen0_gen0-140_pool.all.txt | grep -v "^X" >> all_samples_gen0-140_pool.all.depth_table.txt

#Extract counts from each pool.
POOLS=$(ls *gen0-140_pool.all.txt | grep -Ev 'c1_gen5_|sample1_|sample10_|sample17_')
for p in ${POOLS[@]}
  do
  echo "${p}"
  SAMPLE=$(echo $p | cut -d'_' -f-2)
  paste all_samples_gen0-140_pool.all.depth_table.txt <(cat <(echo $SAMPLE) <(grep -v "^X" "${p}" | awk -F"\t" '{printf ("%s\n", $10+$11)}')) > all_samples_gen0-140_pool.all.depth_table.temp.txt && mv all_samples_gen0-140_pool.all.depth_table.temp.txt all_samples_gen0-140_pool.all.depth_table.txt
  done

DEPTH=50 #input the desired target depth
#Count valid (1, if depth ≥ $DEPTH) and invalid (0, if depth < $DEPTH) sites per population (if any pool from that population doesn't reach the depth threshold, the site is invalid).
##Create dataframe with the info from each site in the VCF:
echo -e "CHR\tSTART\tEND\tID\tANCESTRAL\tDERIVED\tQUAL\tFILTER\tINFO" > all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool
cut -f-9 LBT0_gen0_gen0-140_pool.all.txt | grep -v "^X" >> all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool
##Base population:
cut -f-9 LBT0_gen0_gen0-140_pool.all.txt | grep -v "^X" > all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool.Pb
COLUMNS=$(head -n1 all_samples_gen0-140_pool.all.depth_table.txt | tr '\t' '\n' | grep -nE 'BT20_gen20|BT30_gen30|C1_gen140|c2_gen40|LBT0_gen0' | awk -F":" '{printf ("%s\n", $1)}')
for column in ${COLUMNS[@]}
  do
  #echo "$column"
  paste all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool.Pb <(tail -n+2 all_samples_gen0-140_pool.all.depth_table.txt | awk -v field="$column" -v target_depth="$DEPTH" -F"\t" '{ if ($field >= target_depth) {print 1} else {print 0} }') > all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool.temp.Pb && mv all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool.temp.Pb all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool.Pb
  done
paste all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool <(cat <(echo "Pb") <(awk -F"\t" '{ if (($10==0) || ($11==0) || ($12==0) || ($13==0) || ($14==0)) {print 0} else {print 1} }' all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool.Pb | grep -v "^X")) > all_samples_gen0-140_pool.all.depth_${DEPTH}_table.temp.bool && mv all_samples_gen0-140_pool.all.depth_${DEPTH}_table.temp.bool all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool
##Lines:
POOLS=$(head -n1 all_samples_gen0-140_pool.all.depth_table.txt | tr '\t' '\n' | grep "sample" | cut -d'_' -f1 | sort -u)
for pool in ${POOLS[@]}
  do
  echo "$pool"
  COLUMN_140=$(head -n1 all_samples_gen0-140_pool.all.depth_table.txt | tr '\t' '\n' | grep -nE "${pool}_gen140" | awk -F":" '{printf ("%s\n", $1)}')
  COLUMN_040=$(head -n1 all_samples_gen0-140_pool.all.depth_table.txt | tr '\t' '\n' | grep -nE "${pool}_gen40" | awk -F":" '{printf ("%s\n", $1)}')
  paste all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool <(cat <(echo "$pool") <(tail -n+2 all_samples_gen0-140_pool.all.depth_table.txt | awk -v gen140="$COLUMN_140" -v gen40="$COLUMN_040" -v target_depth="$DEPTH" -F"\t" '{ if (($gen140 >= target_depth) && ($gen40 >= target_depth)) {print 1} else {print 0} }' | grep -v "^X")) > all_samples_gen0-140_pool.all.depth_${DEPTH}_table.temp.bool && mv all_samples_gen0-140_pool.all.depth_${DEPTH}_table.temp.bool all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool
  done

#Summary statistics (for DEPTH=30)
##Total sites:
tail -n+2 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | wc -l #144978
##Valid in the base population:
cut -f$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'Pb' | awk -F":" '{printf ("%s\n", $1)}') all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | sort | uniq -c #14767 invalid, 130211 valid
##Valid in at least 60% of the lines:
cut -f$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'sample' | awk -F":" '{printf ("%s\n", $1)}' | head -n1)- all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | awk -F "\t" '{ for(i=1; i<=NF;i++) j+=$i; print j; j=0 }' | awk '$1 >= 10' | wc -l #137491 valid, which means 7487 invalid
##Valid in both the base population and at least 60% of the lines:
bedtools intersect -a <(cut -f-9,$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'Pb' | awk -F":" '{printf ("%s\n", $1)}') all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | awk '$10 == 1') -b <(cut -f-9,$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'sample' | awk -F":" '{printf ("%s\n", $1)}' | head -n1)- all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | awk -F "\t" '{ for(i=10; i<=NF;i++) j+=$i; printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,j); j=0 }' | awk '$4 >= 10') | sort -k1,1 -k2,2n -u > all_samples_gen0-140_pool.all.depth_${DEPTH}_valid.txt #Note: at first it looked like 128939 were valid in both the base population and at least 60% of the lines, but later on I realised there were some duplicate sites in the file which were already there in the VCF, so I filtered them out. The actual final number of valid sites is 128909.

#Summary statistics (for DEPTH=35)
##Total sites:
tail -n+2 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | wc -l #144978
##Valid in the base population:
cut -f$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'Pb' | awk -F":" '{printf ("%s\n", $1)}') all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | sort | uniq -c #31270 invalid, 113708 valid
##Valid in at least 60% of the lines:
cut -f$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'sample' | awk -F":" '{printf ("%s\n", $1)}' | head -n1)- all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | awk -F "\t" '{ for(i=1; i<=NF;i++) j+=$i; print j; j=0 }' | awk '$1 >= 10' | wc -l #130945 valid, which means 14033 invalid
##Valid in both the base population and at least 60% of the lines:
bedtools intersect -a <(cut -f-9,$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'Pb' | awk -F":" '{printf ("%s\n", $1)}') all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | awk '$10 == 1') -b <(cut -f-9,$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'sample' | awk -F":" '{printf ("%s\n", $1)}' | head -n1)- all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | awk -F "\t" '{ for(i=10; i<=NF;i++) j+=$i; printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,j); j=0 }' | awk '$4 >= 10') | sort -k1,1 -k2,2n -u > all_samples_gen0-140_pool.all.depth_${DEPTH}_valid.txt #The actual final number of valid sites is 111739.

#Summary statistics (for DEPTH=40)
##Total sites:
tail -n+2 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | wc -l #144978
##Valid in the base population:
cut -f$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'Pb' | awk -F":" '{printf ("%s\n", $1)}') all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | sort | uniq -c #58399 invalid, 86579 valid
##Valid in at least 60% of the lines:
cut -f$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'sample' | awk -F":" '{printf ("%s\n", $1)}' | head -n1)- all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | awk -F "\t" '{ for(i=1; i<=NF;i++) j+=$i; print j; j=0 }' | awk '$1 >= 10' | wc -l #114009 valid, which means 30969 invalid
##Valid in both the base population and at least 60% of the lines:
bedtools intersect -a <(cut -f-9,$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'Pb' | awk -F":" '{printf ("%s\n", $1)}') all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | awk '$10 == 1') -b <(cut -f-9,$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'sample' | awk -F":" '{printf ("%s\n", $1)}' | head -n1)- all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | awk -F "\t" '{ for(i=10; i<=NF;i++) j+=$i; printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,j); j=0 }' | awk '$4 >= 10') | sort -k1,1 -k2,2n -u > all_samples_gen0-140_pool.all.depth_${DEPTH}_valid.txt #The actual final number of valid sites is 82796.

#Summary statistics (for DEPTH=50)
##Total sites:
tail -n+2 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | wc -l #144978
##Valid in the base population:
cut -f$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'Pb' | awk -F":" '{printf ("%s\n", $1)}') all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | sort | uniq -c #117890 invalid, 27088 valid
##Valid in at least 60% of the lines:
cut -f$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'sample' | awk -F":" '{printf ("%s\n", $1)}' | head -n1)- all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | awk -F "\t" '{ for(i=1; i<=NF;i++) j+=$i; print j; j=0 }' | awk '$1 >= 10' | wc -l #41141 valid, which means 103837 invalid
##Valid in both the base population and at least 60% of the lines:
bedtools intersect -a <(cut -f-9,$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'Pb' | awk -F":" '{printf ("%s\n", $1)}') all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | awk '$10 == 1') -b <(cut -f-9,$(head -n1 all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tr '\t' '\n' | grep -nE 'sample' | awk -F":" '{printf ("%s\n", $1)}' | head -n1)- all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool | tail -n+2 | awk -F "\t" '{ for(i=10; i<=NF;i++) j+=$i; printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,j); j=0 }' | awk '$4 >= 10') | sort -k1,1 -k2,2n -u > all_samples_gen0-140_pool.all.depth_${DEPTH}_valid.txt #The actual final number of valid sites is 19187.

```

###Extract valid sites for each pool:
```{R, engine='bash'}

DEPTH=50 #input the desired target depth

#After observing the depth distribution of all samples, we've decided to leave out 3 lines (1, 10, and 17) due to their lower depth. Pb-005 is also out from the analysis.
module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

POOLS=$(ls *gen0-140_pool.all.txt | grep -Ev 'c1_gen5_|sample1_|sample10_|sample17_')
for p in ${POOLS[@]}
  do
  echo "${p}"
  bedtools intersect -a <(sort -k1,1 -k2,2n -u "${p}") -b all_samples_gen0-140_pool.all.depth_${DEPTH}_valid.txt > ${p/.txt/.depth_${DEPTH}_valid.txt} #sort -k1,1 -k2,2n -u "${p}" this part of the code removes the few duplicate rows that have been passed down since the VCF. All resulting files have now 129652 sites for depth 30.
  done

```

###Extract state from all reads:
####extract_state_reads.sh
```{R, engine='bash'}

DEPTH=$1
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
POOL=$(ls *gen0-140_pool.all.depth_${DEPTH}_valid.txt | head -n$SGE_TASK_ID | tail -n1)

rm ${POOL/.txt/_mod.txt}
while read -r CHR START STOP ID ANC_STATE DER_STATE QUALITY TAG INFO ANC_COUNT DER_COUNT
  do
  TOT_COUNT=$((ANC_COUNT + DER_COUNT))
  READS=$(echo "$(for i in $(seq 1 $ANC_COUNT); do printf "$ANC_STATE" ; done)""$(for i in $(seq 1 $DER_COUNT); do printf "$DER_STATE" ; done)")
  echo -e "$CHR\t$START\t$STOP\t$ANC_STATE\t$DER_STATE\t$ANC_COUNT\t$DER_COUNT\t$TOT_COUNT\t$READS" >> ${POOL/.txt/_mod.txt}
  done < $POOL

#Save this code as: /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/extract_state_reads.sh

```

####Send the array-jobs:
```{R, engine='bash'}

#Run it as follows:
DEPTH=50 #Input the desired target depth
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

POOL_N=$(ls *gen0-140_pool.all.depth_${DEPTH}_valid.txt | wc -l)
qsub -cwd -l h=compute-0-9 -t 1-$POOL_N /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/extract_state_reads.sh $DEPTH

```

###Generate rarefied counts:
####rarefied_counts.sh
```{R, engine='bash'}

DEPTH=$1
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
POOL=$(ls *gen0-140_pool.all.depth_${DEPTH}_valid_mod.txt | head -n$SGE_TASK_ID | tail -n1)

for boot in {1..100}
  do
  N_BOOT=$(printf "%03d" ${boot})
  awk -v depth=$DEPTH -F"\t" 'BEGIN {"date +%N" | getline seed; srand(seed);} {if($8 >= depth) {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t", $1,$2,$3,$4,$5,$6,$7,$8); len=length($9); for(i=1;i<=depth;) {k=int(rand()*len)+1; if(!(k in N)) {N[k]; printf "%s", substr($9,k,1); i++;}} split("", N); print ""} else {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,0,0,0,"N")}}' $POOL | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$7,$8,$9,gsub($4, "", $9),gsub($5, "", $9))}' > ./rarefied_counts/depth${DEPTH}/${POOL/.txt/.boot_${N_BOOT}.txt}
  done

#Save this code as: /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/rarefied_counts.sh

```

####Send the array-jobs:
```{R, engine='bash'}

#Run it as follows:
DEPTH=50 #Input the desired target depth
mkdir -p /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/depth${DEPTH}
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

POOL_N=$(ls *gen0-140_pool.all.depth_${DEPTH}_valid_mod.txt | wc -l)
qsub -cwd -l h=compute-0-9 -t 1-$POOL_N /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/rarefied_counts.sh $DEPTH

```

####Junk:
```{R, engine='bash'}


| awk '$11 > $7' | less -S > ./rarefied_counts/${POOL/.txt/.boot_${N_BOOT}.txt}

awk -v seed=$RANDOM -F"\t" '{srand(seed); printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t", $1,$2,$3,$4,$5,$6,$7,$8); len=length($9); for(i=1;i<=30;) {k=int(rand()*len)+1; if(!(k in N)) {N[k]; printf "%s_%s.", substr($9,k,1), k; i++;}} split("", N); print ""}' $POOL | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$7,$8,$9,gsub($4, "", $9),gsub($5, "", $9))}' | awk '$11 > $7' | less -S

awk 'BEGIN {"date +%N" | getline seed; srand(seed);} {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t", $1,$2,$3,$4,$5,$6,$7,$8); len=length($9); for(i=1;i<=30;) {k=int(rand()*len)+1; if(!(k in N)) {N[k]; printf "%s_%s.", substr($9,k,1), k; i++;}} split("", N); print ""}' $POOL | less -S


awk '{srand(); len=length($1); for(i=1;i<=10;) {k=int(rand()*len)+1; if(!(k in N)) {N[k]; printf "%s", substr($1,k,1); i++}} print ""}' <(cat kaka) #norep
awk '{srand(); len=length($1); for(i=1;i<=10;) {k=int(rand()*len)+1; if(!(k in N)) {N[k]; printf "%s", substr($1,k,1); i++}} split("", N); print ""}' <(cat kaka) #norep
awk '{srand(); len=length($1); for(i=1;i<=10;) {k=int(rand()*len)+1; if(!(k in N)) {N[k]; printf "%s_%s.", substr($1,k,1), k; i++}} split("", N); print ""}' <(echo $TEST) #norep
awk '{srand(); len=length($1); for(i=1;i<=10;i++) {k=int(rand()*len)+1; printf "%s", substr($1,k,1)} print ""}' <(echo $TEST) #rep

ABCDEFGHIJKLMN
CCCCCCCCCCCCGG
AAAAAAAAAAAAAA

n = sprintf("%d",int(rand()*limit)+1)

awk '
{ V[NR]=$1 }
END {
  srand()
  for(i=1;i<=1440;) {
    v=V[int(1+rand()*7200)]
    if (!(v in N)) {
       N[v]
       print v
       i++
    }
  }
}' random.txt

```

####Obsolete methods:
#####Obsolete (too slow): rarefied_counts.sh
```{R, engine='bash'}

#Save this code as: /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/rarefied_counts.sh (create the directory first if it doesn't exist)

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
POOL=$(ls *gen0-140_pool.all.valid_mod.txt | head -n$SGE_TASK_ID | tail -n1)
TOTAL=$(wc -l < $POOL)

#rm ./rarefied_counts/${POOL/.txt/.boot_*.txt}
COUNTER=0
while read -r CHR START STOP ANC_STATE DER_STATE ANC_COUNT DER_COUNT TOT_COUNT READS
  do
  #for boot in {1..100}
    #do
    #N_BOOT=$(printf "%03d" ${boot}) #chunk of parallelisation
    if (( $TOT_COUNT < 30 ))
      then
      ANC_RAREF=0
      DER_RAREF=0
    elif (( $ANC_COUNT == 0 ))
      then
      ANC_RAREF=0
      DER_RAREF=30
    elif (( $DER_COUNT == 0 ))
      then
      ANC_RAREF=30
      DER_RAREF=0
    else
      RANDOM_READS=$(echo $READS | fold -w1 | shuf -n30)
      #ANC_RAREF=$(echo "$RANDOM_READS" | awk -v anc="$ANC_STATE" '$1==anc { count++ } END { print count }')
      ANC_RAREF=$(echo "$RANDOM_READS" | grep "$ANC_STATE" | wc -l)
      DER_RAREF=$((30 - ANC_RAREF))
    fi
    #echo $ANC_RAREF
    #echo $DER_RAREF
    #echo -e "$CHR\t$START\t$STOP\t$ANC_RAREF\t$DER_RAREF" >> ./rarefied_counts/${POOL/.txt/.boot_${N_BOOT}.txt}
    echo -e "$CHR\t$START\t$STOP\t$ANC_RAREF\t$DER_RAREF" >> ${POOL/.txt/.processed.txt}
    #done
  ((COUNTER++))
  if [ $(( $COUNTER % 10 )) == 0 ]
    then
    echo "Processed $COUNTER sites out of $TOTAL"
  fi
  done < $POOL

```

#####Obsolete (way too slow): rarefied_counts.sh
```{R, engine='bash'}

#Save this code as: /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/rarefied_counts.sh (create the directory first if it doesn't exist)

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
POOL=$(ls *gen0-140_pool.all.valid.txt | head -n$SGE_TASK_ID | tail -n1)

rm ./rarefied_counts/${POOL/.txt/.boot_*.txt}
while read -r CHR START STOP ID ANC_STATE DER_STATE QUALITY TAG INFO ANC_COUNT DER_COUNT
  do
  for boot in {1..100}
    do
    N_BOOT=$(printf "%03d" ${boot}) #chunk of parallelisation
    if (( $((ANC_COUNT + DER_COUNT)) < 30 ))
      then
      ANC_RAREF=0
      DER_RAREF=0
    elif (( $ANC_COUNT == 0 ))
      then
      ANC_RAREF=0
      DER_RAREF=30
    elif (( $DER_COUNT == 0 ))
      then
      ANC_RAREF=30
      DER_RAREF=0
    else
      RANDOM_READS=$(cat <(yes $ANC_STATE | head -n$ANC_COUNT) <(yes $DER_STATE | head -n$DER_COUNT) | shuf -n30)
      ANC_RAREF=$(echo "$RANDOM_READS" | grep $ANC_STATE | wc -l)
      DER_RAREF=$(echo "$RANDOM_READS" | grep $DER_STATE | wc -l)
    fi
    #echo $ANC_RAREF
    #echo $DER_RAREF
    echo -e "$CHR\t$START\t$STOP\t$ANC_RAREF\t$DER_RAREF" >> ./rarefied_counts/${POOL/.txt/.boot_${N_BOOT}.txt}
    done
  done < $POOL

```

#####Send the array-jobs:
```{R, engine='bash'}

#Run it as follows:
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

POOL_N=$(ls *gen0-140_pool.all.valid_mod.txt | wc -l)
qsub -cwd -l h=compute-0-9 -t 1-$POOL_N /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/rarefied_counts.sh

```

###Obtain the average rarefied values:
```{bash}

DEPTH=50

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/depth$DEPTH
module load gcc/7.2.0
module add gcc/7.2.0

#Generate file with the other columns from the VCF (the coordinates and other stuff):
cut -f-5 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/all_samples_gen0-140_pool.all.depth_${DEPTH}_valid.txt > coordinates.txt
cut -f-9 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/all_samples_gen0-140_pool.all.depth_${DEPTH}_valid.txt > coordinates_complete_vcf.txt

#For each pool, obtain average for columns 10 and 11 (rarefied ancestral and derived allele counts) between all 100 rarefied files, as well as a boolean column to indicate whether the site has enough coverage and is thus valid (1) or not (0), and, finally, the proportion of derived alleles relative to total alleles (in order to avoid a division by 0 fatal error, a ternary expression is used here to assign a 0 if the site is invalid, or run the operation otherwise):
for pop in $(ls /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/*.all.depth_${DEPTH}_valid_mod.txt | grep -v "all_samples" | rev | cut -d'/' -f1 | rev | cut -d'_' -f-2)
  do
  echo $pop
  ls ${pop}_gen0-140_pool.all.depth_${DEPTH}_valid_mod.boot_*[[:digit:]]*.txt > ${pop}_gen0-140_pool.all.depth_${DEPTH}_valid_mod.Nboot_100.list
  paste coordinates.txt <(gawk -v nboot=100 '{for (i=10;i<=NF;i++) total[FNR","i]+=$i;} END {for (j=1;j<=FNR;j++) {for (i=10;i<=NF;i++) printf "%.2f\t ",total[j","i]/nboot; print "";}}' $(<${pop}_gen0-140_pool.all.depth_${DEPTH}_valid_mod.Nboot_100.list)) | awk -v depth=$DEPTH '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$7,($6+$7)/depth,(($6+$7)?$7/($6+$7):0))}' > ${pop}_gen0-140_pool.all.depth_${DEPTH}_valid_mod.average.txt
  done

#Next, obtain the averages across all lines, considering only valid sites from each pool:
for gen in $(ls sample*depth_${DEPTH}_valid_mod.average.txt | cut -d'_' -f2 | sort -u)
  do
  echo $gen
  ls sample*_${gen}_gen0-140_pool.all.depth_${DEPTH}_valid_mod.average.txt > lines_${gen}_gen0-140_pool.all.depth_${DEPTH}_valid_mod.average.list
  paste coordinates.txt <(gawk '{for (i=6;i<=NF;i++) total[FNR","i]+=$i;} END {for (j=1;j<=FNR;j++) {printf("%.2f\t%.2f\t%d\t%.2f\n",total[j","6]/total[j","8],total[j","7]/total[j","8],total[j","8],total[j","9]/total[j","8])}}' $(<lines_${gen}_gen0-140_pool.all.depth_${DEPTH}_valid_mod.average.list)) > lines_${gen}_gen0-140_pool.all.depth_${DEPTH}_valid_mod.lines_average.txt
  done

##Test if it has worked fine:
gen="gen40" #gen40 gen140
LINE=13 #input any number
for file in $(ls sample*${gen}_gen0-140_pool.all.depth_${DEPTH}_valid_mod.average.txt)
  do
  head -n$LINE $file | tail -n1
  done
  head -n$LINE lines_${gen}_gen0-140_pool.all.depth_${DEPTH}_valid_mod.lines_average.txt | tail -n1
#Check it against: /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/all_samples_gen0-140_pool.all.depth_${DEPTH}_table.bool (where a 0 denotes that the site hasn't enough coverage in any of the two pools, that is, the gen40 or the gen140 one).

#Finally, include the other fields:
POOL_LIST=$(ls *gen0-140_pool.all.depth_${DEPTH}_valid_mod.average.txt) #If only Pb and the average of lines are wanted, use this instead: ls *gen0-140_pool.all.valid_mod.average.txt lines_*_gen0-140_pool.all.depth_${DEPTH}_valid_mod.lines_average.txt | grep -v "sample"
for pool in ${POOL_LIST[@]}
  do
  echo "${pool}"
  bedtools intersect -a coordinates_complete_vcf.txt -b "${pool}" -wa -wb | cut -f-9,15- > ${pool/.txt/_complete.txt}
  done

##Additional tests to check counts in all rarefied files:
POOL_BOOT=$(ls LBT0_gen0_gen0-140_pool.all.depth_${DEPTH}_valid_mod.boot_*.txt)
grep "CUSTOM=deleterious;" LBT0_gen0_gen0-140_pool.all.depth_50_valid_mod.average_complete.txt | cut -f-3 > misdel.bed
grep "CUSTOM=LoF;" LBT0_gen0_gen0-140_pool.all.depth_50_valid_mod.average_complete.txt | cut -f-3 > LoF.bed
rm LBT0_gen0_gen0-140_pool.all.depth_${DEPTH}_valid_mod.LoF.count
for pool in ${POOL_BOOT[@]}
  do
  echo "${pool}"
  MISDEL_DER_COUNT=$(bedtools intersect -a ${pool} -b misdel.bed -wa | cut -f11 | paste -sd+ | bc)
  LOF_DER_COUNT=$(bedtools intersect -a ${pool} -b LoF.bed -wa | cut -f11 | paste -sd+ | bc)
  echo -e "$pool\t$MISDEL_DER_COUNT\t$LOF_DER_COUNT" >> LBT0_gen0_gen0-140_pool.all.depth_${DEPTH}_valid_mod.LoF.count
  done

```

###Retrieve derived counts per category:
```{R, engine='bash'}

REGION="all" #all #autosomes #Xchr
DEPTH=50

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/depth$DEPTH/
rm rarefied_depth_${DEPTH}_counts_pool_gen0-140_${REGION}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > rarefied_depth_${DEPTH}_counts_pool_gen0-140_${REGION}_summary.txt
POOL_LIST=($(ls *gen0-140_pool.all.depth_${DEPTH}_valid_mod.average_complete.txt))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | awk '$11 > 0' | wc -l)
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | awk '$11 > 0' | wc -l)
  MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | awk '$11 > 0' | wc -l)
  MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | awk '$11 > 0' | wc -l)
  LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> rarefied_depth_${DEPTH}_counts_pool_gen0-140_${REGION}_summary.txt
  done

#From the local environment:
REGION="all" #all #autosomes #Xchr
DEPTH=50
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/depth${DEPTH}/rarefied_depth_${DEPTH}_counts_pool_gen0-140_${REGION}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/rarefied/depth${DEPTH}/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

###Retrieve total counts per category:
```{R, engine='bash'}

REGION="all" #all #autosomes #Xchr
DEPTH=50

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/depth$DEPTH/
rm rarefied_depth_${DEPTH}_ancestralplusderived_counts_pool_gen0-140_${REGION}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_T\ttolerated_V\ttolerated_T\tdeleterious_V\tdeleterious_T\tLoF_V\tLoF_T" > rarefied_depth_${DEPTH}_ancestralplusderived_counts_pool_gen0-140_${REGION}_summary.txt
POOL_LIST=($(ls *gen0-140_pool.all.depth_${DEPTH}_valid_mod.average_complete.txt))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    if [ ! -f ${pool/.txt/_${REGION}.txt} ]
      then
      grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    fi
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    if [ ! -f ${pool/.txt/_${REGION}.txt} ]
      then
      grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    fi
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | awk '$12 > 0' | wc -l)
  FOURFOLD_T=$(grep "CUSTOM=fourfold;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | awk '$12 > 0' | wc -l)
  MISTOL_T=$(grep "CUSTOM=tolerated;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | awk '$12 > 0' | wc -l)
  MISDEL_T=$(grep "CUSTOM=deleterious;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | awk '$12 > 0' | wc -l)
  LOF_T=$(grep "CUSTOM=LoF;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_T\t$MISTOL_V\t$MISTOL_T\t$MISDEL_V\t$MISDEL_T\t$LOF_V\t$LOF_T" >> rarefied_depth_${DEPTH}_ancestralplusderived_counts_pool_gen0-140_${REGION}_summary.txt
  done

#From the local environment:
REGION="all" #all #autosomes #Xchr
DEPTH=50
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/depth$DEPTH/rarefied_depth_${DEPTH}_ancestralplusderived_counts_pool_gen0-140_${REGION}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/rarefied/depth$DEPTH/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

###Retrieve proportion of derived counts per category:
```{R, engine='bash'}

REGION="all" #all #autosomes #Xchr
DEPTH=50

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/depth$DEPTH/
rm rarefied_depth_${DEPTH}_proportion_pool_gen0-140_${REGION}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_P\ttolerated_V\ttolerated_P\tdeleterious_V\tdeleterious_P\tLoF_V\tLoF_P" > rarefied_depth_${DEPTH}_proportion_pool_gen0-140_${REGION}_summary.txt
POOL_LIST=($(ls *gen0-140_pool.all.depth_${DEPTH}_valid_mod.average_complete.txt))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_VALID=$(grep "CUSTOM=fourfold;" $p | awk '$12 == 1' | wc -l)
  FOURFOLD_PROP_SUM=$(grep "CUSTOM=fourfold;" $p | awk '{print $13}' | paste -sd+ | bc)
  FOURFOLD_PROP_AVE=$(echo "scale=3; $FOURFOLD_PROP_SUM/$FOURFOLD_VALID" | bc)
  MISTOL_VALID=$(grep "CUSTOM=tolerated;" $p | awk '$12 == 1' | wc -l)
  MISTOL_PROP_SUM=$(grep "CUSTOM=tolerated;" $p | awk '{print $13}' | paste -sd+ | bc)
  MISTOL_PROP_AVE=$(echo "scale=3; $MISTOL_PROP_SUM/$MISTOL_VALID" | bc)
  MISDEL_VALID=$(grep "CUSTOM=deleterious;" $p | awk '$12 == 1' | wc -l)
  MISDEL_PROP_SUM=$(grep "CUSTOM=deleterious;" $p | awk '{print $13}' | paste -sd+ | bc)
  MISDEL_PROP_AVE=$(echo "scale=3; $MISDEL_PROP_SUM/$MISDEL_VALID" | bc)
  LOF_VALID=$(grep "CUSTOM=LoF;" $p | awk '$12 == 1' | wc -l)
  LOF_PROP_SUM=$(grep "CUSTOM=LoF;" $p | awk '{print $13}' | paste -sd+ | bc)
  LOF_PROP_AVE=$(echo "scale=3; $LOF_PROP_SUM/$LOF_VALID" | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_VALID\t$FOURFOLD_PROP_AVE\t$MISTOL_VALID\t$MISTOL_PROP_AVE\t$MISDEL_VALID\t$MISDEL_PROP_AVE\t$LOF_VALID\t$LOF_PROP_AVE" >> rarefied_depth_${DEPTH}_proportion_pool_gen0-140_${REGION}_summary.txt
  done

#From the local environment:
REGION="all" #all #autosomes #Xchr
DEPTH=50
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/depth$DEPTH/rarefied_depth_${DEPTH}_proportion_pool_gen0-140_${REGION}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/rarefied/depth$DEPTH/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

#14. Plot counts.
##Derived count statistics:
###Derived count ratios (relative to 4fold and Pb-000):
####Empirical Pb and line averages (combined version):
#####All sites:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.txt")) %>% filter(generation!="gen5")

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR
#write_tsv(average_relativised_pool_counts_copies_4FR,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_4FR_",type,".txt"))


#Plot:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,ratio!="fourfold"), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(aes(colour=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(average_relativised_pool_counts_copies_4FR$generation),limits = c(levels(average_relativised_pool_counts_copies_4FR$generation)[1],"skip",levels(average_relativised_pool_counts_copies_4FR$generation)[c(2:4)],c(rep("skip",3)),levels(average_relativised_pool_counts_copies_4FR$generation)[5])) +
  #scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_text(size=12),
        axis.title.y=element_text(size=12),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_text(colour="black"),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()

  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_4FR_",type,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)


```

#####All sites (test different things):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.tris.txt")) %>% filter(generation!="gen5")

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,synonymous=synonymous_D/fourfold_D,missense=missense_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","synonymous","missense","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR
#write_tsv(average_relativised_pool_counts_copies_4FR,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_4FR_",type,".txt"))


#Plot:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,ratio!="fourfold"), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(aes(colour=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(average_relativised_pool_counts_copies_4FR$generation),limits = c(levels(average_relativised_pool_counts_copies_4FR$generation)[1],"skip",levels(average_relativised_pool_counts_copies_4FR$generation)[c(2:4)],c(rep("skip",3)),levels(average_relativised_pool_counts_copies_4FR$generation)[5])) +
  #scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_text(size=12),
        axis.title.y=element_text(size=12),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_text(colour="black"),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()

  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_4FR_",type,".tris.pdf"), width=20, height=12, units="cm", device="pdf", path=wd_path)


```

#####All sites, segregating only (without fixed):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_segregating_summary.txt")) %>% filter(generation!="gen5")

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR


#Plot:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,ratio!="fourfold",ratio!="tolerated"), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(aes(colour=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(average_relativised_pool_counts_copies_4FR$generation),limits = c(levels(average_relativised_pool_counts_copies_4FR$generation)[1],"skip",levels(average_relativised_pool_counts_copies_4FR$generation)[c(2:4)],c(rep("skip",3)),levels(average_relativised_pool_counts_copies_4FR$generation)[5])) +
  #scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation (AF <= 0.90 only)") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_text(size=12),
        axis.title.y=element_text(size=12),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_text(colour="black"),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()

  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_4FR_",type,"_segregating_090.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

#####All sites but correcting by ancestral fourfold:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.txt")) 
pool_counts_bis <- read_tsv(paste0(wd_path,"ancestral_counts_pool_gen0-140_",type,"_summary.txt"))
pool_counts <- cbind(select(pool_counts_bis,c(1:4)),select(pool_counts,c(5:10)))

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_A/fourfold_A,tolerated=tolerated_D/fourfold_A,deleterious=deleterious_D/fourfold_A,LoF=LoF_D/fourfold_A) %>% select(!contains(c("_V","_D","_A","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR
#write_tsv(average_relativised_pool_counts_copies_4FR,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_4FR_",type,".txt"))


#Combined version:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,ratio!="fourfold",generation!=5), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=avg_Pb_relative_value-2*se_Pb_relative_value, ymax=avg_Pb_relative_value+2*se_Pb_relative_value, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative to Pb-000\n and ancestral 4fold") +
  ylim(-0.1,1.1) +
  scale_y_continuous(breaks = seq(0.0, 1.0, by = 0.2), limits=c(0, 1.1)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle("Pools, empirical data") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_anc4FR_",type,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

#####All sites, cov≥35:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_mincov35_summary.txt")) 

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR
#write_tsv(average_relativised_pool_counts_copies_4FR,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_4FR_",type,".txt"))


#Combined version:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,ratio!="fourfold",generation!=5), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=avg_Pb_relative_value-2*se_Pb_relative_value, ymax=avg_Pb_relative_value+2*se_Pb_relative_value, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative to Pb-000") +
  ylim(-0.1,1.1) +
  scale_y_continuous(breaks = seq(0.0, 1.0, by = 0.2), limits=c(0, 1.1)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle("Pools, empirical data, min. cov. = 35x") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_4FR_",type,"_mincov35.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

#####Recombination:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))

pool_counts_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.low_recombination.txt"))
pool_counts_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.high_recombination.txt"))


####First, process the low recombination dataset####
pool_counts_low <- left_join(pool_counts_low,codes_dictionary,by=c("sample"="old"))
pool_counts_low$population = factor(pool_counts_low$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts_low$generation <- as.numeric(gsub("gen","",pool_counts_low$generation))
pool_counts_low <- pool_counts_low %>% arrange(generation)
pool_counts_low$generation = factor(pool_counts_low$generation)
pool_counts_low <- pool_counts_low %>% arrange(population,generation)

pool_counts_low_copies_4FR <- pool_counts_low %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_low_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_low_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_low_copies_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_low_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_low_copies_4FR <- mutate(pool_counts_low_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_low_copies_4FR$group = factor(relativised_pool_counts_low_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_low_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"recombination"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_low_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_low_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_low_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_low_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_low_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_low_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,"low",r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","recombination","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_low_copies_4FR <- rbind(average_relativised_pool_counts_low_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_low_copies_4FR$population = factor(average_relativised_pool_counts_low_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_low_copies_4FR$ratio = factor(average_relativised_pool_counts_low_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_low_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_low_copies_4FR$generation))
average_relativised_pool_counts_low_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_low_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_low_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_low_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_low_copies_4FR


####Next, process the high recombination dataset####
pool_counts_high <- left_join(pool_counts_high,codes_dictionary,by=c("sample"="old"))
pool_counts_high$population = factor(pool_counts_high$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts_high$generation <- as.numeric(gsub("gen","",pool_counts_high$generation))
pool_counts_high <- pool_counts_high %>% arrange(generation)
pool_counts_high$generation = factor(pool_counts_high$generation)
pool_counts_high <- pool_counts_high %>% arrange(population,generation)

pool_counts_high_copies_4FR <- pool_counts_high %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_high_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_high_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_high_copies_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_high_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_high_copies_4FR <- mutate(pool_counts_high_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_high_copies_4FR$group = factor(relativised_pool_counts_high_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_high_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"recombination"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_high_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_high_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_high_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_high_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_high_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_high_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,"high",r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","recombination","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_high_copies_4FR <- rbind(average_relativised_pool_counts_high_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_high_copies_4FR$population = factor(average_relativised_pool_counts_high_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_high_copies_4FR$ratio = factor(average_relativised_pool_counts_high_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_high_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_high_copies_4FR$generation))
average_relativised_pool_counts_high_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_high_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_high_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_high_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_high_copies_4FR


####Then combine both datasets####
average_relativised_pool_counts_combined_copies_4FR <- rbind(average_relativised_pool_counts_low_copies_4FR,average_relativised_pool_counts_high_copies_4FR)
average_relativised_pool_counts_combined_copies_4FR$recombination = factor(average_relativised_pool_counts_combined_copies_4FR$recombination,levels=c("low","high"))


####Then plot the data####
#Combined version:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot_recvert <- ggplot(data=filter(average_relativised_pool_counts_combined_copies_4FR,ratio!="fourfold", generation!=5), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +  
  #geom_line(aes(colour=recombination, group=interaction(recombination, population)),alpha=0.5,size=0.5) +
  geom_point(aes(colour=recombination,shape=population),size=2,position=position_dodge(0.4)) +
  geom_errorbar(aes(ymin=avg_Pb_relative_value-2*se_Pb_relative_value, ymax=avg_Pb_relative_value+2*se_Pb_relative_value, colour=recombination,group=interaction(population,recombination)), position=position_dodge(0.4),size=0.5,width=0.5) +
  ylab("Derived count\n relative to Pb-000 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.5, 1.0, by = 0.1)) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.4,1.1) +
  ggtitle("Pools") +
  #guides(colour="none") +
  labs(colour = "Recombination", shape = "Population") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_text()
  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot_recvert
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_4FR_",type,".all_recombination.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

####Rarefied Pb and line averages (combined version):
#####Not relative to Pb-000:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

depth <- 30
type <- "autosomes" #all #autosomes #Xchr

wd_path <- paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/rarefied/depth",depth,"/")
pool_counts <- read_tsv(paste0(wd_path,"rarefied_depth_",depth,"_counts_pool_gen0-140_",type,"_summary.txt")) 

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T) %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_counts_copies_4FR$group = factor(pool_counts_copies_4FR$group,levels=c("Pb","lines"))
pool_counts_copies_4FR

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_value","se_value")
      average_pool_counts_copies_4FR <- rbind(average_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_pool_counts_copies_4FR$population = factor(average_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_pool_counts_copies_4FR$ratio = factor(average_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_pool_counts_copies_4FR$generation))
average_pool_counts_copies_4FR$avg_value <- as.numeric(average_pool_counts_copies_4FR$avg_value)
average_pool_counts_copies_4FR$se_value <- as.numeric(average_pool_counts_copies_4FR$se_value)
average_pool_counts_copies_4FR
#write_tsv(average_relativised_pool_counts_copies_4FR,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_4FR_",type,".txt"))


#Combined version:
Pb_lines_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_pool_counts_copies_4FR,ratio!="fourfold", generation!=5), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_wrap(. ~ ratio, scales="free") +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count") +
  #ylim(-0.1,1.1) +
  #scale_y_continuous(breaks = seq(0.0, 1.0, by = 0.2), limits=c(0, 1.1)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle(paste0("Pools, rarefied data (cov. ",depth,")")) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_pool_counts_copies_4FR_ggplot
ggsave(paste0("rarefied_depth_",depth,"_Pb_lines_pool_counts_copies_4FR_",type,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

#####Relative to Pb-000:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

depth <- 30
type <- "autosomes" #all #autosomes #Xchr

wd_path <- paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/rarefied/depth",depth,"/")
pool_counts <- read_tsv(paste0(wd_path,"rarefied_depth_",depth,"_counts_pool_gen0-140_",type,"_summary.txt")) 

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR
#write_tsv(average_relativised_pool_counts_copies_4FR,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_4FR_",type,".txt"))


#Combined version:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,ratio!="fourfold", generation!=5), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=avg_Pb_relative_value-se_Pb_relative_value, ymax=avg_Pb_relative_value+se_Pb_relative_value, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative to Pb-000") +
  ylim(-0.1,1.1) +
  scale_y_continuous(breaks = seq(0.0, 1.0, by = 0.2), limits=c(0, 1.1)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle(paste0("Pools, rarefied data (cov. ",depth,")")) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("rarefied_depth_",depth,"_Pb_lines_relativised_pool_counts_copies_4FR_",type,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

####Simulations:
#####Simulations Pb and line averages (combined version):
######Simulated counts, without replicate errors:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


#To make the input file work, do the following:
#FILE=
#cat ${FILE} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${FILE/.dat/.txt}

parameters <- "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5_s0.05_s0.5_aditive"

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/")
pool_counts <- read_tsv(paste0(wd_path,"derived_count_",parameters,".txt")) 

#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==80) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR
#write_tsv(average_relativised_pool_counts_copies_4FR,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_4FR_",type,".txt"))


#Combined version:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,ratio!="fourfold", generation!=5), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=avg_Pb_relative_value-2*se_Pb_relative_value, ymax=avg_Pb_relative_value+2*se_Pb_relative_value, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Simulated derived count relative to Pb-080") +
  ylim(-0.1,1.1) +
  scale_y_continuous(breaks = seq(0.0, 1.0, by = 0.2), limits=c(0, 1.1)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle(parameters) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(size=10, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("simulations_Pb_lines_relativised_pool_counts_copies_4FR_",parameters,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

######Simulated counts, with replicate errors:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


#To make the input file work, do the following:
#FILE=
#cat ${FILE} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${FILE/.dat/.txt}

parameters <- "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5_s0.05.s0.5"

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/")
pool_counts <- read_tsv(paste0(wd_path,"derived_count_",parameters,".txt")) 

#Averages:
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==80) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR


#Errors:
pool_errors <- read_tsv(paste0(wd_path,"derived_count_var_",parameters,".txt")) %>% filter(replicate=="average") %>% rename(population = replicate)
pool_errors$population <- gsub("average","lines",pool_errors$population)
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

lines_120_fourfold_D_mean <- pool_counts %>% filter(population!="Pb", generation=="120") %>% select(fourfold_D) %>% unlist(use.names=F) %>% mean()
lines_220_fourfold_D_mean <- pool_counts %>% filter(population!="Pb", generation=="220") %>% select(fourfold_D) %>% unlist(use.names=F) %>% mean()
pool_errors$counts_fourfold_D <- c(lines_120_fourfold_D_mean,lines_220_fourfold_D_mean)


pool_errors_copies_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains(c("_V","_D"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies_4FR

relativised_pool_errors_copies_4FR <- mutate(pool_errors_copies_4FR, Pb_relative_value=value/r_average_errors)


combined_tidy <- left_join(average_relativised_pool_counts_copies_4FR[,c(1:4)],relativised_pool_errors_copies_4FR[,c(1:3,5)],by=c("population","generation","ratio"))
colnames(combined_tidy) <- c("population","generation","ratio","mean","error")


#Combined version:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(combined_tidy,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Simulated derived count\n relative to Pb-080 4-fold syn.") +
  ylim(0,1.4) +
  scale_y_continuous(breaks = seq(0.0, 1.6, by = 0.2), limits=c(0, 1.6)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle(parameters) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(size=10, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("simulations_Pb_lines_relativised_pool_counts_copies_4FR_",parameters,".repl_errors.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

######Simulated average of ratios, with replicate errors:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The double ratio average is also obtained across replicates.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#FILES=$(ls derived_count*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral_No_mutation", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive_No_mutation", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_No_mutation", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,"derived_count_relative_",parameters,".txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies <- pool_counts %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies <- pool_counts_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_counts_copies$group = factor(pool_counts_copies$group,levels=c("Pb","lines"))
pool_counts_copies

#Errors:
pool_errors <- read_tsv(paste0(wd_path,"derived_count_se_relative_",parameters,".txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies

#Combined:
combined_tidy <- left_join(pool_counts_copies,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,value.x,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral_No_mutation") {
  average_combined_tidy_neutral_nonewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral") {
  average_combined_tidy_neutral_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive_No_mutation") {
  average_combined_tidy_additive_nonewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive") {
  average_combined_tidy_additive_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_No_mutation") {
  average_combined_tidy_purging_nonewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") {
  average_combined_tidy_purging_withnewmut <- average_combined_tidy_bis
}
}

#Plot the data (each model separately):
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral_No_mutation") {
  plot_title <- "neutral model, excluding new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral") {
  plot_title <- "neutral model, including new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive_No_mutation") {
  plot_title <- "additive model, excluding new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive") {
  plot_title <- "additive model, including new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_No_mutation") {
  plot_title <- "purge model, excluding new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") {
  plot_title <- "purge model, including new mutation"
}

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(average_combined_tidy,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.8),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  #scale_shape_manual(values=c(1,16)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle(plot_title) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(linewidth=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10, angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(size=10, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", linewidth=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("simulations_Pb_lines_relativised_pool_counts_copies_4FR_",parameters,".repl_errors.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)


#Plot the data (all models combined):
  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_nonewmut <- ggplot(data=filter(average_combined_tidy_neutral_nonewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Excluding new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_nonewmut

  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut <- ggplot(data=filter(average_combined_tidy_neutral_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0,-4),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_nonewmut <- ggplot(data=filter(average_combined_tidy_additive_nonewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Excluding new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_nonewmut

  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut <- ggplot(data=filter(average_combined_tidy_additive_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0,0),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.95,0.95,0.95),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut

  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_nonewmut <- ggplot(data=filter(average_combined_tidy_purging_nonewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Excluding new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.5,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_nonewmut
  
  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut <- ggplot(data=filter(average_combined_tidy_purging_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.5,-4),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_nonewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_nonewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_nonewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.38,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-083 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2),right=textGrob(expression(bold("  Neutral model                                             Additive model                                          Purging model")),rot=-90,gp=gpar(fontsize=10,fontface="bold"),x=-5,vjust=0))

ggsave("20231201_main_simulations.pdf", width=20.5, height=22.6, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/",ggplot_combined)

#Stop
STOP

```

######Simulated ratio of averages, with replicate errors (excl and incl new mut):
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/
#FILES=$(ls derived_count_L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral_No_mutation", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive_No_mutation", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_No_mutation", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,"derived_count_",parameters,".txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,"derived_count_se_relative_",parameters,".txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral_No_mutation") {
  average_combined_tidy_neutral_nonewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral") {
  average_combined_tidy_neutral_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive_No_mutation") {
  average_combined_tidy_additive_nonewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive") {
  average_combined_tidy_additive_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_No_mutation") {
  average_combined_tidy_purging_nonewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") {
  average_combined_tidy_purging_withnewmut <- average_combined_tidy_bis
}
}

#Plot the data (each model separately):
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral_No_mutation") {
  plot_title <- "neutral model, excluding new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral") {
  plot_title <- "neutral model, including new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive_No_mutation") {
  plot_title <- "additive model, excluding new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive") {
  plot_title <- "additive model, including new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_No_mutation") {
  plot_title <- "purge model, excluding new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") {
  plot_title <- "purge model, including new mutation"
}

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(average_combined_tidy,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.8),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  #scale_shape_manual(values=c(1,16)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle(plot_title) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(linewidth=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10, angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(size=10, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", linewidth=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot
#ggsave(paste0("simulations_Pb_lines_relativised_pool_counts_copies_4FR_",parameters,".repl_errors.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)


#Plot the data (all models combined):
  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_nonewmut <- ggplot(data=filter(average_combined_tidy_neutral_nonewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Excluding new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_nonewmut

  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut <- ggplot(data=filter(average_combined_tidy_neutral_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0,-4),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_nonewmut <- ggplot(data=filter(average_combined_tidy_additive_nonewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Excluding new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_nonewmut

  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut <- ggplot(data=filter(average_combined_tidy_additive_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0,0),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.95,0.95,0.95),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut

  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_nonewmut <- ggplot(data=filter(average_combined_tidy_purging_nonewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Excluding new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.5,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_nonewmut
  
  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut <- ggplot(data=filter(average_combined_tidy_purging_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.5,-4),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_nonewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_nonewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_nonewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.38,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-083 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2),right=textGrob(expression(bold("  Neutral model                                             Additive model                                          Purging model")),rot=-90,gp=gpar(fontsize=10,fontface="bold"),x=-5,vjust=0))

ggsave("20231211_main_simulations.ratio_of_averages.pdf", width=20.5, height=22.6, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/",ggplot_combined)

#Stop
STOP

```

######!Simulated ratio of averages, with replicate errors (incl new mut only):
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/
#FILES=$(ls derived_count_L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,"derived_count_",parameters,".txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,"derived_count_se_relative_",parameters,".txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral") {
  average_combined_tidy_neutral_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive") {
  average_combined_tidy_additive_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") {
  average_combined_tidy_purging_withnewmut <- average_combined_tidy_bis
}
}


#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut <- ggplot(data=filter(average_combined_tidy_neutral_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0,-2.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        #plot.title=element_text(hjust=0.5),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut <- ggplot(data=filter(average_combined_tidy_additive_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.3,1.15),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.75,0.95,0.75),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut
  
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut <- ggplot(data=filter(average_combined_tidy_purging_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.5,-2.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut,width=unit(6,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut,width=unit(6,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut,width=unit(6,"cm"),height=unit(6,"cm")),ncol=1,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.38,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")), rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=2),right=textGrob(expression(bold("Neutral model                                         Additive model                                      Purging model")),rot=-90,gp=gpar(fontsize=11,fontface="bold"),x=-5,vjust=0,hjust=0.51))

ggsave("20240315_main_simulations.ratio_of_averages.syn_wout.pdf", width=18, height=22.5, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/",ggplot_combined)

#Stop
STOP

```

######!Simulated ratio of averages, with replicate errors (incl new mut only, different s thresholds):
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/s0.s0.05.s0.9/
#FILES=$(ls *derived_count*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/s0.s0.05.s0.9/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,".derived_count.txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,".derived_count_se_rel.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral") {
  average_combined_tidy_neutral_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive") {
  average_combined_tidy_additive_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") {
  average_combined_tidy_purging_withnewmut <- average_combined_tidy_bis
}
}


#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut <- ggplot(data=filter(average_combined_tidy_neutral_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0,-2.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        #plot.title=element_text(hjust=0.5),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut <- ggplot(data=filter(average_combined_tidy_additive_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.3,1.15),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.75,0.95,0.75),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut
  
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut <- ggplot(data=filter(average_combined_tidy_purging_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.5,-2.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut,width=unit(6,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut,width=unit(6,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut,width=unit(6,"cm"),height=unit(6,"cm")),ncol=1,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.38,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")), rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=2),right=textGrob(expression(bold("Neutral model                                         Additive model                                      Purging model")),rot=-90,gp=gpar(fontsize=11,fontface="bold"),x=-5,vjust=0,hjust=0.51))

ggsave(paste0("20240401_simulations_Pb12_rel.",parameters_list[3],".Additive.Neutral.ratio_of_averages.pdf"), width=18, height=22.5, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/s0.s0.05.s0.9/",ggplot_combined)

#Stop
STOP

```

######Simulated ratio of averages, with replicate errors (extra additive):
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/
#FILES=$(ls LAd*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/")

parameters_list <- c("LAd0.05.L0.04.L_lethal0.015.K2000.beta0.33.s0.2.h0.283.Purging_derived_count", "LAd0.08.L0.04.L_lethal0.015.K2000.beta0.33.s0.2.h0.283.Purging_derived_count") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,".txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_se_relative.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0


#Plot the data:
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_extra_additive <- ggplot(data=filter(average_combined_tidy_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Simulated derived count\n relative to Pb-083 and 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle(paste0("Extra additive ", substr(parameters,1,7))) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        #axis.title.x=element_blank(),
        #axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        #axis.text.x=element_blank(),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        #plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_extra_additive
ggsave(paste0("simulations_Pb_lines_relativised_pool_counts_copies_4FR_",parameters,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)
}


```

######Simulated ratio of averages (4fold without new mutation), with replicate errors:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/
#FILES=$(ls derived_count_L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral_No_mutation", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive_No_mutation", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_No_mutation", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
if (grepl("No_mutation",parameters)==F) {
  pool_counts <- cbind(read_tsv(paste0(wd_path,"derived_count_",parameters,"_No_mutation.txt")) %>% select(c(1:4)), read_tsv(paste0(wd_path,"derived_count_",parameters,".txt")) %>% select(c(5:10)))
} else {
  pool_counts <- read_tsv(paste0(wd_path,"derived_count_",parameters,".txt"))
}

pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,"derived_count_se_relative_",parameters,".txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral_No_mutation") {
  average_combined_tidy_neutral_nonewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral") {
  average_combined_tidy_neutral_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive_No_mutation") {
  average_combined_tidy_additive_nonewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive") {
  average_combined_tidy_additive_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_No_mutation") {
  average_combined_tidy_purging_nonewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") {
  average_combined_tidy_purging_withnewmut <- average_combined_tidy_bis
}
}

#Plot the data (all models combined):
  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_nonewmut <- ggplot(data=filter(average_combined_tidy_neutral_nonewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Excluding new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_nonewmut

  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut_syn_wout <- ggplot(data=filter(average_combined_tidy_neutral_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0,-4),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut_syn_wout

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_nonewmut <- ggplot(data=filter(average_combined_tidy_additive_nonewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Excluding new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_nonewmut

  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut_syn_wout <- ggplot(data=filter(average_combined_tidy_additive_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0,0),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.95,0.95,0.95),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut_syn_wout

  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_nonewmut <- ggplot(data=filter(average_combined_tidy_purging_nonewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Excluding new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.5,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_nonewmut
  
  Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut_syn_wout <- ggplot(data=filter(average_combined_tidy_purging_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.5,-4),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut_syn_wout


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_nonewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut_syn_wout,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_nonewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut_syn_wout,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_nonewmut,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut_syn_wout,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.38,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-083 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2),right=textGrob(expression(bold("  Neutral model                                             Additive model                                          Purging model")),rot=-90,gp=gpar(fontsize=10,fontface="bold"),x=-5,vjust=0))

ggsave("20231211_main_simulations.ratio_of_averages.syn_wout.pdf", width=20.5, height=22.6, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/",ggplot_combined)

#Stop
STOP

```

#####Simulations Pb and line averages (separate version):
######Simulated counts, without errors:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


#To make the input file work, do the following:
#FILE=
#cat ${FILE} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${FILE/.dat/.txt}

parameters <- "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283_s0.05.s0.5_neutral"
wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/")

#Averages:
pool_counts <- read_tsv(paste0(wd_path,"derived_count_",parameters,".txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
#r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==80) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  #r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
#print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR
colnames(average_relativised_pool_counts_copies_4FR) <- c("population","generation","ratio","mean","error")


#Plot the data:
#Humberto version (Pb):
Pb_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,population=="Pb",ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Simulated derived count\n relative to Pb-080 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.6, by = 0.2)) +
  scale_x_discrete(breaks = levels(average_relativised_pool_counts_copies_4FR$generation),limits = c(levels(average_relativised_pool_counts_copies_4FR$generation)[1],"skip",levels(average_relativised_pool_counts_copies_4FR$generation)[c(2:4)],c(rep("skip",3)),levels(average_relativised_pool_counts_copies_4FR$generation)[5])) +
  ylim(0,1.6) +
  ggtitle(paste0("Pb; ",parameters)) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(size=12),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("simulations_Pb_relativised_pool_counts_copies_4FR_",parameters,".no_errors.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

 #Humberto version (lines):
lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,population=="lines",ratio!="fourfold",ratio!="tolerated"), aes(ratio,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ generation) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.8)) + 
  #geom_errorbar(aes(ymin=avg_Pb_relative_value-se_Pb_relative_value, ymax=avg_Pb_relative_value+se_Pb_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  ylab("Simulated derived count\n relative to Pb-080 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 1.4, by = 0.2)) +
  ylim(0,1.6) +
  ggtitle(paste0("Lines; ",parameters)) +
  #guides(colour="none") +
  #labs(colour = "Generation") +
  scale_colour_manual(values=c(hue_pal()(5)[4:5])) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(size=12),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("simulations_lines_relativised_pool_counts_copies_4FR_",parameters,".no_errors.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

######Simulated counts, with replicate errors:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


#To make the input file work, do the following:
#FILE=
#cat ${FILE} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${FILE/.dat/.txt}

parameters <- "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5_s0.05.s0.5_sinmut"

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/")
pool_counts <- read_tsv(paste0(wd_path,"derived_count_",parameters,".txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==80) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR


#Errors:
pool_errors <- read_tsv(paste0(wd_path,"derived_count_var_",parameters,".txt")) %>% filter(replicate=="average") %>% rename(population = replicate)
pool_errors$population <- gsub("average","lines",pool_errors$population)
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

lines_120_fourfold_D_mean <- pool_counts %>% filter(population!="Pb", generation=="120") %>% select(fourfold_D) %>% unlist(use.names=F) %>% mean()
lines_220_fourfold_D_mean <- pool_counts %>% filter(population!="Pb", generation=="220") %>% select(fourfold_D) %>% unlist(use.names=F) %>% mean()
pool_errors$counts_fourfold_D <- c(lines_120_fourfold_D_mean,lines_220_fourfold_D_mean)


pool_errors_copies_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains(c("_V","_D"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies_4FR

relativised_pool_errors_copies_4FR <- mutate(pool_errors_copies_4FR, Pb_relative_value=value/r_average_errors)


combined_tidy <- left_join(average_relativised_pool_counts_copies_4FR[,c(1:4)],relativised_pool_errors_copies_4FR[,c(1:3,5)],by=c("population","generation","ratio"))
colnames(combined_tidy) <- c("population","generation","ratio","mean","error")


#Plot the data:
#Humberto version (Pb):
Pb_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy,population=="Pb",ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Simulated derived count\n relative to Pb-080 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.6, by = 0.2)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ylim(0,1.6) +
  ggtitle(paste0("Pb; ",parameters)) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(size=12),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("simulations_Pb_relativised_pool_counts_copies_4FR_",parameters,".repl_errors.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)



 #Humberto version (lines):
lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy,population=="lines",ratio!="fourfold",ratio!="tolerated"), aes(ratio,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ generation) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.8)) + 
  #geom_errorbar(aes(ymin=avg_Pb_relative_value-se_Pb_relative_value, ymax=avg_Pb_relative_value+se_Pb_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  ylab("Simulated derived count\n relative to Pb-080 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 1.4, by = 0.2)) +
  ylim(0,1.6) +
  ggtitle(paste0("Lines; ",parameters)) +
  #guides(colour="none") +
  #labs(colour = "Generation") +
  scale_colour_manual(values=c(hue_pal()(5)[4:5])) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(size=12),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
lines_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("simulations_lines_relativised_pool_counts_copies_4FR_",parameters,".repl_errors.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

######Simulated ratios, with replicate errors:
```{r Plot variant count results}

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#FILE=
#cat ${FILE} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${FILE/.dat/.txt}

parameters <- "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283_sinmut"
#L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283_neutral_sinmut #L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283_neutral #L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5_sinmut #L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5 #L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283_sinmut #L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/")

#Averages:
pool_counts <- read_tsv(paste0(wd_path,"derived_count_relative_",parameters,".txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies <- pool_counts %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies <- pool_counts_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_counts_copies$group = factor(pool_counts_copies$group,levels=c("Pb","lines"))
pool_counts_copies

#Errors:
pool_errors <- read_tsv(paste0(wd_path,"derived_count_var_relative_",parameters,".txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
  line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies

#Combined:
combined_tidy <- left_join(pool_counts_copies,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,value.x,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy[is.nan(average_combined_tidy)] <- 0

#Hardcode plot titles:
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283_neutral_sinmut") {
  plot_title <- "neutral model, excluding new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283_neutral") {
  plot_title <- "neutral model, including new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5_sinmut") {
  plot_title <- "additive model, excluding new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5") {
  plot_title <- "additive model, including new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283_sinmut") {
  plot_title <- "purge model, excluding new mutation"
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283") {
  plot_title <- "purge model, including new mutation"
}


#Plot the data:
#Humberto version (Pb):
Pb_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(average_combined_tidy,population=="Pb",ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ylim(0,2) +
  ggtitle(paste0("Pb, ",plot_title)) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(size=12),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("simulations_Pb_relativised_pool_counts_copies_4FR_",parameters,".repl_errors.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

#Humberto version (lines):
lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(average_combined_tidy,population=="lines",ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.8)) + 
  #geom_errorbar(aes(ymin=avg_Pb_relative_value-se_Pb_relative_value, ymax=avg_Pb_relative_value+se_Pb_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  ggtitle(paste0("Lines, ",plot_title)) +
  #guides(colour="none") +
  #labs(colour = "Generation") +
  scale_colour_manual(values=c(hue_pal()(5)[4:5])) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(size=12),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
lines_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("simulations_lines_relativised_pool_counts_copies_4FR_",parameters,".repl_errors.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

###Absolute counts:
####Empirical:
#####Derived Pb and line averages (combined version):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.txt")) %>% filter(generation!="gen5")

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_absolute <- pool_counts %>% mutate(synonymous=`non-fourfold_D`+fourfold_D,fourfold=fourfold_D,missense=tolerated_D+deleterious_D,deleterious=deleterious_D,LoF=LoF_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(count,value,-generation,-population,factor_key=T) %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_counts_copies_absolute$group = factor(pool_counts_copies_absolute$group,levels=c("Pb","lines"))
pool_counts_copies_absolute

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_pool_counts_copies_absolute <- data_frame("population"=character(0),"generation"=character(0),"count"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(pool_counts_copies_absolute$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(pool_counts_copies_absolute,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(pool_counts_copies_absolute$count)) {
      print(r)
      pop_mean <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","count","avg_value","se_value")
      average_pool_counts_copies_absolute <- rbind(average_pool_counts_copies_absolute,row_data,stringsAsFactors=F)
    }
  }
}
average_pool_counts_copies_absolute$population = factor(average_pool_counts_copies_absolute$population,levels=c("Pb","lines"))
average_pool_counts_copies_absolute$count = factor(average_pool_counts_copies_absolute$count,levels=c("synonymous","fourfold","missense","deleterious","LoF"))
average_pool_counts_copies_absolute$generation <- as.factor(as.numeric(average_pool_counts_copies_absolute$generation))
average_pool_counts_copies_absolute$avg_value <- as.numeric(average_pool_counts_copies_absolute$avg_value)
average_pool_counts_copies_absolute$se_value <- as.numeric(average_pool_counts_copies_absolute$se_value)
average_pool_counts_copies_absolute
#write_tsv(average_relativised_pool_counts_copies_absolute,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_absolute_",type,".txt"))


#Combined version:
average_pool_counts_copies_absolute_bis <- average_pool_counts_copies_absolute
average_pool_counts_copies_absolute_bis$generation <- as.numeric(as.character(average_pool_counts_copies_absolute_bis$generation))
average_pool_counts_copies_absolute_bis$count <- factor(average_pool_counts_copies_absolute_bis$count, levels = c("synonymous", "fourfold", "missense", "deleterious", "LoF"), labels = c("synonymous", "s. fourfold", "missense", "m. deleterious", "LoF"))
Pb_lines_pool_counts_copies_absolute_ggplot <- ggplot(data=average_pool_counts_copies_absolute_bis, aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_wrap(. ~ count, scales="free", nrow = 1) +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value, group=population), position=position_dodge(6),size=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) +
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count") +
  #ylim(-0.1,1.1) +
  #scale_y_continuous(breaks = seq(0.0, 1.0, by = 0.2), limits=c(0, 1.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(average_pool_counts_copies_absolute$generation),limits = c(levels(average_pool_counts_copies_absolute$generation)[1],"skip",levels(average_pool_counts_copies_absolute$generation)[c(2:4)],c(rep("skip",3)),levels(average_pool_counts_copies_absolute$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  #ggtitle("Absolute count of derived copies") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=8,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=11,colour="black"),
        axis.title=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=9,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_pool_counts_copies_absolute_ggplot
ggsave(paste0("Pb_lines_pool_counts_dercopies_absolute_",type,".pdf"), width=25, height=12, units="cm", device="pdf", path=wd_path)


```

#####Ancestral Pb and line averages (combined version):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
pool_counts <- read_tsv(paste0(wd_path,"ancestral_counts_pool_gen0-140_",type,"_summary.txt")) 

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_absolute <- pool_counts %>% mutate(fourfold=fourfold_A,tolerated=tolerated_A,deleterious=deleterious_A,LoF=LoF_A) %>% select(!contains(c("_V","_A","sample"))) %>% gather(count,value,-generation,-population,factor_key=T) %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_counts_copies_absolute$group = factor(pool_counts_copies_absolute$group,levels=c("Pb","lines"))
pool_counts_copies_absolute

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_pool_counts_copies_absolute <- data_frame("population"=character(0),"generation"=character(0),"count"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(pool_counts_copies_absolute$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(pool_counts_copies_absolute,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(pool_counts_copies_absolute$count)) {
      print(r)
      pop_mean <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","count","avg_value","se_value")
      average_pool_counts_copies_absolute <- rbind(average_pool_counts_copies_absolute,row_data,stringsAsFactors=F)
    }
  }
}
average_pool_counts_copies_absolute$population = factor(average_pool_counts_copies_absolute$population,levels=c("Pb","lines"))
average_pool_counts_copies_absolute$count = factor(average_pool_counts_copies_absolute$count,levels=c("fourfold","tolerated","deleterious","LoF"))
average_pool_counts_copies_absolute$generation <- as.factor(as.numeric(average_pool_counts_copies_absolute$generation))
average_pool_counts_copies_absolute$avg_value <- as.numeric(average_pool_counts_copies_absolute$avg_value)
average_pool_counts_copies_absolute$se_value <- as.numeric(average_pool_counts_copies_absolute$se_value)
average_pool_counts_copies_absolute
#write_tsv(average_relativised_pool_counts_copies_absolute,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_absolute_",type,".txt"))


#Combined version:
Pb_lines_pool_counts_copies_absolute_ggplot <- ggplot(data=filter(average_pool_counts_copies_absolute, generation!=5), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_wrap(. ~ count, scales="free", nrow = 1) +
  geom_errorbar(aes(ymin=avg_value-2*se_value, ymax=avg_value+2*se_value, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Ancestral count") +
  #ylim(-0.1,1.1) +
  #scale_y_continuous(breaks = seq(0.0, 1.0, by = 0.2), limits=c(0, 1.1)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle("Absolute count of ancestral copies") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_pool_counts_copies_absolute_ggplot
ggsave(paste0("Pb_lines_pool_counts_anccopies_absolute_",type,".pdf"), width=25, height=12, units="cm", device="pdf", path=wd_path)

```

#####Total (ancestral+derived) Pb and line averages (combined version):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
pool_counts <- read_tsv(paste0(wd_path,"ancestralplusderived_counts_pool_gen0-140_",type,"_summary.txt")) 

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_absolute <- pool_counts %>% mutate(fourfold=fourfold_T,tolerated=tolerated_T,deleterious=deleterious_T,LoF=LoF_T) %>% select(!contains(c("_V","_T","sample"))) %>% gather(count,value,-generation,-population,factor_key=T) %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_counts_copies_absolute$group = factor(pool_counts_copies_absolute$group,levels=c("Pb","lines"))
pool_counts_copies_absolute

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_pool_counts_copies_absolute <- data_frame("population"=character(0),"generation"=character(0),"count"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(pool_counts_copies_absolute$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(pool_counts_copies_absolute,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(pool_counts_copies_absolute$count)) {
      print(r)
      pop_mean <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","count","avg_value","se_value")
      average_pool_counts_copies_absolute <- rbind(average_pool_counts_copies_absolute,row_data,stringsAsFactors=F)
    }
  }
}
average_pool_counts_copies_absolute$population = factor(average_pool_counts_copies_absolute$population,levels=c("Pb","lines"))
average_pool_counts_copies_absolute$count = factor(average_pool_counts_copies_absolute$count,levels=c("fourfold","tolerated","deleterious","LoF"))
average_pool_counts_copies_absolute$generation <- as.factor(as.numeric(average_pool_counts_copies_absolute$generation))
average_pool_counts_copies_absolute$avg_value <- as.numeric(average_pool_counts_copies_absolute$avg_value)
average_pool_counts_copies_absolute$se_value <- as.numeric(average_pool_counts_copies_absolute$se_value)
average_pool_counts_copies_absolute
#write_tsv(average_relativised_pool_counts_copies_absolute,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_absolute_",type,".txt"))


#Combined version:
Pb_lines_pool_counts_copies_absolute_ggplot <- ggplot(data=filter(average_pool_counts_copies_absolute, generation!=5), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_wrap(. ~ count, scales="free", nrow = 1) +
  geom_errorbar(aes(ymin=avg_value-2*se_value, ymax=avg_value+2*se_value, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Total count") +
  #ylim(-0.1,1.1) +
  #scale_y_continuous(breaks = seq(0.0, 1.0, by = 0.2), limits=c(0, 1.1)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle("Absolute count of total (ancestral + derived) copies") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_pool_counts_copies_absolute_ggplot
ggsave(paste0("Pb_lines_pool_counts_totcopies_absolute_",type,".pdf"), width=25, height=12, units="cm", device="pdf", path=wd_path)

```

####Rarefied:
#####Derived Pb and line averages (combined version):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

depth <- 30
type <- "autosomes" #all #autosomes #Xchr

wd_path <- paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/rarefied/depth",depth,"/")
pool_counts <- read_tsv(paste0(wd_path,"rarefied_depth_",depth,"_counts_pool_gen0-140_",type,"_summary.txt")) %>% filter(generation!="gen5")

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_absolute <- pool_counts %>% mutate(fourfold=fourfold_D,tolerated=tolerated_D,deleterious=deleterious_D,LoF=LoF_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(count,value,-generation,-population,factor_key=T) %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_counts_copies_absolute$group = factor(pool_counts_copies_absolute$group,levels=c("Pb","lines"))
pool_counts_copies_absolute

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_pool_counts_copies_absolute <- data_frame("population"=character(0),"generation"=character(0),"count"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(pool_counts_copies_absolute$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(pool_counts_copies_absolute,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(pool_counts_copies_absolute$count)) {
      print(r)
      pop_mean <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","count","avg_value","se_value")
      average_pool_counts_copies_absolute <- rbind(average_pool_counts_copies_absolute,row_data,stringsAsFactors=F)
    }
  }
}
average_pool_counts_copies_absolute$population = factor(average_pool_counts_copies_absolute$population,levels=c("Pb","lines"))
average_pool_counts_copies_absolute$count = factor(average_pool_counts_copies_absolute$count,levels=c("fourfold","tolerated","deleterious","LoF"))
average_pool_counts_copies_absolute$generation <- as.factor(as.numeric(average_pool_counts_copies_absolute$generation))
average_pool_counts_copies_absolute$avg_value <- as.numeric(average_pool_counts_copies_absolute$avg_value)
average_pool_counts_copies_absolute$se_value <- as.numeric(average_pool_counts_copies_absolute$se_value)
average_pool_counts_copies_absolute
#write_tsv(average_relativised_pool_counts_copies_absolute,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_absolute_",type,".txt"))

#Combined version:
Pb_lines_pool_counts_copies_absolute_ggplot <- ggplot(data=filter(average_pool_counts_copies_absolute,count!="tolerated",generation!=5), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_wrap(. ~ count, scales="free", nrow = 1) +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count") +
  #ylim(-0.1,1.1) +
  #scale_y_continuous(breaks = seq(0.0, 1.0, by = 0.2), limits=c(0, 1.1)) +
  scale_x_discrete(breaks = levels(average_pool_counts_copies_absolute$generation),limits = c(levels(average_pool_counts_copies_absolute$generation)[1],"skip",levels(average_pool_counts_copies_absolute$generation)[c(2:4)],c(rep("skip",3)),levels(average_pool_counts_copies_absolute$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle(paste0("Pools, rarefied data (cov. ",depth,")")) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_pool_counts_copies_absolute_ggplot
ggsave(paste0("rarefied_depth_",depth,"_Pb_lines_pool_counts_copies_absolute_",type,".pdf"), width=25, height=12, units="cm", device="pdf", path=wd_path)

```

###Proportion of derived counts:
####Empirical Pb and line averages (combined version):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
pool_counts <- read_tsv(paste0(wd_path,"proportion_pool_gen0-140_",type,"_summary.txt")) 

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_absolute <- pool_counts %>% mutate(fourfold=fourfold_P,tolerated=tolerated_P,deleterious=deleterious_P,LoF=LoF_P) %>% select(!contains(c("_V","_P","sample"))) %>% gather(count,value,-generation,-population,factor_key=T) %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_counts_copies_absolute$group = factor(pool_counts_copies_absolute$group,levels=c("Pb","lines"))
pool_counts_copies_absolute

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_pool_counts_copies_absolute <- data_frame("population"=character(0),"generation"=character(0),"proportion"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(pool_counts_copies_absolute$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(pool_counts_copies_absolute,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(pool_counts_copies_absolute$count)) {
      print(r)
      pop_mean <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","proportion","avg_value","se_value")
      average_pool_counts_copies_absolute <- rbind(average_pool_counts_copies_absolute,row_data,stringsAsFactors=F)
    }
  }
}
average_pool_counts_copies_absolute$population = factor(average_pool_counts_copies_absolute$population,levels=c("Pb","lines"))
average_pool_counts_copies_absolute$proportion = factor(average_pool_counts_copies_absolute$proportion,levels=c("fourfold","tolerated","deleterious","LoF"))
average_pool_counts_copies_absolute$generation <- as.factor(as.numeric(average_pool_counts_copies_absolute$generation))
average_pool_counts_copies_absolute$avg_value <- as.numeric(average_pool_counts_copies_absolute$avg_value)
average_pool_counts_copies_absolute$se_value <- as.numeric(average_pool_counts_copies_absolute$se_value)
average_pool_counts_copies_absolute
#write_tsv(average_relativised_pool_counts_copies_absolute,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_absolute_",type,".txt"))


#Combined version:
Pb_lines_pool_proportion_ggplot <- ggplot(data=filter(average_pool_counts_copies_absolute, generation!=5), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ proportion) +
  geom_errorbar(aes(ymin=avg_value-2*se_value, ymax=avg_value+2*se_value, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Proportion of derived alleles") +
  ylim(-0.1,1.1) +
  scale_y_continuous(breaks = seq(0.0, 0.5, by = 0.1), limits=c(0, 0.5)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle("Pools, empirical data") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_pool_proportion_ggplot
ggsave(paste0("Pb_lines_proportion_",type,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

####Rarefied Pb and line averages (combined version):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

depth <- 30
type <- "autosomes" #all #autosomes #Xchr

wd_path <- paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/rarefied/depth",depth,"/")
pool_counts <- read_tsv(paste0(wd_path,"rarefied_depth_",depth,"_proportion_pool_gen0-140_",type,"_summary.txt")) 

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_absolute <- pool_counts %>% mutate(fourfold=fourfold_P,tolerated=tolerated_P,deleterious=deleterious_P,LoF=LoF_P) %>% select(!contains(c("_V","_P","sample"))) %>% gather(count,value,-generation,-population,factor_key=T) %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_counts_copies_absolute$group = factor(pool_counts_copies_absolute$group,levels=c("Pb","lines"))
pool_counts_copies_absolute

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_pool_counts_copies_absolute <- data_frame("population"=character(0),"generation"=character(0),"proportion"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(pool_counts_copies_absolute$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(pool_counts_copies_absolute,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(pool_counts_copies_absolute$count)) {
      print(r)
      pop_mean <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(pool_counts_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","proportion","avg_value","se_value")
      average_pool_counts_copies_absolute <- rbind(average_pool_counts_copies_absolute,row_data,stringsAsFactors=F)
    }
  }
}
average_pool_counts_copies_absolute$population = factor(average_pool_counts_copies_absolute$population,levels=c("Pb","lines"))
average_pool_counts_copies_absolute$proportion = factor(average_pool_counts_copies_absolute$proportion,levels=c("fourfold","tolerated","deleterious","LoF"))
average_pool_counts_copies_absolute$generation <- as.factor(as.numeric(average_pool_counts_copies_absolute$generation))
average_pool_counts_copies_absolute$avg_value <- as.numeric(average_pool_counts_copies_absolute$avg_value)
average_pool_counts_copies_absolute$se_value <- as.numeric(average_pool_counts_copies_absolute$se_value)
average_pool_counts_copies_absolute
#write_tsv(average_relativised_pool_counts_copies_absolute,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_absolute_",type,".txt"))


#Combined version:
Pb_lines_pool_proportion_ggplot <- ggplot(data=filter(average_pool_counts_copies_absolute, generation!=5), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ proportion) +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Proportion of derived alleles") +
  ylim(-0.1,1.1) +
  scale_y_continuous(breaks = seq(0.0, 0.5, by = 0.1), limits=c(0, 0.5)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle(paste0("Pools, rarefied data (cov. ",depth,")")) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_pool_proportion_ggplot
ggsave(paste0("rarefied_depth_",depth,"_Pb_lines_proportion_",type,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

#15. Perform the bootstrap:
##Copy the folder from the previous analysis:
```{bash}

#This chunk doesn't need to be repeated if already done!

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140

#First copy the entire bootstrap folder from the previous analysis, which was carried on a different subset (only sites variables in Pb-000).
scp -pr /share/rdata/ramon.pouso/bootstrap/ ./

#Then delete the counts obtained for that version:
find . -type d -name "block_counts" -exec rm -r "{}" \;


```

##Define bootstrap blocks:
###Autosomes.
```{bash}

#This chunk doesn't need to be repeated if already done!

cd /share/rdata/ramon.pouso/bootstrap/

#Obtain the length of the analysed autosomes:
awk '($1=="2L") || ($1=="2R") || ($1=="3L") || ($1=="3R") {print $2}' /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.length.txt | paste -sd+ | bc #108990206

#Since the autosomes measure 109Mb, we'd ideally split them into 1090 blocks of 100kb. However we can only define 1088 blocks (the missing ones would be split among the remaining bases of each autosome):
BLOCK_LENGTH=100000
awk -F"\t" '($1=="2L") || ($1=="2R") || ($1=="3L") || ($1=="3R") {printf ("%s\t%s\t%s\t%s\n", $1,0,$2,$2)}' /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.length.txt > dmel-autosomes-r6.14.length.bed

#Obtain the number of subdivision blocks for each scaffold, as well as the starting point of the last block:
awk -F"\t" -v bl=$BLOCK_LENGTH '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$4-bl,int($4/bl))}' dmel-autosomes-r6.14.length.bed | sort -k4,4nr > dmel-autosomes-r6.14.length.modified.bed

#For each chromosome, calculate $DIFF (the average distance between the starting points of different blocks i.e. the length of a block + the interblock distance, without considering the last block). Then define the starting and finishing point of each block (except for the last one) accounting for the interblock distance. Then define the last block at the very end of the scaffold. Finally, output all blocks to a new file.
rm bed_file_bootstrap_blocks_autosomes.bed
while read -r SCAFFOLD BEGIN END LENGTH WOUT_LAST N_BLOCKS; do
  echo $SCAFFOLD "has" $N_BLOCKS "block(s)"
  DIFF=$(echo "scale=6; $WOUT_LAST/($N_BLOCKS-1)" | bc | awk '{printf "%s", int($0)}')
  for ((b=1; b<N_BLOCKS; b++))
    do
    CURRENT_DIFF=$((DIFF*(b-1)))
    START=$((BEGIN+1+CURRENT_DIFF))
    STOP=$((START+BLOCK_LENGTH-1))
    echo -e "$SCAFFOLD\t$START\t$STOP" >> bed_file_bootstrap_blocks_autosomes.bed
    done
  echo -e "$SCAFFOLD\t$((WOUT_LAST+1))\t$LENGTH" >> bed_file_bootstrap_blocks_autosomes.bed
done < dmel-autosomes-r6.14.length.modified.bed

#Sanity check: test whether all blocks measure exactly the same as $BLOCK_LENGTH. They do!
awk -F"\t" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$3-$2+1)}' bed_file_bootstrap_blocks_autosomes.bed | cut -f4 | sort | uniq

#Sort the bed by scaffold and position.
sort -k1,1 -k2,2n bed_file_bootstrap_blocks_autosomes.bed | awk -F"\t" '{printf ("%s\t%s\t%s\t%s%04d_%s_%s_%s\n", $1,$2,$3,"bl",NR,$1,$2,$3)}' > bed_file_bootstrap_blocks_autosomes_sorted.bed
mv bed_file_bootstrap_blocks_autosomes_sorted.bed bed_file_bootstrap_blocks_autosomes.bed

#Finally, generate a .bed file for each block (row).
mkdir -p block_beds_autosomes
cd block_beds_autosomes
awk '{filename = sprintf("%s.bed", $4); print >filename; close(filename)}' ./../bed_file_bootstrap_blocks_autosomes.bed

```

###Xchr.
```{bash}

#This chunk doesn't need to be repeated if already done!

cd /share/rdata/ramon.pouso/bootstrap/

#Obtain the length of the Xchr:
awk '($1=="X") {print $2}' /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.length.txt | paste -sd+ | bc #23542271

#Since the Xchr measures 23.54Mb, we'll split it into 235 blocks of 100kb. 42271 bases will remain unassigned:
BLOCK_LENGTH=100000
awk -F"\t" '($1=="X") {printf ("%s\t%s\t%s\t%s\n", $1,0,$2,$2)}' /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.length.txt > dmel-Xchr-r6.14.length.bed

#Obtain the number of subdivision blocks for each scaffold, as well as the starting point of the last block:
awk -F"\t" -v bl=$BLOCK_LENGTH '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$4-bl,int($4/bl))}' dmel-Xchr-r6.14.length.bed | sort -k4,4nr > dmel-Xchr-r6.14.length.modified.bed


#For each chromosome, calculate $DIFF (the average distance between the starting points of different blocks i.e. the length of a block + the interblock distance, without considering the last block). Then define the starting and finishing point of each block (except for the last one) accounting for the interblock distance. Then define the last block at the very end of the scaffold. Finally, output all blocks to a new file.
rm bed_file_bootstrap_blocks_Xchr.bed
while read -r SCAFFOLD BEGIN END LENGTH WOUT_LAST N_BLOCKS; do
  echo $SCAFFOLD "has" $N_BLOCKS "block(s)"
  DIFF=$(echo "scale=6; $WOUT_LAST/($N_BLOCKS-1)" | bc | awk '{printf "%s", int($0)}')
  for ((b=1; b<N_BLOCKS; b++))
    do
    CURRENT_DIFF=$((DIFF*(b-1)))
    START=$((BEGIN+1+CURRENT_DIFF))
    STOP=$((START+BLOCK_LENGTH-1))
    echo -e "$SCAFFOLD\t$START\t$STOP" >> bed_file_bootstrap_blocks_Xchr.bed
    done
  echo -e "$SCAFFOLD\t$((WOUT_LAST+1))\t$LENGTH" >> bed_file_bootstrap_blocks_Xchr.bed
done < dmel-Xchr-r6.14.length.modified.bed

#Sanity check: test whether all blocks measure exactly the same as $BLOCK_LENGTH. They do!
awk -F"\t" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$3-$2+1)}' bed_file_bootstrap_blocks_Xchr.bed | cut -f4 | sort | uniq

#Sort the bed by scaffold and position.
sort -k1,1 -k2,2n bed_file_bootstrap_blocks_Xchr.bed | awk -F"\t" '{printf ("%s\t%s\t%s\t%s%04d_%s_%s_%s\n", $1,$2,$3,"bl",NR,$1,$2,$3)}' > bed_file_bootstrap_blocks_Xchr_sorted.bed
mv bed_file_bootstrap_blocks_Xchr_sorted.bed bed_file_bootstrap_blocks_Xchr.bed

#Finally, generate a .bed file for each block (row).
mkdir -p block_beds_Xchr
cd block_beds_Xchr
awk '{filename = sprintf("%s.bed", $4); print >filename; close(filename)}' ./../bed_file_bootstrap_blocks_Xchr.bed

```

##Define parallelisation parameters (this should be performed for each variable and genomic region).
```{r, eval=FALSE, engine='bash'}

#This chunk doesn't need to be repeated if already done!

REGION=(Xchr) #autosomes #Xchr
STATISTIC=(derived_allele_counts) #derived_allele_counts #derived_heterozygous_counts #derived_homozygous_counts
PARALLEL=10 #Currently this has been set to 20 for autosomes and 10 for the Xchr

mkdir -p /share/rdata/ramon.pouso/bootstrap/$STATISTIC/$REGION/block_list
cd /share/rdata/ramon.pouso/bootstrap/

rm $STATISTIC/$REGION/block_list/block_list_*.txt
BLOCK_N=$(ll -rth block_beds_${REGION}/bl*.bed | wc -l)
PARTITION_N=$(echo "scale=3; $BLOCK_N/$PARALLEL" | bc | awk '{printf "%s", int($0)}')
for ((part=1; part < ${PARALLEL[@]}; part++));
  do
  echo $part
  PARTbis=$(printf "%02d\n" $part)
  START=$(((part-1)*PARTITION_N+1))
  ls block_beds_${REGION}/ | tail -n+$START | head -n$PARTITION_N > $STATISTIC/$REGION/block_list/block_list_${PARTbis}.txt
  done
part=${PARALLEL[@]}
echo $part
PARTbis=$(printf "%02d\n" $part)
START=$(((part-1)*PARTITION_N+1)) 
ls block_beds_${REGION}/ | tail -n+$START > $STATISTIC/$REGION/block_list/block_list_${PARTbis}.txt

```

##Obtain statistics for each block in parallel runs.
###Derived allele counts.
####All sites:
```{r, eval=FALSE, engine='bash'}

#Run it as follows:
PARALLEL=20 #Currently this has been set to 20 for autosomes and 10 for the Xchr
REGION="autosomes" #autosomes #Xchr
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
mkdir -p block_counts
qsub -cwd -l h=compute-0-9 -t 1-$PARALLEL /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/derived_allele_counts.sh $REGION

***************************** #save code from here on as /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/derived_allele_counts.sh

REGION=$1 #autosomes or Xchr
CHUNK=$(printf "%02d" ${SGE_TASK_ID}) #chunk of parallelisation

export PATH=$PATH:/share/apps/bedtools2/bin:/share/apps/est-sfs-release-2.03/:/share/apps/BAMTOOLS/bin:/share/apps/bedtools2/bin
module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/

echo "generating parallel derived allele counts for chunk" $CHUNK
echo "retrieving blocks in chunk" $CHUNK
BLOCKLIST=$(cut -d'.' -f1 derived_allele_counts/$REGION/block_list/block_list_${CHUNK}.txt)
echo "retrieving pools"
POOL_LIST=($(ls -v `find "/share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts" -name '*_gen0-140_pool_'${REGION}'.txt' -print`))
for BLOCK in ${BLOCKLIST[@]}
  do 
  echo "working with block" ${BLOCK}
  BED=$(readlink -f block_beds_${REGION}/${BLOCK}.bed)
  rm derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${BLOCK}.txt
  
  echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${BLOCK}.txt
  for pool in "${POOL_LIST[@]}"
    do
    echo "${pool}"
    SAMPLE=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f1)
    GEN=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f2)

    echo "subsetting VCF for block" $BLOCK "and pool" $pool
    bedtools intersect -a ${pool} -b ${BED} -header > ${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    p=${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    
    FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
    if [ "$FOURFOLD_V" -eq 0 ]
      then 
      FOURFOLD_A=0
      FOURFOLD_D=0
      #FOURFOLD_COV=0
    else
      FOURFOLD_A=$(grep "CUSTOM=fourfold;" $p | awk '{print $10}' | paste -sd+ | bc)
      FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
      #FOURFOLD_COV=$((FOURFOLD_A+FOURFOLD_D))
    fi
    
    MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
    if [ "$MISTOL_V" -eq 0 ]
      then 
      MISTOL_A=0
      MISTOL_D=0
      #MISTOL_COV=0
    else
      MISTOL_A=$(grep "CUSTOM=tolerated;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
      #MISTOL_COV=$((MISTOL_A+MISTOL_D))
    fi

    MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
    if [ "$MISDEL_V" -eq 0 ]
      then 
      MISDEL_A=0
      MISDEL_D=0
      #MISDEL_COV=0
    else
      MISDEL_A=$(grep "CUSTOM=deleterious;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
      #MISDEL_COV=$((MISDEL_A+MISDEL_D))
    fi

    LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
    if [ "$LOF_V" -eq 0 ]
      then 
      LOF_A=0
      LOF_D=0
      #LOF_COV=0
    else
      LOF_A=$(grep "CUSTOM=LoF;" $p | awk '{print $10}' | paste -sd+ | bc)
      LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
      #LOF_COV=$((LOF_A+LOF_D))
    fi
    echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${BLOCK}.txt
    rm ${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    done
  done

#To rename all "provean_only" version of the files in order to not rewrite them, use:
#REGION="autosomes" #autosomes #Xchr
#cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
#for summary in $(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt); do echo $summary; mv $summary ${summary/summary./summary.provean_only.}; done 

```

####Low/High recombination subset.
```{r, eval=FALSE, engine='bash'}

#Run it as follows:
PARALLEL=20
REGION="autosomes" #autosomes or Xchr
RECOMBINATION="high" #low or high
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
qsub -cwd -l h=compute-0-9 -t 1-$PARALLEL /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/derived_allele_counts_recombination.sh $REGION $RECOMBINATION

***************************** #save code from here on as /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/derived_allele_counts_recombination.sh

REGION=$1 #autosomes or Xchr
RECOMBINATION=$2 #low or high
CHUNK=$(printf "%02d" ${SGE_TASK_ID}) #chunk of parallelisation

export PATH=$PATH:/share/apps/bedtools2/bin:/share/apps/est-sfs-release-2.03/:/share/apps/BAMTOOLS/bin:/share/apps/bedtools2/bin
module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/

echo "generating parallel derived allele counts for chunk" $CHUNK
echo "retrieving blocks in chunk" $CHUNK
BLOCKLIST=$(cut -d'.' -f1 derived_allele_counts/$REGION/block_list/block_list_${CHUNK}.txt)
echo "retrieving pools"
POOL_LIST=($(ls -v `find "/share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts" -name '*_gen0-140_pool.'${RECOMBINATION}'_recombination_'${REGION}'.txt' -print`))
for BLOCK in ${BLOCKLIST[@]}
  do 
  echo "working with block" ${BLOCK}
  BED=$(readlink -f block_beds_${REGION}/${BLOCK}.bed)
  rm derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.${BLOCK}.txt
  
  echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.${BLOCK}.txt
  for pool in "${POOL_LIST[@]}"
    do
    echo "${pool}"
    SAMPLE=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f1)
    GEN=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f2)

    echo "subsetting VCF for block" $BLOCK "and pool" $pool
    bedtools intersect -a ${pool} -b ${BED} -header > ${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    p=${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    
    FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
    if [ "$FOURFOLD_V" -eq 0 ]
      then 
      FOURFOLD_A=0
      FOURFOLD_D=0
      FOURFOLD_COV=0
    else
      FOURFOLD_A=$(grep "CUSTOM=fourfold;" $p | awk '{print $10}' | paste -sd+ | bc)
      FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
      FOURFOLD_COV=$((FOURFOLD_A+FOURFOLD_D))
    fi
    
    MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
    if [ "$MISTOL_V" -eq 0 ]
      then 
      MISTOL_A=0
      MISTOL_D=0
      MISTOL_COV=0
    else
      MISTOL_A=$(grep "CUSTOM=tolerated;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
      MISTOL_COV=$((MISTOL_A+MISTOL_D))
    fi

    MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
    if [ "$MISDEL_V" -eq 0 ]
      then 
      MISDEL_A=0
      MISDEL_D=0
      MISDEL_COV=0
    else
      MISDEL_A=$(grep "CUSTOM=deleterious;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
      MISDEL_COV=$((MISDEL_A+MISDEL_D))
    fi

    LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
    if [ "$LOF_V" -eq 0 ]
      then 
      LOF_A=0
      LOF_D=0
      LOF_COV=0
    else
      LOF_A=$(grep "CUSTOM=LoF;" $p | awk '{print $10}' | paste -sd+ | bc)
      LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
      LOF_COV=$((LOF_A+LOF_D))
    fi
    echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.${BLOCK}.txt
    rm ${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    done
  done

#To rename all "provean_only" version of the files in order to not rewrite them, use:
#REGION="autosomes" #autosomes #Xchr
#RECOMBINATION="high" #low or high
#cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
#for summary in $(ls counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.bl*.txt); do echo $summary; mv $summary ${summary/summary./summary.provean_only.}; done 

```

##Generate the synthetic genomes:
###Autosomes or Xchr.
```{bash}

#This should only be performed once (for each N_BOOT size). The same coordinates will be carried over to other analyses (low and high recombination, etc.).

N_BOOT=1000 #100 #1000
REGION="Xchr" #autosomes or Xchr
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/block_beds_${REGION}
#BLOCK_N=$(ll -rth bl*.bed | wc -l)
if [ "$REGION" == "autosomes" ]
  then 
  BLOCK_N=1090
elif [ "$REGION" == "Xchr" ]
  then 
  BLOCK_N=235
fi

#Generate a huge pool of genome blocks (50 of each):
rm ../blocks_${REGION}_bootstrap.list
for i in {1..50}
  do
  ls bl*.bed >> ../blocks_${REGION}_bootstrap.list #List each block 50 times to generate the pool for the randomisation
  done
sed -i -e 's/.bed/.txt/g' ../blocks_${REGION}_bootstrap.list

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/
#$BLOCK_N blocks from the pool will be drawn randomly to generate a synthetic genome; this will be performed N_BOOT times in total:
mkdir -p bootstrapped_genomes_coordinates
for boot in $(seq 1 $N_BOOT)
  do
  #echo "drawing blocks for bootstrapped genome number" $boot
  shuf -n$BLOCK_N blocks_${REGION}_bootstrap.list > bootstrapped_genomes_coordinates/bootstrapped_genome_${REGION}_${boot}.list
  done

```

##Perform the bootstrap, obtain the bootstrap error, and relativise it.
###Absolute derived counts:
####All sites.
#####Empirical data average and error:
######Autosomes/Xchr:
```{bash}

REGION="autosomes" #autosomes or Xchr
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/

#First, generate some headers and info files (this should only be performed once):
head -n1 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) > pool_headers.txt #Retrieve headers for files with pools
printf 'Pb\n%.0s' {1..6} > pop_codes.txt #then generate the population column content
printf 'lines\n%.0s' {1..2} >> pop_codes.txt
tail -n+2 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) | cut -f-2 > pool_gen.txt #Retrieve first 2 columns with pool data

#Next, obtain the population average and sampling error (standard error) for the empirical data.
##Average:
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.empirmean.txt

tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.empirmean.txt | cut -f-2 > pop_gen.txt

##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",0); printf("%.3f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.3f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.empirerror.txt

```

######Whole-genome: EDIT PATHS!!!!
```{bash}

REGION="whole-genome"
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/
head -n1 <$(ls ../autosomes/block_counts/counts_pool_gen0-140_autosomes_summary.bl*.txt | head -n1) > pool_headers.txt #Retrieve headers for files with pools
printf 'Pb\n%.0s' {1..6} > pop_codes.txt #then generate the population column content
printf 'lines\n%.0s' {1..2} >> pop_codes.txt
tail -n+2 <$(ls ../autosomes/block_counts/counts_pool_gen0-140_autosomes_summary.bl*.txt | head -n1) | cut -f-2 > pool_gen.txt #Retrieve first 2 columns with pool data

#First combine the autosomal and Xchr counts:
cat pool_headers.txt <(paste pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_autosomes_summary.txt) <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_Xchr_summary.txt))) > /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt

#Next, obtain the population average and sampling error (standard error):
##Average:
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt)))) > /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.empirmean.txt

tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.empirmean.txt | cut -f-2 > pop_gen.txt

##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",0); printf("%.3f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.3f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt)))) > /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.empirerror.txt

```

#####Synthetic genomes counts:
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
N_BOOT=1000 #100 #1000
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/

#Next, generate several bootstrapped w-g counts by adding the counts of 1090 autosomal and 235 Xchr blocks pulled at random from the pool, and obtain the population averages:
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  #Autosomes:
  if [ $REGION == "autosomes" ]
    then
    cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/autosomes/block_counts/
    ##First, edit the filenames of the input blocks so that they match the current variables:
    echo "generating autosomal counts for bootstrapped genome number" $boot
    sed -e 's/^/counts_pool_gen0-140_autosomes_summary./' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/bootstrapped_genomes_coordinates/bootstrapped_genome_autosomes_${boot}.list > bootstrapped_genome_autosomes_${boot}.list
    ##Next, generate the counts for each bootstrapped genome:
    paste pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' $(cat bootstrapped_genome_autosomes_${boot}.list) | tail -n+2) > counts_pool_gen0-140_autosomes_summary.boot_${boot}.txt
    echo "calculating population averages for bootstrapped genome number" $boot
    cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.9f\t",sum[p"."i]/N[p]); printf("%.9f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_autosomes_summary.boot_${boot}.txt | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.9f\t",sum[p"."i]/N[p]); printf("%.9f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_autosomes_summary.boot_${boot}.txt) > counts_pool_gen0-140_autosomes_average.boot_${boot}.txt
  #Xchr:
  elif [ $REGION == "Xchr" ]
    then
    cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/Xchr/block_counts/
    ##First, edit the filenames of the input blocks so that they match the current variables:
    echo "generating Xchr counts for bootstrapped genome number" $boot
    sed -e 's/^/counts_pool_gen0-140_Xchr_summary./' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/bootstrapped_genomes_coordinates/bootstrapped_genome_Xchr_${boot}.list > bootstrapped_genome_Xchr_${boot}.list
    ##Next, generate the counts for each bootstrapped genome:
    paste pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' $(cat bootstrapped_genome_Xchr_${boot}.list) | tail -n+2) > counts_pool_gen0-140_Xchr_summary.boot_${boot}.txt
    echo "calculating population averages for bootstrapped genome number" $boot
    cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.9f\t",sum[p"."i]/N[p]); printf("%.9f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_Xchr_summary.boot_${boot}.txt | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.9f\t",sum[p"."i]/N[p]); printf("%.9f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_Xchr_summary.boot_${boot}.txt) > counts_pool_gen0-140_Xchr_average.boot_${boot}.txt
  ##Whole-genome (combine autosomes and Xchr):
  elif [ $REGION == "whole-genome" ]
    then
    cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/
    paste whole-genome/pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' autosomes/block_counts/counts_pool_gen0-140_autosomes_summary.boot_${boot}.txt Xchr/block_counts/counts_pool_gen0-140_Xchr_summary.boot_${boot}.txt) > whole-genome/counts_pool_gen0-140_whole-genome_summary.boot_${boot}.txt
    ##Next, obtain the population average for each bootstrap:
    cd whole-genome/
    echo "calculating population averages for bootstrapped genome number" $boot
    cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.9f\t",sum[p"."i]/N[p]); printf("%.9f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_whole-genome_summary.boot_${boot}.txt | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.9f\t",sum[p"."i]/N[p]); printf("%.9f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_whole-genome_summary.boot_${boot}.txt) > counts_pool_gen0-140_whole-genome_average.boot_${boot}.txt
  fi
  done

if [ $REGION == "whole-genome" ]
  then
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
  else
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
fi
#Next, obtain the population average of derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$7 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=2;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=2;i<=NF;i++) printf "%.9f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
touch kaka.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_average.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(head -n1 $BLOCK | cut -f2 | cut -d'.' -f1)
  echo $CURRENT >> kaka.txt
  TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=2;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=2;i<=NF;i++) printf "%.9f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.booterror.txt


#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_average.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.booterrorcorrected.txt


#Per population total error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error, which is 0 for the base population).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.9f\t",(sumsq[j","i])**0.5; printf "%.9f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_${REGION}_average.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.empirerror.txt))) > counts_pool_gen0-140_${REGION}_average.totalerror.txt

#Per population adequate or mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered, which means that booterrorcorrected is the total error), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_${REGION}_average.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_${REGION}_average.adequateerror.txt


#In order to relativise by the Pb-000 population average, divide both the population average and the total error by the Pb-000 empirical population averages:
##Empirical population averages divided by the empirical Pb-000 population average:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.empirmean.txt | cut -f3-) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.empirmean.txt | cut -f3-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1')) > counts_pool_gen0-140_${REGION}_average.empirmean_Pb-000_rel.txt
##Total error:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.empirmean.txt | cut -f3-) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.totalerror.txt | cut -f3-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1')) > counts_pool_gen0-140_${REGION}_average.totalerror_Pb-000_rel.txt
##Adequate error:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.empirmean.txt | cut -f3-) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.adequateerror.txt | cut -f3-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1')) > counts_pool_gen0-140_${REGION}_average.adequateerror_Pb-000_rel.txt


#Other files can also be relativised:
##Empirical errors divided by the empirical Kirov population average:
cat pop_headers.txt <(paste pops.txt <(cat <(grep 'ki' ../../../${CALLING}_ann_population_average_${VAR}_${TYPE}.empirmean.txt | cut -f2-) <(tail -n+2 ../../../${CALLING}_ann_population_average_${VAR}_${TYPE}.empirerror.txt | cut -f2-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1')) > ../../../${CALLING}_ann_population_average_${VAR}_${TYPE}.empirerror_ki_rel.txt
##Bootstrap errors divided by the empirical Kirov population average:
cat pop_headers.txt <(paste pops.txt <(cat <(grep 'ki' ../../../${CALLING}_ann_population_average_${VAR}_${TYPE}.empirmean.txt | cut -f2-) <(tail -n+2 ${CALLING}_ann_population_average_${VAR}_${TYPE}.booterror.txt | cut -f2-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1')) > ${CALLING}_ann_population_average_${VAR}_${TYPE}.booterror_ki_rel.txt
##Bootstrap corrected errors divided by the empirical Kirov population average:
cat pop_headers.txt <(paste pops.txt <(cat <(grep 'ki' ../../../${CALLING}_ann_population_average_${VAR}_${TYPE}.empirmean.txt | cut -f2-) <(tail -n+2 ${CALLING}_ann_population_average_${VAR}_${TYPE}.booterrorcorrected.txt | cut -f2-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1')) > ${CALLING}_ann_population_average_${VAR}_${TYPE}.booterrorcorrected_ki_rel.txt

```


####High/low rec.
#####Empirical data average and error:
######Autosomes/Xchr:
```{bash}

REGION="autosomes" #autosomes or Xchr
RECOMBINATION="high" #low or high
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/

#First, generate some headers and info files (this should only be performed once):
##head -n1 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) > pool_headers.txt #Retrieve headers for files with pools
##printf 'Pb\n%.0s' {1..6} > pop_codes.txt #then generate the population column content
##printf 'lines\n%.0s' {1..2} >> pop_codes.txt
##tail -n+2 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) | cut -f-2 > pool_gen.txt #Retrieve first 2 columns with pool data

#Next, obtain the population average and sampling error (standard error) for the empirical data.
##Average:
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirmean.txt

##tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirmean.txt | cut -f-2 > pop_gen.txt

##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",0); printf("%.3f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.3f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirerror.txt

```

#####Synthetic genomes counts:
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
RECOMBINATION="low" #low or high
N_BOOT=1000 #100 #1000
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/

#Next, generate several bootstrapped w-g counts by adding the counts of 1090 autosomal and 235 Xchr blocks pulled at random from the pool, and obtain the population averages:
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  #Autosomes:
  if [ $REGION == "autosomes" ]
    then
    cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/autosomes/block_counts/
    ##First, edit the filenames of the input blocks so that they match the current variables:
    echo "generating autosomal counts for bootstrapped genome number" $boot
    sed -e "s/^/counts_pool_gen0-140_autosomes_summary.${RECOMBINATION}_recombination./" /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/bootstrapped_genomes_coordinates/bootstrapped_genome_autosomes_${boot}.list > bootstrapped_genome_autosomes_${boot}.${RECOMBINATION}_recombination.list
    ##Next, generate the counts for each bootstrapped genome:
    paste pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' $(cat bootstrapped_genome_autosomes_${boot}.${RECOMBINATION}_recombination.list) | tail -n+2) > counts_pool_gen0-140_autosomes_summary.${RECOMBINATION}_recombination.boot_${boot}.txt
    echo "calculating population averages for bootstrapped genome number" $boot
    cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_autosomes_summary.${RECOMBINATION}_recombination.boot_${boot}.txt | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_autosomes_summary.${RECOMBINATION}_recombination.boot_${boot}.txt) > counts_pool_gen0-140_autosomes_average.${RECOMBINATION}_recombination.boot_${boot}.txt
  #Xchr:
  elif [ $REGION == "Xchr" ]
    then
    cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/Xchr/block_counts/
    ##First, edit the filenames of the input blocks so that they match the current variables:
    echo "generating Xchr counts for bootstrapped genome number" $boot
    sed -e "s/^/counts_pool_gen0-140_Xchr_summary.${RECOMBINATION}_recombination./" /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/bootstrapped_genomes_coordinates/bootstrapped_genome_Xchr_${boot}.list > bootstrapped_genome_Xchr_${boot}.${RECOMBINATION}_recombination.list
    ##Next, generate the counts for each bootstrapped genome:
    paste pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' $(cat bootstrapped_genome_Xchr_${boot}.${RECOMBINATION}_recombination.list) | tail -n+2) > counts_pool_gen0-140_Xchr_summary.${RECOMBINATION}_recombination.boot_${boot}.txt
    echo "calculating population averages for bootstrapped genome number" $boot
    cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_Xchr_summary.${RECOMBINATION}_recombination.boot_${boot}.txt | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_Xchr_summary.${RECOMBINATION}_recombination.boot_${boot}.txt) > counts_pool_gen0-140_Xchr_average.${RECOMBINATION}_recombination.boot_${boot}.txt
  ##Whole-genome (combine autosomes and Xchr):
  elif [ $REGION == "whole-genome" ]
    then
    cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/
    paste whole-genome/pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' autosomes/block_counts/counts_pool_gen0-140_autosomes_summary.${RECOMBINATION}_recombination.boot_${boot}.txt Xchr/block_counts/counts_pool_gen0-140_Xchr_summary.${RECOMBINATION}_recombination.boot_${boot}.txt) > whole-genome/counts_pool_gen0-140_whole-genome_summary.${RECOMBINATION}_recombination.boot_${boot}.txt
    ##Next, obtain the population average for each bootstrap:
    cd whole-genome/
    echo "calculating population averages for bootstrapped genome number" $boot
    cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_whole-genome_summary.${RECOMBINATION}_recombination.boot_${boot}.txt | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_whole-genome_summary.${RECOMBINATION}_recombination.boot_${boot}.txt) > counts_pool_gen0-140_whole-genome_average.${RECOMBINATION}_recombination.boot_${boot}.txt
  fi
  done

if [ $REGION == "whole-genome" ]
  then
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
  else
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
fi
#Next, obtain the population average of derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$9 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=2;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=2;i<=NF;i++) printf "%.1f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
touch kaka.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(head -n1 $BLOCK | cut -f2 | cut -d'.' -f1)
  echo $CURRENT >> kaka.txt
  TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=2;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=2;i<=NF;i++) printf "%.5f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.booterror.txt

#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.booterrorcorrected.txt


#Per population total error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error, which is 0 for the base population).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.8f\t",(sumsq[j","i])**0.5; printf "%.8f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirerror.txt))) > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.totalerror.txt

#Per population adequate or mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered, which means that booterrorcorrected is the total error), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.adequateerror.txt


#In order to relativise by the Pb-000 population average, divide both the population average and the total error by the Pb-000 empirical population averages:
##Empirical population averages divided by the empirical Pb-000 population average:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirmean.txt | cut -f3-) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirmean.txt | cut -f3-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirmean_Pb-000_rel.txt
##Total error:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirmean.txt | cut -f3-) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.totalerror.txt | cut -f3-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.totalerror_Pb-000_rel.txt
##Adequate error:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirmean.txt | cut -f3-) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.adequateerror.txt | cut -f3-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.adequateerror_Pb-000_rel.txt

```

###Relative derived counts:
####All sites.
#####Empirical data average and error:
######Autosomes/Xchr:
```{bash}

REGION="autosomes" #autosomes or Xchr
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/

#First, generate some headers and info files (this should only be performed once):
head -n1 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) > pool_headers.txt #Retrieve headers for files with pools
printf 'Pb\n%.0s' {1..6} > pop_codes.txt #then generate the population column content
printf 'lines\n%.0s' {1..2} >> pop_codes.txt
tail -n+2 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) | cut -f-2 > pool_gen.txt #Retrieve first 2 columns with pool data

#First, obtain the relativised version of the empirical counts.
  #Only Pb-000 rel:
  paste pool_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt | cut -f3-) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt | cut -f3-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.8f", $i/m[i])}1') > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_rel.txt
  #Only 4fold rel:
  paste pool_gen.txt <(paste <(paste <(cut -f3 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt | tail -n+2) <(cut -f$(seq -s, 3 2 9) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt | tail -n+2) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt | tail -n+2) <(cut -f$(seq -s, 4 2 10) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt | tail -n+2) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}') > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.4fold_rel.txt
  #Both Pb-000 rel and 4fold rel:
  cat pool_headers.txt <(paste pool_gen.txt <(paste <(paste <(cut -f3 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_rel.txt) <(cut -f$(seq -s, 3 2 9) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_rel.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_rel.txt) <(cut -f$(seq -s, 4 2 10) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_rel.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}')) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_4fold_rel.txt

#Next, obtain the population average and sampling error (standard error) for the empirical relativised data.
  #Both Pb-000 rel and 4fold rel:
  ##Average:
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_4fold_rel.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_4fold_rel.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirmean.txt
  ##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",0); printf("%.8f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_4fold_rel.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.8f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_4fold_rel.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirerror.txt
  
  #Only 4fold rel:
  ##Average:
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(cat /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.4fold_rel.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(cat /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.4fold_rel.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.4fold_rel.empirmean.txt
  ##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",0); printf("%.8f\n",0);}}' <(cat /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.4fold_rel.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.8f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(cat /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.4fold_rel.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.4fold_rel.empirerror.txt

```

######Autosomes/Xchr (4fold without new mutation):
```{bash}

#Take the 4fold synonymous values from the pipeline without new mutation (see e-mail from Aurora on 2023/12/10), and the rest of the categories from this pipeline (with mutation).

REGION="autosomes" #autosomes or Xchr
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/

#First, generate some headers and info files (this should only be performed once):
head -n1 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) > pool_headers.txt #Retrieve headers for files with pools
printf 'Pb\n%.0s' {1..6} > pop_codes.txt #then generate the population column content
printf 'lines\n%.0s' {1..2} >> pop_codes.txt
tail -n+2 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) | cut -f-2 > pool_gen.txt #Retrieve first 2 columns with pool data


#First, obtain the relativised version of the empirical counts.
  #Only Pb-000 rel (combine 4fold without new mutation and other categories with new mutation):
  paste pool_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/wout_new_mut_counts/counts_pool_gen0-140_${REGION}_summary.txt | cut -f5-) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/wout_new_mut_counts/counts_pool_gen0-140_${REGION}_summary.txt | cut -f5-) | cut -f-2 | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.8f", $i/m[i])}1') <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt | cut -f5-) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.txt | cut -f5-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.8f", $i/m[i])}1' | cut -f3-) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_rel_syn_wout.txt
  #Both Pb-000 rel and 4fold rel (the 4fold columns come from the files without new mutation; the rest come from the files with new mutation):
  cat pool_headers.txt <(paste pool_gen.txt <(paste <(paste <(cut -f3 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_rel_syn_wout.txt) <(cut -f$(seq -s, 3 2 9) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_rel_syn_wout.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_rel_syn_wout.txt) <(cut -f$(seq -s, 4 2 10) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_rel_syn_wout.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}')) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_4fold_rel_syn_wout.txt

#Next, obtain the population average and sampling error (standard error) for the empirical relativised data.
  #Both Pb-000 rel and 4fold rel:
  ##Average:
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_4fold_rel_syn_wout.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_4fold_rel_syn_wout.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.empirmean.txt
  ##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",0); printf("%.8f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_4fold_rel_syn_wout.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.8f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.Pb-000_4fold_rel_syn_wout.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.empirerror.txt

```

#####Synthetic genomes counts:
######Double ratio, line average:
```{bash}

#Run the absolute derived counts chunk before running this one, as this one needs files generated in that section.

REGION="autosomes" #autosomes #Xchr #whole-genome
N_BOOT=1000 #100 #1000
if [ $REGION == "whole-genome" ]
  then
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
  else
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
fi

#Obtain the Pb-000 and 4fold relative version of all bootstrapped counts.
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  FILE=counts_pool_gen0-140_${REGION}_average.boot_${boot}.txt
  #Pb-000 rel:
  paste pop_gen.txt <(cat <(grep 'gen0' $FILE | cut -f2-) <(cut -f2- $FILE) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1') > ${FILE/.boot/.Pb-000_rel.boot}
  #Pb-000 and 4fold rel:
  paste pop_gen.txt <(paste <(paste <(cut -f3 ${FILE/.boot/.Pb-000_rel.boot}) <(cut -f$(seq -s, 3 2 9) ${FILE/.boot/.Pb-000_rel.boot}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 ${FILE/.boot/.Pb-000_rel.boot}) <(cut -f$(seq -s, 4 2 10) ${FILE/.boot/.Pb-000_rel.boot}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}') > ${FILE/.boot/.Pb-000_4fold_rel.boot} && rm ${FILE/.boot/.Pb-000_rel.boot}
  done

#Next, obtain the population average of relativised derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$10 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.9f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
rm kaka.Pb-000_4fold_rel.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(tail -n1 $BLOCK | cut -f10)
  echo $CURRENT >> kaka.Pb-000_4fold_rel.txt
  #TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.5f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.booterror.txt


#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.booterrorcorrected.txt


#Per population total error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error, which is 0 for the base population).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.8f\t",(sumsq[j","i])**0.5; printf "%.8f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirerror.txt))) > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.totalerror.txt

#Per population adequate or mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered, which means that booterrorcorrected is the total error), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.adequateerror.txt

```

######Double ratio, line average (4fold without new mutation):
```{bash}

#Run the absolute derived counts chunk before running this one, as this one needs files generated in that section.

#Take the 4fold synonymous values from the pipeline without new mutation (see e-mail from Aurora on 2023/12/10), and the rest of the categories from this pipeline (with mutation).

REGION="autosomes" #autosomes #Xchr #whole-genome
N_BOOT=1000 #100 #1000
if [ $REGION == "whole-genome" ]
  then
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
  else
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
fi

#Obtain the Pb-000 and 4fold relative version of all bootstrapped counts.
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  FILE=counts_pool_gen0-140_${REGION}_average.boot_${boot}.txt
  #Pb-000 rel (combine 4fold without new mutation and other categories with new mutation):
  paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/$REGION/block_counts/$FILE | cut -f2-) <(cut -f2- /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/$REGION/block_counts/$FILE) | cut -f-2 | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1') <(cat <(grep 'gen0' $FILE | cut -f2-) <(cut -f2- $FILE) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1' | cut -f3-) > ${FILE/.boot/.Pb-000_rel_syn_wout.boot}
  #Pb-000 and 4fold rel (the 4fold columns come from the files without new mutation; the rest come from the files with new mutation):
  paste pop_gen.txt <(paste <(paste <(cut -f3 ${FILE/.boot/.Pb-000_rel_syn_wout.boot}) <(cut -f$(seq -s, 3 2 9) ${FILE/.boot/.Pb-000_rel_syn_wout.boot}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 ${FILE/.boot/.Pb-000_rel_syn_wout.boot}) <(cut -f$(seq -s, 4 2 10) ${FILE/.boot/.Pb-000_rel_syn_wout.boot}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}') > ${FILE/.boot/.Pb-000_4fold_rel_syn_wout.boot} && rm ${FILE/.boot/.Pb-000_rel_syn_wout.boot}
  done

#Next, obtain the population average of relativised derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$12 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.9f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
rm kaka.Pb-000_4fold_rel.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(tail -n1 $BLOCK | cut -f10)
  echo $CURRENT >> kaka.Pb-000_4fold_rel.txt
  #TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.5f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.booterror.txt


#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.booterrorcorrected.txt


#Per population total error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error, which is 0 for the base population).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.8f\t",(sumsq[j","i])**0.5; printf "%.8f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.empirerror.txt))) > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.totalerror.txt

#Per population adequate or mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered, which means that booterrorcorrected is the total error), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.adequateerror.txt

```


######Double ratio, line average (mix numerator and denominator):
```{bash}

#Run the absolute derived counts chunk before running this one, as this one needs files generated in that section.

REGION="autosomes" #autosomes #Xchr #whole-genome
N_BOOT=1000 #100 #1000
if [ $REGION == "whole-genome" ]
  then
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
  else
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
fi

#Obtain the Pb-000 and 4fold relative version of all bootstrapped counts.
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  FILE=counts_pool_gen0-140_${REGION}_average.boot_${boot}.txt
  #4fold rel:
  paste pop_gen.txt <(paste <(paste <(cut -f2 ${FILE}) <(cut -f$(seq -s, 2 2 8) ${FILE}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) <(paste <(cut -f3 ${FILE}) <(cut -f$(seq -s, 3 2 9) ${FILE}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}') > ${FILE/.boot/.4fold_rel.boot}
  done
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  FILE=counts_pool_gen0-140_${REGION}_average.boot_${boot}.txt
  if [ $boot == $N_BOOT ]
    then
    FILE_NEXT=counts_pool_gen0-140_${REGION}_average.boot_1.txt
    else
    FILE_NEXT=counts_pool_gen0-140_${REGION}_average.boot_$((boot+1)).txt
  fi
  #4fold and Pb-000 rel:
  paste pop_gen.txt <(cat <(grep 'gen0' ${FILE_NEXT/.boot/.4fold_rel.boot} | cut -f3-) <(cut -f3- ${FILE/.boot/.4fold_rel.boot}) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1') > ${FILE/.boot/.4fold_Pb-000_rel.boot}
  done

#Next, obtain the population average of relativised derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$10 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.5f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
rm kaka.4fold_Pb-000_rel.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(tail -n1 $BLOCK | cut -f10)
  echo $CURRENT >> kaka.4fold_Pb-000_rel.txt
  #TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.5f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.booterror.txt


#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.booterrorcorrected.txt


#Per population total error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error, which is 0 for the base population).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.8f\t",(sumsq[j","i])**0.5; printf "%.8f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirerror.txt))) > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.totalerror.txt

#Per population adequate or mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered, which means that booterrorcorrected is the total error), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.adequateerror.txt

```

######Double ratio, line average (denominator average boot):
```{bash}

#Run the absolute derived counts chunk before running this one, as this one needs files generated in that section.

REGION="autosomes" #autosomes #Xchr #whole-genome
N_BOOT=1000 #100 #1000
if [ $REGION == "whole-genome" ]
  then
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
  else
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
fi

#Obtain the 4fold relative version of all bootstrapped counts, and then relativise everything by the bootstrap average of the Pb-000 values.
##4fold rel:
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  FILE=counts_pool_gen0-140_${REGION}_average.boot_${boot}.txt
  paste pop_gen.txt <(paste <(paste <(cut -f2 ${FILE}) <(cut -f$(seq -s, 2 2 8) ${FILE}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) <(paste <(cut -f3 ${FILE}) <(cut -f$(seq -s, 3 2 9) ${FILE}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}') > ${FILE/.boot/.4fold_rel.boot}
  done
##Next, obtain the population average of relativised derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.4fold_rel.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$9 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.4fold_rel.Nboot_${N_BOOT}.list
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.9f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.4fold_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.4fold_rel.bootmean.txt
##4fold and Pb-000-mean rel:
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  FILE=counts_pool_gen0-140_${REGION}_average.boot_${boot}.txt
  paste pop_gen.txt <(cat <(grep 'gen0' counts_pool_gen0-140_${REGION}_average.4fold_rel.bootmean.txt | cut -f3-) <(cut -f3- ${FILE/.boot/.4fold_rel.boot}) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1') > ${FILE/.boot/.4fold_Pb-000-mean_rel.boot}
  done

#Next, obtain the population average of relativised derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$10 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.5f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
rm kaka.4fold_Pb-000-mean_rel.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(tail -n1 $BLOCK | cut -f10)
  echo $CURRENT >> kaka.4fold_Pb-000-mean_rel.txt
  #TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.9f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.booterror.txt


#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.booterrorcorrected.txt


#Per population total error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error, which is 0 for the base population).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.8f\t",(sumsq[j","i])**0.5; printf "%.8f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirerror.txt))) > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.totalerror.txt

#Per population adequate or mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered, which means that booterrorcorrected is the total error), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.adequateerror.txt

```

######4fold relative, line average:
```{bash}

#Run the absolute derived counts chunk before running this one, as this one needs files generated in that section.

REGION="autosomes" #autosomes #Xchr #whole-genome
N_BOOT=1000 #100 #1000
if [ $REGION == "whole-genome" ]
  then
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
  else
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
fi

#Obtain the 4fold relative version of all bootstrapped counts.
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  FILE=counts_pool_gen0-140_${REGION}_average.boot_${boot}.txt
  #4fold rel:
  paste pop_gen.txt <(paste <(paste <(cut -f2 ${FILE}) <(cut -f$(seq -s, 2 2 8) ${FILE}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) <(paste <(cut -f3 ${FILE}) <(cut -f$(seq -s, 3 2 9) ${FILE}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}') > ${FILE/.boot/.4fold_rel.boot}
  done

#Next, obtain the population average of relativised derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.4fold_rel.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$9 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.4fold_rel.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.9f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.4fold_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.4fold_rel.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
rm kaka.4fold_rel.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_average.4fold_rel.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(tail -n1 $BLOCK | cut -f10)
  echo $CURRENT >> kaka.4fold_rel.txt
  #TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.9f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.4fold_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.4fold_rel.booterror.txt


#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.4fold_rel.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_rel.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.4fold_rel.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_rel.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_rel.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.4fold_rel.booterrorcorrected.txt


#Per population total error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error, which is 0 for the base population).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.8f\t",(sumsq[j","i])**0.5; printf "%.8f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_rel.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.4fold_rel.empirerror.txt))) > counts_pool_gen0-140_${REGION}_average.4fold_rel.totalerror.txt

#Per population adequate or mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered, which means that booterrorcorrected is the total error), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_${REGION}_average.4fold_rel.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.4fold_rel.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_${REGION}_average.4fold_rel.adequateerror.txt

```

######4fold relative, separate lines:
```{bash}

#Run the absolute derived counts chunk before running this one, as this one needs files generated in that section.

REGION="autosomes" #autosomes #Xchr #whole-genome
N_BOOT=1000 #100 #1000
if [ $REGION == "whole-genome" ]
  then
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
  else
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
fi

#Obtain the 4fold relative version of all bootstrapped counts.
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  FILE=counts_pool_gen0-140_${REGION}_summary.boot_${boot}.txt
  #4fold rel:
  paste pool_gen.txt <(paste <(paste <(cut -f3 ${FILE}) <(cut -f$(seq -s, 3 2 9) ${FILE}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.5f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 ${FILE}) <(cut -f$(seq -s, 4 2 10) ${FILE}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.5f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}') > ${FILE/.boot/.4fold_rel.boot}
  done

#Next, obtain the population average of relativised derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_summary.4fold_rel.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$9 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_summary.4fold_rel.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pool_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.5f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_summary.4fold_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_summary.4fold_rel.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
rm kaka.4fold_rel.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_summary.4fold_rel.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(tail -n2 $BLOCK | head -n1 | cut -f10)
  echo $CURRENT >> kaka.4fold_rel.txt
  #TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pool_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.9f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_summary.4fold_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_summary.4fold_rel.booterror.txt


#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(cat /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.4fold_rel.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_summary.4fold_rel.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_summary.4fold_rel.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_summary.4fold_rel.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_summary.4fold_rel.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_summary.4fold_rel.booterrorcorrected.txt

#Since the empirical error is 0 here given that only one population is considered, the booterrorcorrected is the total error).

```

####High/low rec.
#####Empirical data average and error:
######Autosomes/Xchr:
```{bash}

REGION="autosomes" #autosomes or Xchr
RECOMBINATION="low" #low or high
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/

#First, obtaion the relativised version of the empirical counts.
  #Pb-000 rel:
  paste pool_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt | cut -f3-) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt | cut -f3-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.8f", $i/m[i])}1') > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_rel.txt
  #4fold rel:
  cat pool_headers.txt <(paste pool_gen.txt <(paste <(paste <(cut -f3 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_rel.txt) <(cut -f$(seq -s, 3 2 9) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_rel.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_rel.txt) <(cut -f$(seq -s, 4 2 10) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_rel.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}')) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_4fold_rel.txt

#Next, obtain the population average and sampling error (standard error) for the empirical relativised data.
  ##Average:
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_4fold_rel.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_4fold_rel.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.empirmean.txt
  ##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",0); printf("%.8f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_4fold_rel.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.8f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_4fold_rel.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.empirerror.txt

```

######Autosomes/Xchr (4fold without new mutation):
```{bash}

#Take the 4fold synonymous values from the pipeline without new mutation (see e-mail from Aurora on 2023/12/10), and the rest of the categories from this pipeline (with mutation).

REGION="autosomes" #autosomes or Xchr
RECOMBINATION="low" #low or high
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/

#First, obtain the relativised version of the empirical counts.
  #Only Pb-000 rel (combine 4fold without new mutation and other categories with new mutation):
  paste pool_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt | cut -f3-) <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt | cut -f3-) | cut -f-2 | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.8f", $i/m[i])}1') <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt | cut -f3-) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.txt | cut -f3-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.8f", $i/m[i])}1' | cut -f3-) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_rel_syn_wout.txt
  #Both Pb-000 rel and 4fold rel (the 4fold columns come from the files without new mutation; the rest come from the files with new mutation):
  cat pool_headers.txt <(paste pool_gen.txt <(paste <(paste <(cut -f3 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_rel_syn_wout.txt) <(cut -f$(seq -s, 3 2 9) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_rel_syn_wout.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_rel_syn_wout.txt) <(cut -f$(seq -s, 4 2 10) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_rel_syn_wout.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}')) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_4fold_rel_syn_wout.txt

#Next, obtain the population average and sampling error (standard error) for the empirical relativised data.
##Average:
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_4fold_rel_syn_wout.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.Pb-000_4fold_rel_syn_wout.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel_syn_wout.empirmean.txt

```

#####Synthetic genomes counts:
```{bash}

#Run the absolute derived counts chunk before running this one, as this one needs files generated in that section.

REGION="autosomes" #autosomes #Xchr #whole-genome
RECOMBINATION="low" #low or high
N_BOOT=1000 #100 #1000
if [ $REGION == "whole-genome" ]
  then
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
  else
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
fi

#Obtain the Pb-000 and 4fold relative version of all bootstrapped counts.
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  FILE=counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.boot_${boot}.txt
  #Pb-000 rel:
  paste pop_gen.txt <(cat <(grep 'gen0' $FILE | cut -f2-) <(cut -f2- $FILE) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1') > ${FILE/.boot/.Pb-000_rel.boot}
  #4fold rel:
  paste pop_gen.txt <(paste <(paste <(cut -f3 ${FILE/.boot/.Pb-000_rel.boot}) <(cut -f$(seq -s, 3 2 9) ${FILE/.boot/.Pb-000_rel.boot}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.5f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 ${FILE/.boot/.Pb-000_rel.boot}) <(cut -f$(seq -s, 4 2 10) ${FILE/.boot/.Pb-000_rel.boot}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.5f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}') > ${FILE/.boot/.Pb-000_4fold_rel.boot} && rm ${FILE/.boot/.Pb-000_rel.boot}
  done

#Next, obtain the population average of relativised derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$12 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.5f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
rm kaka.Pb-000_4fold_rel.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(tail -n1 $BLOCK | cut -f10)
  echo $CURRENT >> kaka.Pb-000_4fold_rel.txt
  #TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.5f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.booterror.txt


#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.booterrorcorrected.txt


#Per population total error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error, which is 0 for the base population).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.8f\t",(sumsq[j","i])**0.5; printf "%.8f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.empirerror.txt))) > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.totalerror.txt

#Per population adequate or mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered, which means that booterrorcorrected is the total error), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.adequateerror.txt

```


##Download files:
###Absolute derived allele counts.
####All sites
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)

#Empirical mean relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.empirmean.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Total error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.totalerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Adequate error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.adequateerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites

```

####Recombination.
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
RECOMBINATION="low" #low or high

#Empirical mean relativised by Pb:
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.empirmean_Pb-000_rel.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Total error relativised by Pb:
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.totalerror_Pb-000_rel.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Adequate error relativised by Pb:
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.adequateerror_Pb-000_rel.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites

```

###Relative derived allele counts.
####All sites.
#####Double ratio, line average:
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)

#Empirical mean relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirmean.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Total error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.totalerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Adequate error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.adequateerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites

```

#####Double ratio, line average (4fold without new mutation):
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)

#Empirical mean relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.empirmean.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Total error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.totalerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Adequate error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel_syn_wout.adequateerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites

```

#####Double ratio, line average (mix numerator and denominator):
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)

#Empirical mean relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirmean.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Total error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.totalerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Adequate error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.4fold_Pb-000_rel.adequateerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites

```

#####Double ratio, line average (denominator average boot):
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)

#Empirical mean relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.Pb-000_4fold_rel.empirmean.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Total error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.totalerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Adequate error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.4fold_Pb-000-mean_rel.adequateerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites

```

#####4fold relative, line average:
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)

#Empirical mean:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.4fold_rel.empirmean.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Bootstrap error (corrected):
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.4fold_rel.booterrorcorrected.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Adequate error:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.4fold_rel.adequateerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites

```

#####4fold relative, separate lines:
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)

#Empirical data:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.4fold_rel.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/contrastes/all_sites/
#Bootstrap error (corrected):
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_autosomes_summary.4fold_rel.booterrorcorrected.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/contrastes/all_sites/

```

####Recombination.
#####Double ratio, line average:
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
RECOMBINATION="low" #low or high
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)

#Empirical mean relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.empirmean.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Total error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.totalerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Adequate error relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel.adequateerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites

```

#####Double ratio, line average (4fold without new mutation):
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
RECOMBINATION="low" #low or high
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)

#Empirical mean relativised by Pb:
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel_syn_wout.empirmean.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Total error relativised by Pb:
#sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel_syn_wout.totalerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites
#Adequate error relativised by Pb:
#sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_average.${RECOMBINATION}_recombination.Pb-000_4fold_rel_syn_wout.adequateerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites

```

##Plot counts.
###Derived count ratios (relative to 4fold and Pb-000):
####Gen0-140 pools Pb booterror and line averages empirerror (combined version):
#####All sites:
######Double ratio:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.Pb-000_4fold_rel.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.Pb-000_4fold_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
#names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation)) + 83
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)
pool_errors <- pool_errors %>% setNames(gsub("_D","",names(.)))
pool_errors[c(1),c(4:6)] <- NA

# pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_4FR
pool_errors_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
combined_tidy_withnewmut <- left_join(pool_counts_tidy,pool_errors_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_withnewmut) <- c("population","generation","ratio","mean","error")

#Combined version (Pb):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy_withnewmut,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot
#ggsave(paste0("Pb_lines_relativised_pool_counts_copies_adequateerrors_4FR_",type,".bootstrap.pdf"), width=12, height=9, units="cm", device="pdf", path=wd_path)

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_y_scales <- ggplot(data=filter(combined_tidy_withnewmut,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(ratio ~ .,scales="free_y") +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_y_scales
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_adequateerrors_4FR_",type,".bootstrap.y_scales.pdf"), width=12, height=9, units="cm", device="pdf", path=wd_path)


#Paper versions:
##Various colours:
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy_withnewmut,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot

##Two colours:
combined_tidy_withnewmut_bis <- combined_tidy_withnewmut
combined_tidy_withnewmut_bis$generation <- as.numeric(as.character(combined_tidy_withnewmut_bis$generation))
combined_tidy_withnewmut_bis$ratio <- factor(combined_tidy_withnewmut_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis <- ggplot(data=filter(combined_tidy_withnewmut_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis

##Two colours (manuscript version, only including new mutation):
combined_tidy_withnewmut_bis <- combined_tidy_withnewmut
combined_tidy_withnewmut_bis$generation <- as.numeric(as.character(combined_tidy_withnewmut_bis$generation))
combined_tidy_withnewmut_bis$ratio <- factor(combined_tidy_withnewmut_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis <- ggplot(data=filter(combined_tidy_withnewmut_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 and 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  ylim(0.6,1.2) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=8,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=11,colour="black"),
        axis.title=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(-1,-1,-1,-1),"cm"),
        #plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=9,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis
#ggsave("20231220_main_empirical.syn_wout.pdf", width=15, height=12, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/")


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.13,hjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=1))

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis,width=unit(6,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.45,vjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=1))

ggsave("20240802_main_empirical.pdf", width=11, height=8.5, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#ggsave("20240315_main_empirical.syn_wout.pdf", width=11, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#STOP


```

######Double ratio (4fold without new mutation):
```{r}

#Take the 4fold synonymous values from the pipeline without new mutation (see e-mail from Aurora on 2023/12/10), and the rest of the categories from this pipeline (with mutation).

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.Pb-000_4fold_rel_syn_wout.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.Pb-000_4fold_rel_syn_wout.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
#names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation)) + 83
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)
pool_errors <- pool_errors %>% setNames(gsub("_D","",names(.)))
pool_errors[c(1),c(4:6)] <- NA

# pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_4FR
pool_errors_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
combined_tidy_withnewmut <- left_join(pool_counts_tidy,pool_errors_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_withnewmut) <- c("population","generation","ratio","mean","error")

#Paper versions:
##Various colours:
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_syn_wout <- ggplot(data=filter(combined_tidy_withnewmut,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_syn_wout

##Two colours:
combined_tidy_withnewmut_bis <- combined_tidy_withnewmut
combined_tidy_withnewmut_bis$generation <- as.numeric(as.character(combined_tidy_withnewmut_bis$generation))
combined_tidy_withnewmut_bis$ratio <- factor(combined_tidy_withnewmut_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout <- ggplot(data=filter(combined_tidy_withnewmut_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout


##Two colours (manuscript version, only including new mutation):
combined_tidy_withnewmut_bis <- combined_tidy_withnewmut
combined_tidy_withnewmut_bis$generation <- as.numeric(as.character(combined_tidy_withnewmut_bis$generation))
combined_tidy_withnewmut_bis$ratio <- factor(combined_tidy_withnewmut_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout <- ggplot(data=filter(combined_tidy_withnewmut_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 and 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  ylim(0.6,1.2) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=8,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=11,colour="black"),
        axis.title=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(-1,-1,-1,-1),"cm"),
        #plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=9,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout
#ggsave("20231220_main_empirical.syn_wout.pdf", width=15, height=12, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/")


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.13,hjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=1))

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout,width=unit(6,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.45,vjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=1))

ggsave("20240705_main_empirical.syn_wout.pdf", width=11, height=8.5, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#ggsave("20240315_main_empirical.syn_wout.pdf", width=11, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#STOP

```

######Double ratio (mix numerator and denominator):
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.Pb-000_4fold_rel.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.4fold_Pb-000_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
#names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation)) + 83
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)
pool_errors <- pool_errors %>% setNames(gsub("_D","",names(.)))

# pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_4FR
pool_errors_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
combined_tidy <- left_join(pool_counts_tidy,pool_errors_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy) <- c("population","generation","ratio","mean","error")

#Combined version (Pb):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_adequateerrors_4FR_",type,".bootstrap_mixed.pdf"), width=12, height=9, units="cm", device="pdf", path=wd_path)

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_y_scales <- ggplot(data=filter(combined_tidy,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(ratio ~ .,scales="free_y") +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_y_scales
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_adequateerrors_4FR_",type,".bootstrap_mixed.y_scales.pdf"), width=12, height=9, units="cm", device="pdf", path=wd_path)

```

######Double ratio (denominator average boot):
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.Pb-000_4fold_rel.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.4fold_Pb-000-mean_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
#names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation)) + 83
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)
pool_errors <- pool_errors %>% setNames(gsub("_D","",names(.)))

# pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_4FR
pool_errors_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
combined_tidy <- left_join(pool_counts_tidy,pool_errors_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy) <- c("population","generation","ratio","mean","error")

#Combined version (Pb):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_adequateerrors_4FR_",type,".bootstrap_mean.pdf"), width=12, height=9, units="cm", device="pdf", path=wd_path)

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_y_scales <- ggplot(data=filter(combined_tidy,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(ratio ~ .,scales="free_y") +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_y_scales
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_adequateerrors_4FR_",type,".bootstrap_mean.y_scales.pdf"), width=12, height=9, units="cm", device="pdf", path=wd_path)

```

######Single ratio:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.4fold_rel.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.4fold_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
#names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation)) + 83
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)
pool_errors <- pool_errors %>% setNames(gsub("_D","",names(.)))

# pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_4FR
pool_errors_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
combined_tidy <- left_join(pool_counts_tidy,pool_errors_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy) <- c("population","generation","ratio","mean","error")

#Combined version (Pb):
Pb_lines_pool_counts_copies_errors_4FR_ggplot_y_scales <- ggplot(data=filter(combined_tidy,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(ratio ~ .,scales="free_y") +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  ylab("Derived count relative to 4-fold syn.") +
  #scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  #ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_pool_counts_copies_errors_4FR_ggplot_y_scales
ggsave(paste0("Pb_lines_pool_counts_copies_adequateerrors_4FR_",type,".bootstrap.y_scales.pdf"), width=12, height=9, units="cm", device="pdf", path=wd_path)

```

######Absolute counts:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
#names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation)) + 83
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)
pool_errors <- pool_errors %>% setNames(gsub("_D","",names(.)))

# pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_4FR
pool_errors_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
combined_tidy <- left_join(pool_counts_tidy,pool_errors_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy) <- c("population","generation","ratio","mean","error")

#Combined version (Pb):
Pb_lines_pool_counts_copies_errors_ggplot_y_scales <- ggplot(data=filter(combined_tidy,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(ratio ~ .,scales="free_y") +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  ylab("Absolute derived count") +
  #scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  #ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_pool_counts_copies_errors_ggplot_y_scales
ggsave(paste0("Pb_lines_pool_counts_copies_adequateerrors_",type,".bootstrap.y_scales.pdf"), width=12, height=9, units="cm", device="pdf", path=wd_path)

```

#####Combine with and without new mutation:
######Double ratio:
```{r}

library(grid)
library(gridExtra)
library(egg)

##Various colours:
Pb_lines_nonewmut_relativised_pool_counts_copies_errors_4FR_ggplot #obtain this in the bootstrap.Rmd script, where all the code for the dataset without new mutation is.
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot #obtain this in the previous chunk from this script.

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_nonewmut_relativised_pool_counts_copies_errors_4FR_ggplot,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.42,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-083 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=3))

ggsave("20231023_main_empirical.pdf", width=20, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)



##Two colours:
Pb_lines_nonewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis #obtain this in the bootstrap.Rmd script, where all the code for the dataset without new mutation is.
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis #obtain this in the previous chunk from this script.

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_nonewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.42,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-083 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=3))

ggsave("20231201_main_empirical.pdf", width=20, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#Stop
STOP

```

######Double ratio (4fold without new mutation):
```{r}

library(grid)
library(gridExtra)
library(egg)

##Two colours:
#Pb_lines_nonewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis #obtain this in the bootstrap.Rmd script, where all the code for the dataset without new mutation is.
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout #obtain this in the previous chunk from this script.

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.42,hjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=1))

#ggsave("20231211_main_empirical.syn_wout.pdf", width=20, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

ggsave("20240109_main_empirical.syn_wout.pdf", width=15, height=12, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#Stop
STOP

```

#####Recombination:
######Double ratio:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


####First, process the low recombination dataset####
##Averages:
pool_counts_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.low_recombination.Pb-000_4fold_rel.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
pool_counts_low$population = factor(pool_counts_low$population,levels=c("Pb","lines"))
pool_counts_low$generation <- as.numeric(gsub("gen","",pool_counts_low$generation)) + 83
pool_counts_low <- pool_counts_low %>% arrange(generation)
pool_counts_low$generation = factor(pool_counts_low$generation)
pool_counts_low <- pool_counts_low %>% arrange(population,generation)
pool_counts_low <- pool_counts_low %>% setNames(gsub("_D","",names(.)))

# pool_counts_low_4FR <- pool_counts_low %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_low_4FR
pool_counts_low_tidy <- pool_counts_low %>% gather(ratio,value,-generation,-population,factor_key=T)

##Errors:
pool_errors_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.low_recombination.Pb-000_4fold_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors_low <- cbind(pool_errors_low,pool_counts_low$fourfold_D)
#names(pool_errors_low)[names(pool_errors_low) == 'pool_counts_low$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors_low <- left_join(pool_errors_low,codes_dictionary,by=c("population"="old"))
pool_errors_low$population = factor(pool_errors_low$population,levels=c("Pb","lines"))
pool_errors_low$generation <- as.numeric(gsub("gen","",pool_errors_low$generation)) + 83
pool_errors_low <- pool_errors_low %>% arrange(generation)
pool_errors_low$generation = factor(pool_errors_low$generation)
pool_errors_low <- pool_errors_low %>% arrange(population,generation)
pool_errors_low <- pool_errors_low %>% setNames(gsub("_D","",names(.)))

# pool_errors_low_4FR <- pool_errors_low %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_low_4FR
pool_errors_low_tidy <- pool_errors_low %>% gather(ratio,value,-generation,-population,factor_key=T)

##Combined:
combined_tidy_low <- left_join(pool_counts_low_tidy,pool_errors_low_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_low) <- c("population","generation","ratio","mean","error")


####Next, process the high recombination dataset####
##Averages:
pool_counts_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.high_recombination.Pb-000_4fold_rel.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
pool_counts_high$population = factor(pool_counts_high$population,levels=c("Pb","lines"))
pool_counts_high$generation <- as.numeric(gsub("gen","",pool_counts_high$generation)) + 83
pool_counts_high <- pool_counts_high %>% arrange(generation)
pool_counts_high$generation = factor(pool_counts_high$generation)
pool_counts_high <- pool_counts_high %>% arrange(population,generation)
pool_counts_high <- pool_counts_high %>% setNames(gsub("_D","",names(.)))

# pool_counts_high_4FR <- pool_counts_high %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_high_4FR
pool_counts_high_tidy <- pool_counts_high %>% gather(ratio,value,-generation,-population,factor_key=T)


##Errors:
pool_errors_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.high_recombination.Pb-000_4fold_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors_high <- cbind(pool_errors_high,pool_counts_high$fourfold_D)
#names(pool_errors_high)[names(pool_errors_high) == 'pool_counts_high$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors_high <- left_join(pool_errors_high,codes_dictionary,by=c("population"="old"))
pool_errors_high$population = factor(pool_errors_high$population,levels=c("Pb","lines"))
pool_errors_high$generation <- as.numeric(gsub("gen","",pool_errors_high$generation)) + 83
pool_errors_high <- pool_errors_high %>% arrange(generation)
pool_errors_high$generation = factor(pool_errors_high$generation)
pool_errors_high <- pool_errors_high %>% arrange(population,generation)
pool_errors_high <- pool_errors_high %>% setNames(gsub("_D","",names(.)))

# pool_errors_high_4FR <- pool_errors_high %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_high_4FR
pool_errors_high_tidy <- pool_errors_high %>% gather(ratio,value,-generation,-population,factor_key=T)


##Combined:
combined_tidy_high <- left_join(pool_counts_high_tidy,pool_errors_high_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_high) <- c("population","generation","ratio","mean","error")


####Then combine both datasets####
combined_tidy <- rbind(mutate(combined_tidy_low,recombination="low"),mutate(combined_tidy_high,recombination="high"))
combined_tidy$recombination = factor(combined_tidy$recombination,levels=c("low","high"))


####Then plot the data####
combined_tidy_bis <- combined_tidy
combined_tidy_bis$generation <- as.numeric(as.character(combined_tidy_bis$generation))
combined_tidy_bis$ratio <- factor(combined_tidy_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined version:
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy_bis,ratio!="fourfold",ratio!="m. tolerated",generation!=5), aes(generation,mean,group=interaction(recombination,population))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +  
  geom_line(aes(colour=recombination,linetype=population,alpha=recombination),size=0.5,position=position_dodge(0.8)) +
  geom_point(aes(colour=recombination,shape=population),size=2,position=position_dodge(0.8)) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=recombination, group=interaction(population,recombination)), alpha=0.4, position=position_dodge(0.8),size=0.5,width=0.5) +
  ylab("Derived count relative to Pb-083 and 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.5, 1.2, by = 0.2)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  scale_linetype_manual(values=c(1,3)) +
  scale_shape_manual(values=c(16,18)) +
  scale_alpha_manual(values=c(0.8,0.4)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(linetype="none",alpha="none",shape = guide_legend(order = 1),colour = guide_legend(order = 2)) +
  labs(shape = "Population",colour = "Recombination") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_text()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot
#ggsave(paste0("Pb_lines_relativised_pool_counts_copies_adequateerrors_4FR_",type,".all_recombination.bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)
ggsave("20231205_main_recombination.pdf", width=15, height=12, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/")


```

######Double ratio (4fold without new mutation):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


####First, process the low recombination dataset####
##Averages:
pool_counts_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.low_recombination.Pb-000_4fold_rel_syn_wout.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
pool_counts_low$population = factor(pool_counts_low$population,levels=c("Pb","lines"))
pool_counts_low$generation <- as.numeric(gsub("gen","",pool_counts_low$generation)) + 83
pool_counts_low <- pool_counts_low %>% arrange(generation)
pool_counts_low$generation = factor(pool_counts_low$generation)
pool_counts_low <- pool_counts_low %>% arrange(population,generation)
pool_counts_low <- pool_counts_low %>% setNames(gsub("_D","",names(.)))

# pool_counts_low_4FR <- pool_counts_low %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_low_4FR
pool_counts_low_tidy <- pool_counts_low %>% gather(ratio,value,-generation,-population,factor_key=T)

##Errors:
pool_errors_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.low_recombination.Pb-000_4fold_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors_low <- cbind(pool_errors_low,pool_counts_low$fourfold_D)
#names(pool_errors_low)[names(pool_errors_low) == 'pool_counts_low$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors_low <- left_join(pool_errors_low,codes_dictionary,by=c("population"="old"))
pool_errors_low$population = factor(pool_errors_low$population,levels=c("Pb","lines"))
pool_errors_low$generation <- as.numeric(gsub("gen","",pool_errors_low$generation)) + 83
pool_errors_low <- pool_errors_low %>% arrange(generation)
pool_errors_low$generation = factor(pool_errors_low$generation)
pool_errors_low <- pool_errors_low %>% arrange(population,generation)
pool_errors_low <- pool_errors_low %>% setNames(gsub("_D","",names(.)))

# pool_errors_low_4FR <- pool_errors_low %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_low_4FR
pool_errors_low_tidy <- pool_errors_low %>% gather(ratio,value,-generation,-population,factor_key=T)

##Combined:
combined_tidy_low <- left_join(pool_counts_low_tidy,pool_errors_low_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_low) <- c("population","generation","ratio","mean","error")


####Next, process the high recombination dataset####
##Averages:
pool_counts_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.high_recombination.Pb-000_4fold_rel_syn_wout.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
pool_counts_high$population = factor(pool_counts_high$population,levels=c("Pb","lines"))
pool_counts_high$generation <- as.numeric(gsub("gen","",pool_counts_high$generation)) + 83
pool_counts_high <- pool_counts_high %>% arrange(generation)
pool_counts_high$generation = factor(pool_counts_high$generation)
pool_counts_high <- pool_counts_high %>% arrange(population,generation)
pool_counts_high <- pool_counts_high %>% setNames(gsub("_D","",names(.)))

# pool_counts_high_4FR <- pool_counts_high %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_high_4FR
pool_counts_high_tidy <- pool_counts_high %>% gather(ratio,value,-generation,-population,factor_key=T)


##Errors:
pool_errors_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.high_recombination.Pb-000_4fold_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors_high <- cbind(pool_errors_high,pool_counts_high$fourfold_D)
#names(pool_errors_high)[names(pool_errors_high) == 'pool_counts_high$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors_high <- left_join(pool_errors_high,codes_dictionary,by=c("population"="old"))
pool_errors_high$population = factor(pool_errors_high$population,levels=c("Pb","lines"))
pool_errors_high$generation <- as.numeric(gsub("gen","",pool_errors_high$generation)) + 83
pool_errors_high <- pool_errors_high %>% arrange(generation)
pool_errors_high$generation = factor(pool_errors_high$generation)
pool_errors_high <- pool_errors_high %>% arrange(population,generation)
pool_errors_high <- pool_errors_high %>% setNames(gsub("_D","",names(.)))

# pool_errors_high_4FR <- pool_errors_high %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_high_4FR
pool_errors_high_tidy <- pool_errors_high %>% gather(ratio,value,-generation,-population,factor_key=T)


##Combined:
combined_tidy_high <- left_join(pool_counts_high_tidy,pool_errors_high_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_high) <- c("population","generation","ratio","mean","error")


####Then combine both datasets####
combined_tidy <- rbind(mutate(combined_tidy_low,recombination="low"),mutate(combined_tidy_high,recombination="high"))
combined_tidy$recombination = factor(combined_tidy$recombination,levels=c("low","high"))


####Then plot the data####
combined_tidy_bis <- combined_tidy
combined_tidy_bis$generation <- as.numeric(as.character(combined_tidy_bis$generation))
combined_tidy_bis$ratio <- factor(combined_tidy_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined version:
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy_bis,ratio!="fourfold",ratio!="m. tolerated",generation!=5), aes(generation,mean,group=interaction(recombination,population))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +  
  geom_line(aes(colour=recombination,linetype=population,alpha=recombination),size=0.5,position=position_dodge(0.8)) +
  geom_point(aes(colour=recombination,shape=population),size=2,position=position_dodge(0.8)) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=recombination, group=interaction(population,recombination)), alpha=0.4, position=position_dodge(0.8),size=0.5,width=0.5) +
  ylab("Derived count relative to Pb-083 and 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.5, 1.2, by = 0.2)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  scale_linetype_manual(values=c(1,3)) +
  scale_shape_manual(values=c(16,18)) +
  scale_alpha_manual(values=c(0.8,0.4)) +
  ylim(0.6,1.2) +
  #ggtitle("Including new mutation") +
  guides(linetype="none",alpha="none",shape = guide_legend(order = 1),colour = guide_legend(order = 2)) +
  labs(shape = "Population",colour = "Recombination") +
  theme_bw() +
  theme(text=element_text(size=8,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_blank(),
        #axis.title=element_text(size=11,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(-1,-1,-1,-1),"cm"),
        #plot.title=element_text(hjust=0.5),
        strip.text=element_text(size=9,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_text()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot
#ggsave(paste0("Pb_lines_relativised_pool_counts_copies_adequateerrors_4FR_",type,".all_recombination.bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)
#ggsave("20231220_main_recombination.syn_wout.pdf", width=16.2, height=12, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/")


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.13,hjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=1))

#ggsave("20231211_main_empirical.syn_wout.pdf", width=20, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot,width=unit(6,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.42,vjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=1))

#ggsave("20240314_main_recombination.syn_wout.pdf", width=17.2, height=10, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

ggsave("20240315_main_recombination.syn_wout.pdf", width=12, height=8.5, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#STOP

```

####Gen0-140 pools Pb booterror and line averages empirerror (separate version):
#####All sites:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))

#Pb
##Averages:
pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.Pb-000_4fold_rel.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

##Errors:
pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.Pb-000_4fold_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
#names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)
pool_errors <- pool_errors %>% setNames(gsub("_D","",names(.)))

# pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_4FR
pool_errors_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

##Combined:
combined_tidy <- left_join(pool_counts_tidy,pool_errors_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")


#Line averages:
pool_counts_lines <- read_tsv(paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/counts_pool_gen0-140_",type,"_summary.txt")) %>% select(.,sample,generation,contains("_D")) %>% filter(generation!="gen5")
pool_counts_lines <- left_join(pool_counts_lines,codes_dictionary,by=c("sample"="old"))
pool_counts_lines$population = factor(pool_counts_lines$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))

pool_counts_lines$generation <- as.numeric(gsub("gen","",pool_counts_lines$generation))
pool_counts_lines <- pool_counts_lines %>% arrange(generation)
pool_counts_lines$generation = factor(pool_counts_lines$generation)
pool_counts_lines <- pool_counts_lines %>% arrange(population,generation)

pool_counts_lines_4FR <- pool_counts_lines %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_lines_4FR

r_average_vector <- c()
for (r in unique(pool_counts_lines_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_lines_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_lines_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_lines_4FR <- mutate(pool_counts_lines_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines")) %>% filter(group!="Pb")
relativised_pool_counts_lines_4FR$group = factor(relativised_pool_counts_lines_4FR$group,levels=c("Pb","lines"))


#Plot the data:
#Humberto version (Pb):
Pb_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy,population=="Pb",ratio!="fourfold",ratio!="tolerated",generation!=5), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count\n relative to Pb-000 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ylim(0.6,1.2) +
  ggtitle("Empirical pools, Pb, bootstrap error") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("Pb_relativised_pool_counts_copies_4FR_",type,".bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

#Humberto version (lines):
lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(relativised_pool_counts_lines_4FR,ratio!="fourfold",ratio!="tolerated"), aes(generation,Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_boxplot(aes(colour=generation)) +
  #geom_errorbar(aes(ymin=avg_Pb_relative_value-se_Pb_relative_value, ymax=avg_Pb_relative_value+se_Pb_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count\n relative to Pb-000 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  ylim(0.6,1.2) +
  ggtitle("Empirical pools, lines") +
  #guides(colour="none") +
  labs(colour = "Generation") +
  scale_colour_manual(values=c(hue_pal()(5)[4:5])) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_text()
  )
lines_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("lines_relativised_pool_counts_copies_4FR_",type,".bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

#####Recombination:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


####First, process the low recombination dataset####
#Pb:
##Averages:
pool_counts_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.low_recombination.Pb-000_4fold_rel.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
pool_counts_low$population = factor(pool_counts_low$population,levels=c("Pb","lines"))
pool_counts_low$generation <- as.numeric(gsub("gen","",pool_counts_low$generation))
pool_counts_low <- pool_counts_low %>% arrange(generation)
pool_counts_low$generation = factor(pool_counts_low$generation)
pool_counts_low <- pool_counts_low %>% arrange(population,generation)
pool_counts_low <- pool_counts_low %>% setNames(gsub("_D","",names(.)))

# pool_counts_low_4FR <- pool_counts_low %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_low_4FR
pool_counts_low_tidy <- pool_counts_low %>% gather(ratio,value,-generation,-population,factor_key=T)

##Errors:
pool_errors_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.low_recombination.Pb-000_4fold_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors_low <- cbind(pool_errors_low,pool_counts_low$fourfold_D)
#names(pool_errors_low)[names(pool_errors_low) == 'pool_counts_low$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors_low <- left_join(pool_errors_low,codes_dictionary,by=c("population"="old"))
pool_errors_low$population = factor(pool_errors_low$population,levels=c("Pb","lines"))
pool_errors_low$generation <- as.numeric(gsub("gen","",pool_errors_low$generation))
pool_errors_low <- pool_errors_low %>% arrange(generation)
pool_errors_low$generation = factor(pool_errors_low$generation)
pool_errors_low <- pool_errors_low %>% arrange(population,generation)
pool_errors_low <- pool_errors_low %>% setNames(gsub("_D","",names(.)))

# pool_errors_low_4FR <- pool_errors_low %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_low_4FR
pool_errors_low_tidy <- pool_errors_low %>% gather(ratio,value,-generation,-population,factor_key=T)

##Combined:
combined_tidy_low <- left_join(pool_counts_low_tidy,pool_errors_low_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_low) <- c("population","generation","ratio","mean","error")


#Line averages:
pool_counts_lines_low <- read_tsv(paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/counts_pool_gen0-140_",type,"_summary.low_recombination.txt")) %>% select(.,sample,generation,contains("_D")) %>% filter(generation!="gen5")
pool_counts_lines_low <- left_join(pool_counts_lines_low,codes_dictionary,by=c("sample"="old"))
pool_counts_lines_low$population = factor(pool_counts_lines_low$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))

pool_counts_lines_low$generation <- as.numeric(gsub("gen","",pool_counts_lines_low$generation))
pool_counts_lines_low <- pool_counts_lines_low %>% arrange(generation)
pool_counts_lines_low$generation = factor(pool_counts_lines_low$generation)
pool_counts_lines_low <- pool_counts_lines_low %>% arrange(population,generation)

pool_counts_lines_low_4FR <- pool_counts_lines_low %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_lines_low_4FR

r_average_vector <- c()
for (r in unique(pool_counts_lines_low_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_lines_low_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_lines_low_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_lines_low_4FR <- mutate(pool_counts_lines_low_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines")) %>% filter(group!="Pb")
relativised_pool_counts_lines_low_4FR$group = factor(relativised_pool_counts_lines_low_4FR$group,levels=c("Pb","lines"))


####Next, process the high recombination dataset####
#Pb:
##Averages:
pool_counts_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.high_recombination.Pb-000_4fold_rel.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.)))
pool_counts_high$population = factor(pool_counts_high$population,levels=c("Pb","lines"))
pool_counts_high$generation <- as.numeric(gsub("gen","",pool_counts_high$generation))
pool_counts_high <- pool_counts_high %>% arrange(generation)
pool_counts_high$generation = factor(pool_counts_high$generation)
pool_counts_high <- pool_counts_high %>% arrange(population,generation)
pool_counts_high <- pool_counts_high %>% setNames(gsub("_D","",names(.)))

# pool_counts_high_4FR <- pool_counts_high %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_high_4FR
pool_counts_high_tidy <- pool_counts_high %>% gather(ratio,value,-generation,-population,factor_key=T)

##Errors:
pool_errors_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.high_recombination.Pb-000_4fold_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.)))
#pool_errors_high <- cbind(pool_errors_high,pool_counts_high$fourfold_D)
#names(pool_errors_high)[names(pool_errors_high) == 'pool_counts_high$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors_high <- left_join(pool_errors_high,codes_dictionary,by=c("population"="old"))
pool_errors_high$population = factor(pool_errors_high$population,levels=c("Pb","lines"))
pool_errors_high$generation <- as.numeric(gsub("gen","",pool_errors_high$generation))
pool_errors_high <- pool_errors_high %>% arrange(generation)
pool_errors_high$generation = factor(pool_errors_high$generation)
pool_errors_high <- pool_errors_high %>% arrange(population,generation)
pool_errors_high <- pool_errors_high %>% setNames(gsub("_D","",names(.)))

# pool_errors_high_4FR <- pool_errors_high %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_high_4FR
pool_errors_high_tidy <- pool_errors_high %>% gather(ratio,value,-generation,-population,factor_key=T)

##Combined:
combined_tidy_high <- left_join(pool_counts_high_tidy,pool_errors_high_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_high) <- c("population","generation","ratio","mean","error")


#Line averages:
pool_counts_lines_high <- read_tsv(paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/counts_pool_gen0-140_",type,"_summary.high_recombination.txt")) %>% select(.,sample,generation,contains("_D"))
pool_counts_lines_high <- left_join(pool_counts_lines_high,codes_dictionary,by=c("sample"="old"))
pool_counts_lines_high$population = factor(pool_counts_lines_high$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))

pool_counts_lines_high$generation <- as.numeric(gsub("gen","",pool_counts_lines_high$generation))
pool_counts_lines_high <- pool_counts_lines_high %>% arrange(generation)
pool_counts_lines_high$generation = factor(pool_counts_lines_high$generation)
pool_counts_lines_high <- pool_counts_lines_high %>% arrange(population,generation)

pool_counts_lines_high_4FR <- pool_counts_lines_high %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_lines_high_4FR

r_average_vector <- c()
for (r in unique(pool_counts_lines_high_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_lines_high_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_lines_high_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_lines_high_4FR <- mutate(pool_counts_lines_high_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines")) %>% filter(group!="Pb")
relativised_pool_counts_lines_high_4FR$group = factor(relativised_pool_counts_lines_high_4FR$group,levels=c("Pb","lines"))


####Then combine both datasets####
#Pb:
combined_tidy <- rbind(mutate(combined_tidy_low,recombination="low"),mutate(combined_tidy_high,recombination="high"))
combined_tidy$recombination = factor(combined_tidy$recombination,levels=c("low","high"))

#Lines:
combined_tidy_lines <- rbind(mutate(relativised_pool_counts_lines_low_4FR,recombination="low"),mutate(relativised_pool_counts_lines_high_4FR,recombination="high"))
combined_tidy_lines$recombination = factor(combined_tidy_lines$recombination,levels=c("low","high"))



#Plot the data:
Pb_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy,population=="Pb",ratio!="fourfold",ratio!="tolerated",generation!=5), aes(generation,mean,group=interaction(recombination,population))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_line(aes(colour=recombination),linetype=2,alpha=0.4,size=0.5,position=position_dodge(0.8)) +
  geom_point(aes(colour=recombination),size=2,position=position_dodge(0.8)) + 
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=recombination, group=interaction(population,recombination)),alpha=0.4,position=position_dodge(0.8),size=0.5,width=0.5) +
  ylab("Derived count\n relative to Pb-000 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.4, 1.2, by = 0.2)) +
  scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ylim(0.4,1.4) +
  #ggtitle("Empirical pools, Pb, bootstrap error") +
  ggtitle("Empirical pools, Pb") +
  #guides(colour="none") +
  labs(colour = "Recombination") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_text()
  )
Pb_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("Pb_relativised_pool_counts_copies_4FR_",type,".all_recombination.bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

#Humberto version (lines):
lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy_lines,ratio!="fourfold",ratio!="tolerated"), aes(ratio,Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(generation ~ ., labeller = labeller(generation=c("40" = "Generation 40", "140" = "Generation 140"))) +
  geom_boxplot(aes(colour=recombination)) +
  #geom_errorbar(aes(ymin=avg_Pb_relative_value-se_Pb_relative_value, ymax=avg_Pb_relative_value+se_Pb_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count\n relative to Pb-000 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.4, 1.2, by = 0.1)) +
  ylim(0.4,1.4) +
  ggtitle("Empirical pools, lines") +
  #guides(colour="none") +
  labs(colour = "Recombination") +
  #scale_colour_manual(values=c(hue_pal()(5)[4:5])) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_text()
  )
lines_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("lines_relativised_pool_counts_copies_4FR_",type,".all_recombination.bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

#####WRONG All sites:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


#Pb
##Averages:
pool_counts_Pb <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.empirmean_Pb-000_rel.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(population=="Pb")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts_Pb$population = factor(pool_counts_Pb$population,levels=c("Pb","lines"))
pool_counts_Pb$generation <- as.numeric(gsub("gen","",pool_counts_Pb$generation))
pool_counts_Pb <- pool_counts_Pb %>% arrange(generation)
pool_counts_Pb$generation = factor(pool_counts_Pb$generation)
pool_counts_Pb <- pool_counts_Pb %>% arrange(population,generation)

pool_counts_Pb_4FR <- pool_counts_Pb %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_Pb_4FR

##Errors:
pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.adequateerror_Pb-000_rel.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(population=="Pb")
pool_errors <- cbind(pool_errors,pool_counts_Pb$fourfold_D)
names(pool_errors)[names(pool_errors) == 'pool_counts_Pb$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_4FR

##Combined:
combined_tidy <- left_join(pool_counts_Pb_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
colnames(combined_tidy) <- c("population","generation","ratio","mean","error")


#Line averages:
pool_counts_lines <- read_tsv(paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/counts_pool_gen0-140_",type,"_summary.txt")) %>% select(.,sample,generation,contains("_D"))
pool_counts_lines <- left_join(pool_counts_lines,codes_dictionary,by=c("sample"="old"))
pool_counts_lines$population = factor(pool_counts_lines$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))

pool_counts_lines$generation <- as.numeric(gsub("gen","",pool_counts_lines$generation))
pool_counts_lines <- pool_counts_lines %>% arrange(generation)
pool_counts_lines$generation = factor(pool_counts_lines$generation)
pool_counts_lines <- pool_counts_lines %>% arrange(population,generation)

pool_counts_lines_4FR <- pool_counts_lines %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_lines_4FR

r_average_vector <- c()
for (r in unique(pool_counts_lines_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_lines_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_lines_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_lines_4FR <- mutate(pool_counts_lines_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines")) %>% filter(group!="Pb")
relativised_pool_counts_lines_4FR$group = factor(relativised_pool_counts_lines_4FR$group,levels=c("Pb","lines"))


# se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function
# 
# average_relativised_pool_counts_lines_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe
# 
# for (pop in unique(relativised_pool_counts_lines_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
#   print(pop)
#   for (g in unlist(unique(select(filter(relativised_pool_counts_lines_4FR,group==pop),generation)),use.names=F)) {
#   #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
#     for (r in unique(relativised_pool_counts_lines_4FR$ratio)) {
#       print(r)
#       pop_mean <- filter(relativised_pool_counts_lines_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
#       #print(paste0(pop," feature ",r," average is ",pop_mean))
#       pop_se <- filter(relativised_pool_counts_lines_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
#       #print(paste0(pop," feature ",r," std error is ",pop_se))
#       row_data <- cbind(pop,g,r,pop_mean,pop_se)
#       colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
#       average_relativised_pool_counts_lines_4FR <- rbind(average_relativised_pool_counts_lines_4FR,row_data,stringsAsFactors=F)
#     }
#   }
# }
# average_relativised_pool_counts_lines_4FR$population = factor(average_relativised_pool_counts_lines_4FR$population,levels=c("Pb","lines"))
# average_relativised_pool_counts_lines_4FR$ratio = factor(average_relativised_pool_counts_lines_4FR$ratio,levels=c("fourfold","missense","tolerated","deleterious","LoF"))
# average_relativised_pool_counts_lines_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_lines_4FR$generation))
# average_relativised_pool_counts_lines_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_lines_4FR$avg_Pb_relative_value)
# average_relativised_pool_counts_lines_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_lines_4FR$se_Pb_relative_value)
# average_relativised_pool_counts_lines_4FR <- average_relativised_pool_counts_lines_4FR %>% filter(population=="lines")

#Plot the data:
#Humberto version (Pb):
Pb_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy,ratio!="fourfold", generation!=5), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count\n relative to Pb-000 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  ylim(0.6,1.2) +
  ggtitle("Empirical pools, Pb, bootstrap error") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("Pb_relativised_pool_counts_copies_4FR_",type,".bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

#Humberto version (lines):
lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(relativised_pool_counts_lines_4FR, ratio!="fourfold"), aes(ratio,Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  #facet_grid(. ~ population) +
  geom_boxplot(aes(colour=generation)) +
  #geom_errorbar(aes(ymin=avg_Pb_relative_value-se_Pb_relative_value, ymax=avg_Pb_relative_value+se_Pb_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count\n relative to Pb-000 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  ylim(0.6,1.2) +
  ggtitle("Empirical pools, lines") +
  #guides(colour="none") +
  labs(colour = "Generation") +
  scale_colour_manual(values=c(hue_pal()(5)[4:5])) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_text()
  )
lines_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("lines_relativised_pool_counts_copies_4FR_",type,".bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

#####WRONG Recombination:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


####First, process the low recombination dataset####
#Pb:
##Averages:
pool_counts_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.low_recombination.empirmean_Pb-000_rel.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(population=="Pb")
pool_counts_low$population = factor(pool_counts_low$population,levels=c("Pb","lines"))
pool_counts_low$generation <- as.numeric(gsub("gen","",pool_counts_low$generation))
pool_counts_low <- pool_counts_low %>% arrange(generation)
pool_counts_low$generation = factor(pool_counts_low$generation)
pool_counts_low <- pool_counts_low %>% arrange(population,generation)

pool_counts_low_4FR <- pool_counts_low %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_low_4FR

##Errors:
pool_errors_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.low_recombination.adequateerror_Pb-000_rel.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(population=="Pb")
pool_errors_low <- cbind(pool_errors_low,pool_counts_low$fourfold_D)
names(pool_errors_low)[names(pool_errors_low) == 'pool_counts_low$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors_low <- left_join(pool_errors_low,codes_dictionary,by=c("population"="old"))
pool_errors_low$population = factor(pool_errors_low$population,levels=c("Pb","lines"))
pool_errors_low$generation <- as.numeric(gsub("gen","",pool_errors_low$generation))
pool_errors_low <- pool_errors_low %>% arrange(generation)
pool_errors_low$generation = factor(pool_errors_low$generation)
pool_errors_low <- pool_errors_low %>% arrange(population,generation)

pool_errors_low_4FR <- pool_errors_low %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_low_4FR

##Finally, combine the averages and errors into a single dataset:
combined_tidy_low <- left_join(pool_counts_low_4FR,pool_errors_low_4FR,by=c("population","generation","ratio"))
colnames(combined_tidy_low) <- c("population","generation","ratio","mean","error")

#Line averages:
pool_counts_lines_low <- read_tsv(paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/counts_pool_gen0-140_",type,"_summary.low_recombination.txt")) %>% select(.,sample,generation,contains("_D"))
pool_counts_lines_low <- left_join(pool_counts_lines_low,codes_dictionary,by=c("sample"="old"))
pool_counts_lines_low$population = factor(pool_counts_lines_low$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))

pool_counts_lines_low$generation <- as.numeric(gsub("gen","",pool_counts_lines_low$generation))
pool_counts_lines_low <- pool_counts_lines_low %>% arrange(generation)
pool_counts_lines_low$generation = factor(pool_counts_lines_low$generation)
pool_counts_lines_low <- pool_counts_lines_low %>% arrange(population,generation)

pool_counts_lines_low_4FR <- pool_counts_lines_low %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_lines_low_4FR

r_average_vector <- c()
for (r in unique(pool_counts_lines_low_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_lines_low_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_lines_low_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_lines_low_4FR <- mutate(pool_counts_lines_low_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines")) %>% filter(group!="Pb")
relativised_pool_counts_lines_low_4FR$group = factor(relativised_pool_counts_lines_low_4FR$group,levels=c("Pb","lines"))


####Next, process the high recombination dataset####
##Averages:
pool_counts_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.high_recombination.empirmean_Pb-000_rel.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(population=="Pb")
pool_counts_high$population = factor(pool_counts_high$population,levels=c("Pb","lines"))
pool_counts_high$generation <- as.numeric(gsub("gen","",pool_counts_high$generation))
pool_counts_high <- pool_counts_high %>% arrange(generation)
pool_counts_high$generation = factor(pool_counts_high$generation)
pool_counts_high <- pool_counts_high %>% arrange(population,generation)

pool_counts_high_4FR <- pool_counts_high %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_high_4FR

##Errors:
pool_errors_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.high_recombination.adequateerror_Pb-000_rel.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(population=="Pb")
pool_errors_high <- cbind(pool_errors_high,pool_counts_high$fourfold_D)
names(pool_errors_high)[names(pool_errors_high) == 'pool_counts_high$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors_high <- left_join(pool_errors_high,codes_dictionary,by=c("population"="old"))
pool_errors_high$population = factor(pool_errors_high$population,levels=c("Pb","lines"))
pool_errors_high$generation <- as.numeric(gsub("gen","",pool_errors_high$generation))
pool_errors_high <- pool_errors_high %>% arrange(generation)
pool_errors_high$generation = factor(pool_errors_high$generation)
pool_errors_high <- pool_errors_high %>% arrange(population,generation)

pool_errors_high_4FR <- pool_errors_high %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_high_4FR

##Finally, combine the averages and errors into a single dataset:
combined_tidy_high <- left_join(pool_counts_high_4FR,pool_errors_high_4FR,by=c("population","generation","ratio"))
colnames(combined_tidy_high) <- c("population","generation","ratio","mean","error")

#Line averages:
pool_counts_lines_high <- read_tsv(paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/counts_pool_gen0-140_",type,"_summary.high_recombination.txt")) %>% select(.,sample,generation,contains("_D"))
pool_counts_lines_high <- left_join(pool_counts_lines_high,codes_dictionary,by=c("sample"="old"))
pool_counts_lines_high$population = factor(pool_counts_lines_high$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))

pool_counts_lines_high$generation <- as.numeric(gsub("gen","",pool_counts_lines_high$generation))
pool_counts_lines_high <- pool_counts_lines_high %>% arrange(generation)
pool_counts_lines_high$generation = factor(pool_counts_lines_high$generation)
pool_counts_lines_high <- pool_counts_lines_high %>% arrange(population,generation)

pool_counts_lines_high_4FR <- pool_counts_lines_high %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_lines_high_4FR

r_average_vector <- c()
for (r in unique(pool_counts_lines_high_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_lines_high_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_lines_high_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_lines_high_4FR <- mutate(pool_counts_lines_high_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines")) %>% filter(group!="Pb")
relativised_pool_counts_lines_high_4FR$group = factor(relativised_pool_counts_lines_high_4FR$group,levels=c("Pb","lines"))


####Then combine both datasets####
#Pb:
combined_tidy <- rbind(mutate(combined_tidy_low,recombination="low"),mutate(combined_tidy_high,recombination="high"))
combined_tidy$recombination = factor(combined_tidy$recombination,levels=c("low","high"))

#Lines:
combined_tidy_lines <- rbind(mutate(relativised_pool_counts_lines_low_4FR,recombination="low"),mutate(relativised_pool_counts_lines_high_4FR,recombination="high"))
combined_tidy_lines$recombination = factor(combined_tidy_lines$recombination,levels=c("low","high"))


####Then plot the data####
#Humberto version (Pb):
Pb_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy,ratio!="fourfold", generation!=5), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(aes(colour=recombination),size=2,position=position_dodge(0.8)) + 
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=recombination, group=interaction(population,recombination)),alpha=0.4,position=position_dodge(0.8),size=0.5,width=0.5) +
  ylab("Derived count\n relative to Pb-000 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.4, 1.2, by = 0.2)) +
  ylim(0.4,1.4) +
  ggtitle("Empirical pools, Pb, bootstrap error") +
  #guides(colour="none") +
  labs(colour = "Recombination") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_text()
  )
Pb_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("Pb_relativised_pool_counts_copies_4FR_",type,".all_recombination.bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

#Humberto version (lines):
lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy_lines, ratio!="fourfold"), aes(ratio,Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(generation ~ ., labeller = labeller(generation=c("40" = "Generation 40", "140" = "Generation 140"))) +
  geom_boxplot(aes(colour=recombination)) +
  #geom_errorbar(aes(ymin=avg_Pb_relative_value-se_Pb_relative_value, ymax=avg_Pb_relative_value+se_Pb_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count\n relative to Pb-000 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.4, 1.2, by = 0.1)) +
  ylim(0.4,1.4) +
  ggtitle("Empirical pools, lines") +
  #guides(colour="none") +
  labs(colour = "Recombination") +
  #scale_colour_manual(values=c(hue_pal()(5)[4:5])) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_text()
  )
lines_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("lines_relativised_pool_counts_copies_4FR_",type,".all_recombination.bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

#X. Carry out additional analyses:
##Explore high- and low-frequency missense mutations:
###Define high- and low-frequency missense mutations:
```{bash}

PERCENTIL=10 #define the percentage of sites that will be kept as high- and low-frequency mutations.

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts
module load gcc/7.2.0
module add gcc/7.2.0

awk -F"\t" '{printf ("%s\t%s\n", $0,$11/($10+$11))}' LBT0_gen0_gen0-140_pool_autosomes.txt | awk -F '$12 != "1"' > LBT0_gen0_gen0-140_pool_autosomes.af.txt

#Tolerated:
N_TOL=$(grep "CUSTOM=tolerated;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | wc -l)
TARGET_TOL=$(echo "scale=1; $N_TOL*$PERCENTIL*0.01" | bc | awk '{printf("%d\n",$1+0.5)}')
grep "CUSTOM=tolerated;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | LC_NUMERIC=C sort -g -k12,12 | head -n $TARGET_TOL | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2,$3)}' | bedtools sort > LBT0_gen0_gen0-140_pool_autosomes.tol_low_af.bed
grep "CUSTOM=tolerated;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | LC_NUMERIC=C sort -g -k12,12 | tail -n $TARGET_TOL | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2,$3)}' | bedtools sort > LBT0_gen0_gen0-140_pool_autosomes.tol_high_af.bed

#Deleterious:
N_DEL=$(grep "CUSTOM=deleterious;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | wc -l)
TARGET_DEL=$(echo "scale=1; $N_DEL*$PERCENTIL*0.01" | bc | awk '{printf("%d\n",$1+0.5)}')
grep "CUSTOM=deleterious;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | LC_NUMERIC=C sort -g -k12,12 | head -n $TARGET_DEL | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2,$3)}' | bedtools sort > LBT0_gen0_gen0-140_pool_autosomes.del_low_af.bed
grep "CUSTOM=deleterious;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | LC_NUMERIC=C sort -g -k12,12 | tail -n $TARGET_DEL | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2,$3)}' | bedtools sort > LBT0_gen0_gen0-140_pool_autosomes.del_high_af.bed

#Missense:
N_MIS=$(grep -E "CUSTOM=tolerated;|CUSTOM=deleterious;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | wc -l)
TARGET_MIS=$(echo "scale=1; $N_MIS*$PERCENTIL*0.01" | bc | awk '{printf("%d\n",$1+0.5)}')
grep -E "CUSTOM=tolerated;|CUSTOM=deleterious;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | LC_NUMERIC=C sort -g -k12,12 | head -n $TARGET_MIS | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2,$3)}' | bedtools sort > LBT0_gen0_gen0-140_pool_autosomes.mis_low_af.bed
grep -E "CUSTOM=tolerated;|CUSTOM=deleterious;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | LC_NUMERIC=C sort -g -k12,12 | tail -n $TARGET_MIS | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2,$3)}' | bedtools sort > LBT0_gen0_gen0-140_pool_autosomes.mis_high_af.bed

#LoF:
N_LOF=$(grep "CUSTOM=LoF;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | wc -l)
TARGET_LOF=$(echo "scale=1; $N_LOF*$PERCENTIL*0.01" | bc | awk '{printf("%d\n",$1+0.5)}')
grep "CUSTOM=LoF;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | LC_NUMERIC=C sort -g -k12,12 | head -n $TARGET_LOF | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2,$3)}' | bedtools sort > LBT0_gen0_gen0-140_pool_autosomes.LoF_low_af.bed
grep "CUSTOM=LoF;" LBT0_gen0_gen0-140_pool_autosomes.af.txt | LC_NUMERIC=C sort -g -k12,12 | tail -n $TARGET_LOF | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2,$3)}' | bedtools sort > LBT0_gen0_gen0-140_pool_autosomes.LoF_high_af.bed

```

###Retrieve derived counts per category:
```{R, engine='bash'}

REGION="autosomes" #all #autosomes #Xchr
AF="high" #high #low

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
rm counts_pool_gen0-140_${REGION}_summary.${AF}_af_sites.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\tmissense_V\tmissense_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > counts_pool_gen0-140_${REGION}_summary.${AF}_af_sites.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-140_pool.txt' -print`))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l) #these aren't the high/low AF fraction, but the total
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  
  bedtools intersect -a $p -b LBT0_gen0_gen0-140_pool_autosomes.mis_${AF}_af.bed > ${p/.txt/.mis_${AF}_af.rm}
  MISSENSE_V=$(wc -l <  ${p/.txt/.mis_${AF}_af.rm})
  MISSENSE_D=$(awk '{print $11}' ${p/.txt/.mis_${AF}_af.rm} | paste -sd+ | bc)

  bedtools intersect -a $p -b LBT0_gen0_gen0-140_pool_autosomes.tol_${AF}_af.bed > ${p/.txt/.tol_${AF}_af.rm}
  MISTOL_V=$(wc -l < ${p/.txt/.tol_${AF}_af.rm})
  MISTOL_D=$(awk '{print $11}' ${p/.txt/.tol_${AF}_af.rm} | paste -sd+ | bc)
  
  bedtools intersect -a $p -b LBT0_gen0_gen0-140_pool_autosomes.del_${AF}_af.bed > ${p/.txt/.del_${AF}_af.rm}
  MISDEL_V=$(wc -l < ${p/.txt/.del_${AF}_af.rm})
  MISDEL_D=$(awk '{print $11}' ${p/.txt/.del_${AF}_af.rm} | paste -sd+ | bc)
  
  bedtools intersect -a $p -b LBT0_gen0_gen0-140_pool_autosomes.LoF_${AF}_af.bed > ${p/.txt/.LoF_${AF}_af.rm}
  LOF_V=$(wc -l < ${p/.txt/.LoF_${AF}_af.rm})
  if [ $LOF_V == 0 ]
    then LOF_D=0
    else LOF_D=$(awk '{print $11}' ${p/.txt/.LoF_${AF}_af.rm} | paste -sd+ | bc)
  fi
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISSENSE_V\t$MISSENSE_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> counts_pool_gen0-140_${REGION}_summary.${AF}_af_sites.txt
  done
  rm *.rm

#From the local environment:
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.${AF}_af_sites.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

###Plot counts:
####Absolute counts:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))

pool_counts_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.low_af_sites.txt")) %>% filter(generation!="gen5")
pool_counts_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.high_af_sites.txt")) %>% filter(generation!="gen5")


####First, process the low AF dataset####
pool_counts_low <- left_join(pool_counts_low,codes_dictionary,by=c("sample"="old"))
pool_counts_low$population = factor(pool_counts_low$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts_low$generation <- as.numeric(gsub("gen","",pool_counts_low$generation)) + 83
pool_counts_low <- pool_counts_low %>% arrange(generation)
pool_counts_low$generation = factor(pool_counts_low$generation)
pool_counts_low <- pool_counts_low %>% arrange(population,generation)

pool_counts_low_copies_absolute <- pool_counts_low %>% mutate(fourfold=fourfold_D,missense=missense_D,tolerated=tolerated_D,deleterious=deleterious_D,LoF=LoF_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(count,value,-generation,-population,factor_key=T) %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_counts_low_copies_absolute$group = factor(pool_counts_low_copies_absolute$group,levels=c("Pb","lines"))
pool_counts_low_copies_absolute


#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_pool_counts_low_copies_absolute <- data_frame("population"=character(0),"generation"=character(0),"AF"=character(0),"count"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(pool_counts_low_copies_absolute$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(pool_counts_low_copies_absolute,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(pool_counts_low_copies_absolute$count)) {
      print(r)
      pop_mean <- filter(pool_counts_low_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(pool_counts_low_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,"low",r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","AF","count","avg_value","se_value")
      average_pool_counts_low_copies_absolute <- rbind(average_pool_counts_low_copies_absolute,row_data,stringsAsFactors=F)
    }
  }
}
average_pool_counts_low_copies_absolute$population = factor(average_pool_counts_low_copies_absolute$population,levels=c("Pb","lines"))
average_pool_counts_low_copies_absolute$count = factor(average_pool_counts_low_copies_absolute$count,levels=c("fourfold","missense","tolerated","deleterious","LoF"))
average_pool_counts_low_copies_absolute$generation <- as.factor(as.numeric(average_pool_counts_low_copies_absolute$generation))
average_pool_counts_low_copies_absolute$avg_value <- as.numeric(average_pool_counts_low_copies_absolute$avg_value)
average_pool_counts_low_copies_absolute$se_value <- as.numeric(average_pool_counts_low_copies_absolute$se_value)
average_pool_counts_low_copies_absolute


####Next, process the high AF dataset####
pool_counts_high <- left_join(pool_counts_high,codes_dictionary,by=c("sample"="old"))
pool_counts_high$population = factor(pool_counts_high$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts_high$generation <- as.numeric(gsub("gen","",pool_counts_high$generation)) + 83
pool_counts_high <- pool_counts_high %>% arrange(generation)
pool_counts_high$generation = factor(pool_counts_high$generation)
pool_counts_high <- pool_counts_high %>% arrange(population,generation)

pool_counts_high_copies_absolute <- pool_counts_high %>% mutate(fourfold=fourfold_D,missense=missense_D,tolerated=tolerated_D,deleterious=deleterious_D,LoF=LoF_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(count,value,-generation,-population,factor_key=T) %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_counts_high_copies_absolute$group = factor(pool_counts_high_copies_absolute$group,levels=c("Pb","lines"))
pool_counts_high_copies_absolute


#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_pool_counts_high_copies_absolute <- data_frame("population"=character(0),"generation"=character(0),"AF"=character(0),"count"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(pool_counts_high_copies_absolute$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(pool_counts_high_copies_absolute,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(pool_counts_high_copies_absolute$count)) {
      print(r)
      pop_mean <- filter(pool_counts_high_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(pool_counts_high_copies_absolute,count==r & generation==g & group==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,"high",r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","AF","count","avg_value","se_value")
      average_pool_counts_high_copies_absolute <- rbind(average_pool_counts_high_copies_absolute,row_data,stringsAsFactors=F)
    }
  }
}
average_pool_counts_high_copies_absolute$population = factor(average_pool_counts_high_copies_absolute$population,levels=c("Pb","lines"))
average_pool_counts_high_copies_absolute$count = factor(average_pool_counts_high_copies_absolute$count,levels=c("fourfold","missense","tolerated","deleterious","LoF"))
average_pool_counts_high_copies_absolute$generation <- as.factor(as.numeric(average_pool_counts_high_copies_absolute$generation))
average_pool_counts_high_copies_absolute$avg_value <- as.numeric(average_pool_counts_high_copies_absolute$avg_value)
average_pool_counts_high_copies_absolute$se_value <- as.numeric(average_pool_counts_high_copies_absolute$se_value)
average_pool_counts_high_copies_absolute


####Then combine both datasets####
average_pool_counts_combined_copies_absolute <- rbind(average_pool_counts_low_copies_absolute,average_pool_counts_high_copies_absolute)
average_pool_counts_combined_copies_absolute$AF = factor(average_pool_counts_combined_copies_absolute$AF,levels=c("low","high"))


####Then plot the data####
#Combined version:
Pb_lines_relativised_pool_counts_copies_ggplot <- ggplot(data=average_pool_counts_combined_copies_absolute, aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_wrap(. ~ count, scales="free", nrow = 1) +
  #geom_line(aes(colour=recombination, group=interaction(recombination, population)),alpha=0.5,size=0.5) +
  geom_point(aes(colour=AF,shape=population),size=2,position=position_dodge(0.8)) +
  geom_errorbar(aes(ymin=avg_value-2*se_value, ymax=avg_value+2*se_value,colour=AF,group=interaction(population,AF)), position=position_dodge(0.8),size=0.5,width=0.5) +
  ylab("Derived count") +
  #scale_y_continuous(breaks = seq(0, 2.5, by = 0.5)) +
  scale_x_discrete(breaks = levels(average_pool_counts_combined_copies_absolute$generation),limits = c(levels(average_pool_counts_combined_copies_absolute$generation)[1],"skip",levels(average_pool_counts_combined_copies_absolute$generation)[c(2:4)],c(rep("skip",3)),levels(average_pool_counts_combined_copies_absolute$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  #ylim(0,2.5) +
  #guides(colour="none") +
  labs(colour = "AF", shape = "Population") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_text(size=12),
        axis.title.y=element_text(size=12),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_text(colour="black"),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_text()
  )
Pb_lines_relativised_pool_counts_copies_ggplot
ggsave(paste0("Pb_lines_pool_counts_copies_absolute_",type,".low_high_AF.pdf"), width=25, height=12, units="cm", device="pdf", path=wd_path)

```

####Relativised counts:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))

pool_counts_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.low_af_sites.txt")) %>% filter(generation!="gen5")
pool_counts_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.high_af_sites.txt")) %>% filter(generation!="gen5")


####First, process the low AF dataset####
pool_counts_low <- left_join(pool_counts_low,codes_dictionary,by=c("sample"="old"))
pool_counts_low$population = factor(pool_counts_low$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts_low$generation <- as.numeric(gsub("gen","",pool_counts_low$generation)) + 83
pool_counts_low <- pool_counts_low %>% arrange(generation)
pool_counts_low$generation = factor(pool_counts_low$generation)
pool_counts_low <- pool_counts_low %>% arrange(population,generation)

pool_counts_low_copies_4FR <- pool_counts_low %>% mutate(fourfold=fourfold_D/fourfold_D,missense=missense_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_low_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_low_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_low_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_low_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_low_copies_4FR <- mutate(pool_counts_low_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_low_copies_4FR$group = factor(relativised_pool_counts_low_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_low_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"AF"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_low_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_low_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_low_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_low_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_low_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_low_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,"low",r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","AF","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_low_copies_4FR <- rbind(average_relativised_pool_counts_low_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_low_copies_4FR$population = factor(average_relativised_pool_counts_low_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_low_copies_4FR$ratio = factor(average_relativised_pool_counts_low_copies_4FR$ratio,levels=c("fourfold","missense","tolerated","deleterious","LoF"))
average_relativised_pool_counts_low_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_low_copies_4FR$generation))
average_relativised_pool_counts_low_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_low_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_low_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_low_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_low_copies_4FR


####Next, process the high AF dataset####
pool_counts_high <- left_join(pool_counts_high,codes_dictionary,by=c("sample"="old"))
pool_counts_high$population = factor(pool_counts_high$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts_high$generation <- as.numeric(gsub("gen","",pool_counts_high$generation)) + 83
pool_counts_high <- pool_counts_high %>% arrange(generation)
pool_counts_high$generation = factor(pool_counts_high$generation)
pool_counts_high <- pool_counts_high %>% arrange(population,generation)

pool_counts_high_copies_4FR <- pool_counts_high %>% mutate(fourfold=fourfold_D/fourfold_D,missense=missense_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_high_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_high_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_high_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_high_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_high_copies_4FR <- mutate(pool_counts_high_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_high_copies_4FR$group = factor(relativised_pool_counts_high_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_high_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"AF"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_high_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_high_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_high_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_high_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_high_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_high_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,"high",r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","AF","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_high_copies_4FR <- rbind(average_relativised_pool_counts_high_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_high_copies_4FR$population = factor(average_relativised_pool_counts_high_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_high_copies_4FR$ratio = factor(average_relativised_pool_counts_high_copies_4FR$ratio,levels=c("fourfold","missense","tolerated","deleterious","LoF"))
average_relativised_pool_counts_high_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_high_copies_4FR$generation))
average_relativised_pool_counts_high_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_high_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_high_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_high_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_high_copies_4FR


####Then combine both datasets####
average_relativised_pool_counts_combined_copies_4FR <- rbind(average_relativised_pool_counts_low_copies_4FR,average_relativised_pool_counts_high_copies_4FR)
average_relativised_pool_counts_combined_copies_4FR$AF = factor(average_relativised_pool_counts_combined_copies_4FR$AF,levels=c("low","high"))


####Then plot the data####
#Combined version:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_combined_copies_4FR,ratio!="fourfold", generation!=5), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +  
  #geom_line(aes(colour=recombination, group=interaction(recombination, population)),alpha=0.5,size=0.5) +
  geom_point(aes(colour=AF,shape=population),size=2,position=position_dodge(0.8)) +
  geom_errorbar(aes(ymin=avg_Pb_relative_value-2*se_Pb_relative_value, ymax=avg_Pb_relative_value+2*se_Pb_relative_value,colour=AF,group=interaction(population,AF)), position=position_dodge(0.8),size=0.5,width=0.5) +
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2.5, by = 0.5)) +
  scale_x_discrete(breaks = levels(average_relativised_pool_counts_combined_copies_4FR$generation),limits = c(levels(average_relativised_pool_counts_combined_copies_4FR$generation)[1],"skip",levels(average_relativised_pool_counts_combined_copies_4FR$generation)[c(2:4)],c(rep("skip",3)),levels(average_relativised_pool_counts_combined_copies_4FR$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0,2.5) +
  #guides(colour="none") +
  labs(colour = "AF", shape = "Population") +
  theme_bw() +
  
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_text(size=12),
        axis.title.y=element_text(size=12),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_text(colour="black"),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_text()
  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_4FR_",type,".low_high_AF.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

##Explore validated and unvalidated SNPs:
###Obtain share of validated sites:
```{bash}

#Check how many SNPs in our VCF can be found in the validated SNP database for the Drosophila melanogaster species. This VCF was downloaded by Humberto here: /share/rdata/snp_database/vcf_release_6_plus_ISO1_MT/7227_GCA_000001215.4_current_ids.vcf.gz

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/
module load gcc/7.2.0
module add gcc/7.2.0

VCF="crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.vcf"

#All CDS sites:
TOTAL_SNPS=$(grep -v "^#" $VCF | wc -l)
MATCH_SNPS=$(zcat /share/rdata/snp_database/vcf_release_6_plus_ISO1_MT/7227_GCA_000001215.4_current_ids.vcf.gz | bedtools intersect -a $VCF -b stdin | wc -l)
MATCH_PROP=$(echo "scale=3; $MATCH_SNPS/$TOTAL_SNPS" | bc)
echo $MATCH_PROP% #89.2%

#Missense and LoF sites:
TOTAL_SNPS=$(grep -v "^#" $VCF | grep -E "CUSTOM=tolerated;|CUSTOM=deleterious;|CUSTOM=LoF;" | wc -l)
MATCH_SNPS=$(zcat /share/rdata/snp_database/vcf_release_6_plus_ISO1_MT/7227_GCA_000001215.4_current_ids.vcf.gz | bedtools intersect -a <(grep -E "#|CUSTOM=tolerated;|CUSTOM=deleterious;|CUSTOM=LoF;" $VCF) -b stdin | wc -l)
MATCH_PROP=$(echo "scale=3; $MATCH_SNPS/$TOTAL_SNPS" | bc)
echo $MATCH_PROP% #79.9%

```

###Examine AF of non-validated mutations:
####Extract AF:
```{bash}

#Check how many SNPs in our VCF can be found in the validated SNP database for the Drosophila melanogaster species. This VCF was downloaded by Humberto here: /share/rdata/snp_database/vcf_release_6_plus_ISO1_MT/7227_GCA_000001215.4_current_ids.vcf.gz

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/
module load gcc/7.2.0
module add gcc/7.2.0

VCF="crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.vcf"

#Generate list of allele frequency values:
zcat /share/rdata/snp_database/vcf_release_6_plus_ISO1_MT/7227_GCA_000001215.4_current_ids.vcf.gz | bedtools subtract -a $VCF -b stdin | awk -F ";AF=|;EMstats" '{print $2}' > ${VCF/.vcf/non_validated_snps.af} #25085 of which 21254 (84.7%) are <0.1, 18177 (72.5%) are <0.05, and 9253 (36.9%) are <0.01.

#Obtain bed file, to be used later:
zcat /share/rdata/snp_database/vcf_release_6_plus_ISO1_MT/7227_GCA_000001215.4_current_ids.vcf.gz | bedtools subtract -a $VCF -b stdin | awk -F "\t" '{printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' > ${VCF/.vcf/.non_validated_snps.bed}

```

####Plot AF:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")

af_file <- read_tsv(paste0(wd_path,"crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_completenon_validated_snps.af"), col_names = c("AF"))

####Then plot the data####
#Combined version:
af_ggplot <- ggplot(af_file, aes(x=AF)) +
  geom_density() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.1)) +
  geom_vline(aes(xintercept=median(AF), color="median"), linetype="dashed", size=0.5) +
  geom_vline(aes(xintercept=mean(AF), color="mean"), linetype="dashed", size=0.5) +
  scale_color_manual(name = "statistics", values = c(median = "blue", mean = "red")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        #axis.text.x=element_text(angle=45, hjust=1, size=24,colour="black"),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        legend.key.size=unit(0.5,"cm"),
        #legend.spacing.y = unit(1,"cm"),
        legend.position=c(0.865,0.83),
        legend.title=element_text()
  )
af_ggplot
ggsave(paste0("non-validated_snps_AF.pdf"), width=15, height=10, units="cm", device="pdf", path=wd_path)

```

###Check derived counts after removing unvalidated sites.
####Split the VCFs at the pool level:
```{R, engine='bash'}

module load gcc/7.2.0 
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/

POOLS=$(ls *gen0-140_pool.txt)
for p in ${POOLS[@]}
  do
  echo "${p}"
  bedtools subtract -a ${p} -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.non_validated_snps.bed > ${p/.txt/.validated_subset.txt}
  grep -v "^X" ${p/.txt/.validated_subset.txt} > ${p/.txt/.validated_subset_autosomes.txt}
  done

```

####All sites:
#####Retrieve derived counts per category:
```{R, engine='bash'}

REGION="autosomes" #all #autosomes #Xchr
BED="/share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.non_validated_snps.bed"

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
rm counts_pool_gen0-140_${REGION}_summary.validated_subset.txt
echo -e "sample\tgeneration\tnon-fourfold_V\tnon-fourfold_D\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > counts_pool_gen0-140_${REGION}_summary.validated_subset.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-140_pool.txt' -print`))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  grep -E "#|CUSTOM=non-fourfold;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.nfo_validated.rm}
  NONFOURFOLD_V=$(wc -l <  ${p/.txt/.nfo_validated.rm})
  NONFOURFOLD_D=$(awk '{print $11}' ${p/.txt/.nfo_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=fourfold;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.ffo_validated.rm}
  FOURFOLD_V=$(wc -l <  ${p/.txt/.ffo_validated.rm})
  FOURFOLD_D=$(awk '{print $11}' ${p/.txt/.ffo_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=tolerated;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.tol_validated.rm}
  MISTOL_V=$(wc -l < ${p/.txt/.tol_validated.rm})
  MISTOL_D=$(awk '{print $11}' ${p/.txt/.tol_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=deleterious;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.del_validated.rm}
  MISDEL_V=$(wc -l < ${p/.txt/.del_validated.rm})
  MISDEL_D=$(awk '{print $11}' ${p/.txt/.del_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=LoF;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.LoF_validated.rm}
  LOF_V=$(wc -l < ${p/.txt/.LoF_validated.rm})
  if [ $LOF_V == 0 ]
    then LOF_D=0
    else LOF_D=$(awk '{print $11}' ${p/.txt/.LoF_validated.rm} | paste -sd+ | bc)
  fi
  echo -e "$SAMPLE\t$GEN\t$NONFOURFOLD_V\t$NONFOURFOLD_D\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> counts_pool_gen0-140_${REGION}_summary.validated_subset.txt
  done
  rm *.rm

#From the local environment:
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

#####Plot relativised counts (not the manuscript version):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.validated_snps.txt")) %>% filter(generation!="gen5")

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR
#write_tsv(average_relativised_pool_counts_copies_4FR,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_4FR_",type,".txt"))


#Plot:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,ratio!="fourfold"), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(aes(colour=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(average_relativised_pool_counts_copies_4FR$generation),limits = c(levels(average_relativised_pool_counts_copies_4FR$generation)[1],"skip",levels(average_relativised_pool_counts_copies_4FR$generation)[c(2:4)],c(rep("skip",3)),levels(average_relativised_pool_counts_copies_4FR$generation)[5])) +
  #scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Validated SNPs only") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_text(size=12),
        axis.title.y=element_text(size=12),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_text(colour="black"),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()

  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_4FR_",type,".validated_snps.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)


```

####Recombination:
#####Retrieve derived counts per category:
```{R, engine='bash'}

RECOMBINATION="low" #low #high
REGION="autosomes" #all #autosomes #Xchr
BED="/share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.non_validated_snps.bed"

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/
rm counts_pool_gen0-140_${REGION}_summary.validated_snps.${RECOMBINATION}_recombination.txt
echo -e "sample\tgeneration\tnon-fourfold_V\tnon-fourfold_D\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > counts_pool_gen0-140_${REGION}_summary.validated_snps.${RECOMBINATION}_recombination.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-140_pool.'${RECOMBINATION}'_recombination.txt' -print`))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  grep -E "#|CUSTOM=non-fourfold;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.nfo_validated.rm}
  NONFOURFOLD_V=$(wc -l <  ${p/.txt/.nfo_validated.rm})
  NONFOURFOLD_D=$(awk '{print $11}' ${p/.txt/.nfo_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=fourfold;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.ffo_validated.rm}
  FOURFOLD_V=$(wc -l <  ${p/.txt/.ffo_validated.rm})
  FOURFOLD_D=$(awk '{print $11}' ${p/.txt/.ffo_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=tolerated;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.tol_validated.rm}
  MISTOL_V=$(wc -l < ${p/.txt/.tol_validated.rm})
  MISTOL_D=$(awk '{print $11}' ${p/.txt/.tol_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=deleterious;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.del_validated.rm}
  MISDEL_V=$(wc -l < ${p/.txt/.del_validated.rm})
  MISDEL_D=$(awk '{print $11}' ${p/.txt/.del_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=LoF;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.LoF_validated.rm}
  LOF_V=$(wc -l < ${p/.txt/.LoF_validated.rm})
  if [ $LOF_V == 0 ]
    then LOF_D=0
    else LOF_D=$(awk '{print $11}' ${p/.txt/.LoF_validated.rm} | paste -sd+ | bc)
  fi
  echo -e "$SAMPLE\t$GEN\t$NONFOURFOLD_V\t$NONFOURFOLD_D\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> counts_pool_gen0-140_${REGION}_summary.validated_snps.${RECOMBINATION}_recombination.txt
  done
rm *.rm

#From the local environment:
RECOMBINATION="high" #low #high
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_snps.${RECOMBINATION}_recombination.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

#####Plot recombination (not the manuscript version):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))

pool_counts_low <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.validated_snps.low_recombination.txt"))
pool_counts_high <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_summary.validated_snps.high_recombination.txt"))


####First, process the low recombination dataset####
pool_counts_low <- left_join(pool_counts_low,codes_dictionary,by=c("sample"="old"))
pool_counts_low$population = factor(pool_counts_low$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts_low$generation <- as.numeric(gsub("gen","",pool_counts_low$generation))
pool_counts_low <- pool_counts_low %>% arrange(generation)
pool_counts_low$generation = factor(pool_counts_low$generation)
pool_counts_low <- pool_counts_low %>% arrange(population,generation)

pool_counts_low_copies_4FR <- pool_counts_low %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_low_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_low_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_low_copies_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_low_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_low_copies_4FR <- mutate(pool_counts_low_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_low_copies_4FR$group = factor(relativised_pool_counts_low_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_low_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"recombination"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_low_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_low_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_low_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_low_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_low_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_low_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,"low",r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","recombination","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_low_copies_4FR <- rbind(average_relativised_pool_counts_low_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_low_copies_4FR$population = factor(average_relativised_pool_counts_low_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_low_copies_4FR$ratio = factor(average_relativised_pool_counts_low_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_low_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_low_copies_4FR$generation))
average_relativised_pool_counts_low_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_low_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_low_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_low_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_low_copies_4FR


####Next, process the high recombination dataset####
pool_counts_high <- left_join(pool_counts_high,codes_dictionary,by=c("sample"="old"))
pool_counts_high$population = factor(pool_counts_high$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts_high$generation <- as.numeric(gsub("gen","",pool_counts_high$generation))
pool_counts_high <- pool_counts_high %>% arrange(generation)
pool_counts_high$generation = factor(pool_counts_high$generation)
pool_counts_high <- pool_counts_high %>% arrange(population,generation)

pool_counts_high_copies_4FR <- pool_counts_high %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_high_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_high_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_high_copies_4FR,r==ratio & population=="Pb" & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_high_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_high_copies_4FR <- mutate(pool_counts_high_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_high_copies_4FR$group = factor(relativised_pool_counts_high_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_high_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"recombination"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_high_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_high_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_high_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_high_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_high_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_high_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,"high",r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","recombination","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_high_copies_4FR <- rbind(average_relativised_pool_counts_high_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_high_copies_4FR$population = factor(average_relativised_pool_counts_high_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_high_copies_4FR$ratio = factor(average_relativised_pool_counts_high_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_high_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_high_copies_4FR$generation))
average_relativised_pool_counts_high_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_high_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_high_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_high_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_high_copies_4FR


####Then combine both datasets####
average_relativised_pool_counts_combined_copies_4FR <- rbind(average_relativised_pool_counts_low_copies_4FR,average_relativised_pool_counts_high_copies_4FR)
average_relativised_pool_counts_combined_copies_4FR$recombination = factor(average_relativised_pool_counts_combined_copies_4FR$recombination,levels=c("low","high"))


####Then plot the data####
#Combined version:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot_recvert <- ggplot(data=filter(average_relativised_pool_counts_combined_copies_4FR,ratio!="fourfold", generation!=5), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +  
  #geom_line(aes(colour=recombination, group=interaction(recombination, population)),alpha=0.5,size=0.5) +
  geom_point(aes(colour=recombination,shape=population),size=2,position=position_dodge(0.4)) +
  geom_errorbar(aes(ymin=avg_Pb_relative_value-2*se_Pb_relative_value, ymax=avg_Pb_relative_value+2*se_Pb_relative_value, colour=recombination,group=interaction(population,recombination)), position=position_dodge(0.4),size=0.5,width=0.5) +
  ylab("Derived count\n relative to Pb-000 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.5, 1.0, by = 0.1)) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.4,1.1) +
  ggtitle("Validated SNPs only") +
  #guides(colour="none") +
  labs(colour = "Recombination", shape = "Population") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_text()
  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot_recvert
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_4FR_",type,".validated_snps.all_recombination.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

####Rarefied:
#####Retrieve derived counts per category:
```{R, engine='bash'}

REGION="all" #all #autosomes #Xchr
DEPTH=50
BED="/share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.non_validated_snps.bed"

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/depth$DEPTH/
rm rarefied_depth_${DEPTH}_counts_pool_gen0-140_${REGION}_summary.validated_snps.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > rarefied_depth_${DEPTH}_counts_pool_gen0-140_${REGION}_summary.validated_snps.txt
POOL_LIST=($(ls *gen0-140_pool.all.depth_${DEPTH}_valid_mod.average_complete.txt))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  if [ $REGION == "all" ]
    then
    p=${pool}
    else
    p=${pool/.txt/_${REGION}.txt}
  fi
  #grep -E "#|CUSTOM=non-fourfold;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.nfo_validated.rm}
  #NONFOURFOLD_V=$(wc -l <  ${p/.txt/.nfo_validated.rm})
  #NONFOURFOLD_D=$(awk '{print $11}' ${p/.txt/.nfo_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=fourfold;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.ffo_validated.rm}
  FOURFOLD_V=$(awk '$11 > 0' ${p/.txt/.ffo_validated.rm} | wc -l)
  FOURFOLD_D=$(awk '{print $11}' ${p/.txt/.ffo_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=tolerated;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.tol_validated.rm}
  MISTOL_V=$(awk '$11 > 0' ${p/.txt/.tol_validated.rm} | wc -l)
  MISTOL_D=$(awk '{print $11}' ${p/.txt/.tol_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=deleterious;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.del_validated.rm}
  MISDEL_V=$(awk '$11 > 0' ${p/.txt/.del_validated.rm} | wc -l)
  MISDEL_D=$(awk '{print $11}' ${p/.txt/.del_validated.rm} | paste -sd+ | bc)
  grep -E "#|CUSTOM=LoF;" $p | bedtools subtract -a stdin -b $BED > ${p/.txt/.LoF_validated.rm}
  LOF_V=$(awk '$11 > 0' ${p/.txt/.LoF_validated.rm} | wc -l)
  if [ $LOF_V == 0 ]
    then LOF_D=0
    else LOF_D=$(awk '{print $11}' ${p/.txt/.LoF_validated.rm} | paste -sd+ | bc)
  fi
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> rarefied_depth_${DEPTH}_counts_pool_gen0-140_${REGION}_summary.validated_snps.txt
  done
  rm *.rm

#From the local environment:
REGION="all" #all #autosomes #Xchr
DEPTH=50
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/rarefied_counts/depth${DEPTH}/rarefied_depth_${DEPTH}_counts_pool_gen0-140_${REGION}_summary.validated_snps.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/rarefied/depth${DEPTH}/

#There are generally less LoF sites and counts in the new dataset (even though there are more sites in general and in the other categories). The reason seems to be that for the old dataset I used the whole annovar dataset instead of the nr one, and that one seems to assign more LoF than the nr one, which more than make up for the fewer overall sites.

```

#####Plot relativised counts (not the manuscript version):
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


type <- "autosomes" #all #autosomes #Xchr
depth <- 50

wd_path <- paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/rarefied/depth",depth,"/")
pool_counts <- read_tsv(paste0(wd_path,"rarefied_depth_50_counts_pool_gen0-140_",type,"_summary.validated_snps.txt")) %>% filter(generation!="gen5")

codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))
pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","L01","L16","L27","L29","L31","L33","L34","L36","L38","L39","L42","L45","L48","L51","L52","L54","L59","L61","L63"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
}
print(r_average_vector)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_pool_counts_copies_4FR <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"avg_Pb_relative_value"=character(0),"se_Pb_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_pool_counts_copies_4FR$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(relativised_pool_counts_copies_4FR,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
      print(r)
      pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g & group==pop) %>% select(Pb_relative_value) %>% unlist(.,use.names=F) %>% se()
      #print(paste0(pop," feature ",r," std error is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","avg_Pb_relative_value","se_Pb_relative_value")
      average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
    }
  }
}
average_relativised_pool_counts_copies_4FR$population = factor(average_relativised_pool_counts_copies_4FR$population,levels=c("Pb","lines"))
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_Pb_relative_value)
average_relativised_pool_counts_copies_4FR$se_Pb_relative_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_Pb_relative_value)
average_relativised_pool_counts_copies_4FR
#write_tsv(average_relativised_pool_counts_copies_4FR,paste0(wd_path,"/pop_average_relativised_pool_counts_copies_4FR_",type,".txt"))


#Plot:
Pb_lines_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,ratio!="fourfold"), aes(generation,avg_Pb_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(aes(colour=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(average_relativised_pool_counts_copies_4FR$generation),limits = c(levels(average_relativised_pool_counts_copies_4FR$generation)[1],"skip",levels(average_relativised_pool_counts_copies_4FR$generation)[c(2:4)],c(rep("skip",3)),levels(average_relativised_pool_counts_copies_4FR$generation)[5])) +
  #scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle(paste0("Rarefied data (cov. ",depth,"), validated SNPs only")) +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_text(size=12),
        axis.title.y=element_text(size=12),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_text(colour="black"),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()

  )
Pb_lines_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("rarefied_depth_",depth,"_Pb_lines_relativised_pool_counts_copies_4FR_",type,".validated_snps.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```
###Bootstrap:
####Obtain statistics for each block in parallel runs.
#####Derived allele counts.
```{r, eval=FALSE, engine='bash'}

#Run it as follows:
PARALLEL=20
REGION="autosomes" #autosomes or Xchr
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
qsub -cwd -l h=compute-0-9 -t 1-$PARALLEL /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/derived_allele_counts_validated_subset.sh $REGION

***************************** #save code from here on as /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/derived_allele_counts_validated_subset.sh

REGION=$1 #autosomes or Xchr
CHUNK=$(printf "%02d" ${SGE_TASK_ID}) #chunk of parallelisation

export PATH=$PATH:/share/apps/bedtools2/bin:/share/apps/est-sfs-release-2.03/:/share/apps/BAMTOOLS/bin:/share/apps/bedtools2/bin
module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/

echo "generating parallel derived allele counts for chunk" $CHUNK
echo "retrieving blocks in chunk" $CHUNK
BLOCKLIST=$(cut -d'.' -f1 derived_allele_counts/$REGION/block_list/block_list_${CHUNK}.txt)
echo "retrieving pools"
POOL_LIST=($(ls -v `find "/share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts" -name '*_gen0-140_pool.validated_subset_'${REGION}'.txt' -print`))
for BLOCK in ${BLOCKLIST[@]}
  do 
  echo "working with block" ${BLOCK}
  BED=$(readlink -f block_beds_${REGION}/${BLOCK}.bed)
  rm derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.${BLOCK}.txt
  
  echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.${BLOCK}.txt
  for pool in "${POOL_LIST[@]}"
    do
    echo "${pool}"
    SAMPLE=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f1)
    GEN=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f2)

    echo "subsetting VCF for block" $BLOCK "and pool" $pool
    bedtools intersect -a ${pool} -b ${BED} -header > ${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    p=${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    
    FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
    if [ "$FOURFOLD_V" -eq 0 ]
      then 
      FOURFOLD_A=0
      FOURFOLD_D=0
      FOURFOLD_COV=0
    else
      FOURFOLD_A=$(grep "CUSTOM=fourfold;" $p | awk '{print $10}' | paste -sd+ | bc)
      FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
      FOURFOLD_COV=$((FOURFOLD_A+FOURFOLD_D))
    fi
    
    MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
    if [ "$MISTOL_V" -eq 0 ]
      then 
      MISTOL_A=0
      MISTOL_D=0
      MISTOL_COV=0
    else
      MISTOL_A=$(grep "CUSTOM=tolerated;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
      MISTOL_COV=$((MISTOL_A+MISTOL_D))
    fi

    MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
    if [ "$MISDEL_V" -eq 0 ]
      then 
      MISDEL_A=0
      MISDEL_D=0
      MISDEL_COV=0
    else
      MISDEL_A=$(grep "CUSTOM=deleterious;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
      MISDEL_COV=$((MISDEL_A+MISDEL_D))
    fi

    LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
    if [ "$LOF_V" -eq 0 ]
      then 
      LOF_A=0
      LOF_D=0
      LOF_COV=0
    else
      LOF_A=$(grep "CUSTOM=LoF;" $p | awk '{print $10}' | paste -sd+ | bc)
      LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
      LOF_COV=$((LOF_A+LOF_D))
    fi
    echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.${BLOCK}.txt
    rm ${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    done
  done

```

####Perform the bootstrap, obtain the bootstrap error, and relativise it.
#####Absolute derived counts:
######Empirical data average and error:
```{bash}

REGION="autosomes" #autosomes or Xchr
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/

#First, generate some headers and info files (this should only be performed once):
head -n1 <$(ls counts_pool_gen0-140_${REGION}_summary.validated_subset.bl*.txt | head -n1) > pool_headers.txt #Retrieve headers for files with pools
printf 'Pb\n%.0s' {1..6} > pop_codes.txt #then generate the population column content
printf 'lines\n%.0s' {1..2} >> pop_codes.txt
tail -n+2 <$(ls counts_pool_gen0-140_${REGION}_summary.validated_subset.bl*.txt | head -n1) | cut -f-2 > pool_gen.txt #Retrieve first 2 columns with pool data

#Next, obtain the population average and sampling error (standard error) for the empirical data.
##Average:
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=5;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=5;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=5;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=5;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.empirmean.txt

tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.empirmean.txt | cut -f-2 > pop_gen.txt

##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=5;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=5;i<NF;i++) printf("%.3f\t",0); printf("%.3f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=5;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=5;i<NF;i++) printf("%.3f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.3f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.empirerror.txt

```

######Synthetic genomes counts:
```{bash}

REGION="autosomes" #autosomes #Xchr #whole-genome
N_BOOT=1000 #100 #1000
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/

#Next, generate several bootstrapped w-g counts by adding the counts of 1090 autosomal and 235 Xchr blocks pulled at random from the pool, and obtain the population averages:
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  #Autosomes:
  if [ $REGION == "autosomes" ]
    then
    cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/autosomes/block_counts/
    ##First, edit the filenames of the input blocks so that they match the current variables:
    echo "generating autosomal counts for bootstrapped genome number" $boot
    sed -e 's/^/counts_pool_gen0-140_autosomes_summary.validated_subset./' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/bootstrapped_genomes_coordinates/bootstrapped_genome_autosomes_${boot}.list > bootstrapped_genome_autosomes_${boot}.validated_subset.list
    ##Next, generate the counts for each bootstrapped genome:
    paste pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' $(cat bootstrapped_genome_autosomes_${boot}.validated_subset.list) | tail -n+2) > counts_pool_gen0-140_autosomes_summary.validated_subset.boot_${boot}.txt
    echo "calculating population averages for bootstrapped genome number" $boot
    cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.9f\t",sum[p"."i]/N[p]); printf("%.9f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_autosomes_summary.validated_subset.boot_${boot}.txt | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.9f\t",sum[p"."i]/N[p]); printf("%.9f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_autosomes_summary.validated_subset.boot_${boot}.txt) > counts_pool_gen0-140_autosomes_average.validated_subset.boot_${boot}.txt
    else
    print "ERROR: region $REGION files not prepared"
  fi
  done

#Next, obtain the population average of derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.validated_subset.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$9 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.validated_subset.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=2;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=2;i<=NF;i++) printf "%.9f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.validated_subset.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.validated_subset.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
touch kaka.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_average.validated_subset.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(head -n1 $BLOCK | cut -f2 | cut -d'.' -f1)
  echo $CURRENT >> kaka.txt
  TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=2;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=2;i<=NF;i++) printf "%.9f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.validated_subset.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.validated_subset.booterror.txt


#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.validated_subset.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.validated_subset.booterrorcorrected.txt


#Per population total error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error, which is 0 for the base population).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.9f\t",(sumsq[j","i])**0.5; printf "%.9f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.empirerror.txt))) > counts_pool_gen0-140_${REGION}_average.validated_subset.totalerror.txt

#Per population adequate or mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered, which means that booterrorcorrected is the total error), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_${REGION}_average.validated_subset.adequateerror.txt


#In order to relativise by the Pb-000 population average, divide both the population average and the total error by the Pb-000 empirical population averages:
##Empirical population averages divided by the empirical Pb-000 population average:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.empirmean.txt | cut -f3-) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.empirmean.txt | cut -f3-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1')) > counts_pool_gen0-140_${REGION}_average.validated_subset.empirmean_Pb-000_rel.txt
##Total error:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.empirmean.txt | cut -f3-) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.totalerror.txt | cut -f3-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1')) > counts_pool_gen0-140_${REGION}_average.validated_subset.totalerror_Pb-000_rel.txt
##Adequate error:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.empirmean.txt | cut -f3-) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.adequateerror.txt | cut -f3-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1')) > counts_pool_gen0-140_${REGION}_average.validated_subset.adequateerror_Pb-000_rel.txt

```


#####Relative derived counts:
######Empirical data average and error:
#######All sites:
```{bash}

REGION="autosomes" #autosomes or Xchr
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/

#First, generate some headers and info files (this should only be performed once):
head -n1 <$(ls counts_pool_gen0-140_${REGION}_summary.validated_subset.bl*.txt | head -n1) > pool_headers.txt #Retrieve headers for files with pools
printf 'Pb\n%.0s' {1..6} > pop_codes.txt #then generate the population column content
printf 'lines\n%.0s' {1..2} >> pop_codes.txt
tail -n+2 <$(ls counts_pool_gen0-140_${REGION}_summary.validated_subset.bl*.txt | head -n1) | cut -f-2 > pool_gen.txt #Retrieve first 2 columns with pool data

#First, obtain the relativised version of the empirical counts.
  #Only Pb-000 rel:
  paste pool_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt | cut -f5-) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt | cut -f5-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.8f", $i/m[i])}1') > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_rel.txt
  #Only 4fold rel:
  paste pool_gen.txt <(paste <(paste <(cut -f5 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt | tail -n+2) <(cut -f$(seq -s, 5 2 11) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt | tail -n+2) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) <(paste <(cut -f6 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt | tail -n+2) <(cut -f$(seq -s, 6 2 12) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt | tail -n+2) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}') > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.4fold_rel.txt
  #Both Pb-000 rel and 4fold rel:
  cat pool_headers.txt <(paste pool_gen.txt <(paste <(paste <(cut -f3 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_rel.txt) <(cut -f$(seq -s, 3 2 9) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_rel.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_rel.txt) <(cut -f$(seq -s, 4 2 10) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_rel.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}')) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_4fold_rel.txt

#Next, obtain the population average and sampling error (standard error) for the empirical relativised data.
  #Both Pb-000 rel and 4fold rel:
  ##Average:
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_4fold_rel.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_4fold_rel.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.empirmean.txt
  ##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",0); printf("%.8f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_4fold_rel.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.8f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_4fold_rel.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.empirerror.txt
  
  #Only 4fold rel:
  ##Average:
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(cat /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.4fold_rel.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(cat /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.4fold_rel.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.4fold_rel.empirmean.txt
  ##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",0); printf("%.8f\n",0);}}' <(cat /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.4fold_rel.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.8f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(cat /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.4fold_rel.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.4fold_rel.empirerror.txt

```

#######All sites, 4fold without new mutation:
```{bash}

#Take the 4fold synonymous values from the pipeline without new mutation (see e-mail from Aurora on 2023/12/10), and the rest of the categories from this pipeline (with mutation).

REGION="autosomes" #autosomes or Xchr
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/

#First, obtain the relativised version of the empirical counts.
  #Only Pb-000 rel (combine 4fold without new mutation and other categories with new mutation):
  paste pool_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/wout_new_mut_counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt | cut -f3-) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/wout_new_mut_counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt | cut -f3-) | cut -f-2 | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.8f", $i/m[i])}1') <(cat <(grep 'gen0' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt | cut -f5-) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt | cut -f5-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.8f", $i/m[i])}1' | cut -f3-) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_rel_syn_wout.txt
  #Both Pb-000 rel and 4fold rel (the 4fold columns come from the files without new mutation; the rest come from the files with new mutation):
  cat pool_headers.txt <(paste pool_gen.txt <(paste <(paste <(cut -f3 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_rel_syn_wout.txt) <(cut -f$(seq -s, 3 2 9) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_rel_syn_wout.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_rel_syn_wout.txt) <(cut -f$(seq -s, 4 2 10) /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_rel_syn_wout.txt) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.8f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}')) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_4fold_rel_syn_wout.txt

#Next, obtain the population average and sampling error (standard error) for the empirical relativised data.
  #Both Pb-000 rel and 4fold rel:
  ##Average:
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_4fold_rel_syn_wout.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",sum[p"."i]/N[p]); printf("%.8f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_4fold_rel_syn_wout.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.empirmean.txt
  ##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
  cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",0); printf("%.8f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_4fold_rel_syn_wout.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.8f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.8f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.Pb-000_4fold_rel_syn_wout.txt)))) > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.empirerror.txt

```

######Synthetic genomes counts:
#######All sites:
```{bash}

#Run the absolute derived counts chunk before running this one, as this one needs files generated in that section.

REGION="autosomes" #autosomes #Xchr #whole-genome
N_BOOT=1000 #100 #1000
if [ $REGION == "whole-genome" ]
  then
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
  else
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
fi

#Obtain the Pb-000 and 4fold relative version of all bootstrapped counts.
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  FILE=counts_pool_gen0-140_${REGION}_average.validated_subset.boot_${boot}.txt
  #Pb-000 rel:
  paste pop_gen.txt <(cat <(grep 'gen0' $FILE | cut -f2-) <(cut -f2- $FILE) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1') > ${FILE/.boot/.Pb-000_rel.boot}
  #Pb-000 and 4fold rel:
  paste pop_gen.txt <(paste <(paste <(cut -f3 ${FILE/.boot/.Pb-000_rel.boot}) <(cut -f$(seq -s, 3 2 9) ${FILE/.boot/.Pb-000_rel.boot}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 ${FILE/.boot/.Pb-000_rel.boot}) <(cut -f$(seq -s, 4 2 10) ${FILE/.boot/.Pb-000_rel.boot}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}') > ${FILE/.boot/.Pb-000_4fold_rel.boot} && rm ${FILE/.boot/.Pb-000_rel.boot}
  done

#Next, obtain the population average of relativised derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$12 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.9f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
rm kaka.Pb-000_4fold_rel.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(tail -n1 $BLOCK | cut -f10)
  echo $CURRENT >> kaka.Pb-000_4fold_rel.txt
  #TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.5f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.booterror.txt


#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.booterrorcorrected.txt


#Per population total error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error, which is 0 for the base population).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.8f\t",(sumsq[j","i])**0.5; printf "%.8f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.empirerror.txt))) > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.totalerror.txt

#Per population adequate or mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered, which means that booterrorcorrected is the total error), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel.adequateerror.txt

```

#######All sites, 4fold without new mutation:
```{bash}

#Run the absolute derived counts chunk before running this one, as this one needs files generated in that section.

#Take the 4fold synonymous values from the pipeline without new mutation (see e-mail from Aurora on 2023/12/10), and the rest of the categories from this pipeline (with mutation).

REGION="autosomes" #autosomes #Xchr #whole-genome
N_BOOT=1000 #100 #1000
if [ $REGION == "whole-genome" ]
  then
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION
  else
  cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/bootstrap/derived_allele_counts/$REGION/block_counts/
fi

#Obtain the Pb-000 and 4fold relative version of all bootstrapped counts.
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  FILE=counts_pool_gen0-140_${REGION}_average.validated_subset.boot_${boot}.txt
  #Pb-000 rel (combine 4fold without new mutation and other categories with new mutation):
  paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/$REGION/block_counts/$FILE | cut -f2-) <(cut -f2- /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/$REGION/block_counts/$FILE) | cut -f-2 | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1') <(cat <(grep 'gen0' $FILE | cut -f2-) <(cut -f2- $FILE) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.9f", $i/m[i])}1' | cut -f3-) > ${FILE/.boot/.Pb-000_rel_syn_wout.boot}
  #Pb-000 and 4fold rel (the 4fold columns come from the files without new mutation; the rest come from the files with new mutation):
  paste pop_gen.txt <(paste <(paste <(cut -f3 ${FILE/.boot/.Pb-000_rel_syn_wout.boot}) <(cut -f$(seq -s, 3 2 9) ${FILE/.boot/.Pb-000_rel_syn_wout.boot}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) <(paste <(cut -f4 ${FILE/.boot/.Pb-000_rel_syn_wout.boot}) <(cut -f$(seq -s, 4 2 10) ${FILE/.boot/.Pb-000_rel_syn_wout.boot}) | awk 'BEGIN {OFS = "\t"} { for (i=2;i<=NF;i++) $i = sprintf ("%.9f", $i/$1)}1' | cut -f2-) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$5,$2,$6,$3,$7,$4,$8)}') > ${FILE/.boot/.Pb-000_4fold_rel_syn_wout.boot} && rm ${FILE/.boot/.Pb-000_rel_syn_wout.boot}
  done

#Next, obtain the population average of relativised derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$14 <= nboot {print $0}' > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.9f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.bootmean.txt

#Test average:
N_BOOT=1000
TOTAL=0
rm kaka.Pb-000_4fold_rel.txt
LIST=$(cat counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(tail -n1 $BLOCK | cut -f10)
  echo $CURRENT >> kaka.Pb-000_4fold_rel.txt
  #TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL #divide this by NBOOT


#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%.5f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.booterror.txt


#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.booterrorcorrected.txt


#Per population total error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error, which is 0 for the base population).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.8f\t",(sumsq[j","i])**0.5; printf "%.8f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.empirerror.txt))) > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.totalerror.txt

#Per population adequate or mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered, which means that booterrorcorrected is the total error), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_${REGION}_average.validated_subset.Pb-000_4fold_rel_syn_wout.adequateerror.txt

```

####Draw plots:
#####Double ratio:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.validated_subset.Pb-000_4fold_rel.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.validated_subset.Pb-000_4fold_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
#names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation)) + 83
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)
pool_errors <- pool_errors %>% setNames(gsub("_D","",names(.)))
pool_errors[c(1),c(4:6)] <- NA

# pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_4FR
pool_errors_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
combined_tidy_withnewmut <- left_join(pool_counts_tidy,pool_errors_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_withnewmut) <- c("population","generation","ratio","mean","error")

#Paper versions:
##Various colours:
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy_withnewmut,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot

##Two colours:
combined_tidy_withnewmut_bis <- combined_tidy_withnewmut
combined_tidy_withnewmut_bis$generation <- as.numeric(as.character(combined_tidy_withnewmut_bis$generation))
combined_tidy_withnewmut_bis$ratio <- factor(combined_tidy_withnewmut_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis <- ggplot(data=filter(combined_tidy_withnewmut_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis


##Two colours (manuscript version, only including new mutation):
combined_tidy_withnewmut_bis <- combined_tidy_withnewmut
combined_tidy_withnewmut_bis$generation <- as.numeric(as.character(combined_tidy_withnewmut_bis$generation))
combined_tidy_withnewmut_bis$ratio <- factor(combined_tidy_withnewmut_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis <- ggplot(data=filter(combined_tidy_withnewmut_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 and 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  ylim(0.6,1.2) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=8,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=11,colour="black"),
        axis.title=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(-1,-1,-1,-1),"cm"),
        #plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=9,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis
#ggsave("20231220_main_empirical.pdf", width=15, height=12, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/")


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.13,hjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=1))

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis,width=unit(6,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.45,vjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=1))

ggsave("20240802_empirical.validated_subset.pdf", width=11, height=8.5, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#ggsave("20240315_main_empirical.pdf", width=11, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#STOP

```

#####Double ratio (4fold without new mutation):
```{r}

#Take the 4fold synonymous values from the pipeline without new mutation (see e-mail from Aurora on 2023/12/10), and the rest of the categories from this pipeline (with mutation).

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.validated_subset.Pb-000_4fold_rel_syn_wout.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.validated_subset.Pb-000_4fold_rel_syn_wout.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
#names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation)) + 83
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)
pool_errors <- pool_errors %>% setNames(gsub("_D","",names(.)))
pool_errors[c(1),c(4:6)] <- NA

# pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_4FR
pool_errors_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
combined_tidy_withnewmut <- left_join(pool_counts_tidy,pool_errors_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_withnewmut) <- c("population","generation","ratio","mean","error")

#Paper versions:
##Various colours:
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_syn_wout <- ggplot(data=filter(combined_tidy_withnewmut,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_syn_wout

##Two colours:
combined_tidy_withnewmut_bis <- combined_tidy_withnewmut
combined_tidy_withnewmut_bis$generation <- as.numeric(as.character(combined_tidy_withnewmut_bis$generation))
combined_tidy_withnewmut_bis$ratio <- factor(combined_tidy_withnewmut_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout <- ggplot(data=filter(combined_tidy_withnewmut_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout


##Two colours (manuscript version, only including new mutation):
combined_tidy_withnewmut_bis <- combined_tidy_withnewmut
combined_tidy_withnewmut_bis$generation <- as.numeric(as.character(combined_tidy_withnewmut_bis$generation))
combined_tidy_withnewmut_bis$ratio <- factor(combined_tidy_withnewmut_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout <- ggplot(data=filter(combined_tidy_withnewmut_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 and 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  ylim(0.6,1.2) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=8,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=11,colour="black"),
        axis.title=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(-1,-1,-1,-1),"cm"),
        #plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=9,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout
#ggsave("20231220_main_empirical.syn_wout.pdf", width=15, height=12, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/")


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.13,hjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=1))

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout,width=unit(6,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.45,vjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=1))

ggsave("20240705_empirical.validated_subset.syn_wout.pdf", width=11, height=8.5, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#ggsave("20240315_main_empirical.syn_wout.pdf", width=11, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#STOP

```

#####!!!!Additional mutation categories: without errors, take the averages from /share/rdata/ramon.pouso/POOLS/all_gens_0_140/wout_new_mut_counts/counts_pool_gen0-140_autosomes_summary.txt (without new mutation for 4fold) and from /share/rdata/ramon.pouso/POOLS/all_gens_0_140/counts/counts_pool_gen0-140_autosomes_summary.txt (with new mutation, rest of categories), relativise and draw them.
```{r}

#Take the 4fold synonymous values from the pipeline without new mutation (see e-mail from Aurora on 2023/12/10), and the rest of the categories from this pipeline (with mutation).

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/all_sites/gen0-140/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))

pool_counts_wout_new_mut <- read_tsv("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/sites_in_Pb000/gen0-140_custom_complete/counts_pool_gen0-140_autosomes_summary.txt") %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")



pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.validated_subset.Pb-000_4fold_rel_syn_wout.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.validated_subset.Pb-000_4fold_rel_syn_wout.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
#names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation)) + 83
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)
pool_errors <- pool_errors %>% setNames(gsub("_D","",names(.)))
pool_errors[c(1),c(4:6)] <- NA

# pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_4FR
pool_errors_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
combined_tidy_withnewmut <- left_join(pool_counts_tidy,pool_errors_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_withnewmut) <- c("population","generation","ratio","mean","error")

#Paper versions:
##Various colours:
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_syn_wout <- ggplot(data=filter(combined_tidy_withnewmut,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_syn_wout

##Two colours:
combined_tidy_withnewmut_bis <- combined_tidy_withnewmut
combined_tidy_withnewmut_bis$generation <- as.numeric(as.character(combined_tidy_withnewmut_bis$generation))
combined_tidy_withnewmut_bis$ratio <- factor(combined_tidy_withnewmut_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout <- ggplot(data=filter(combined_tidy_withnewmut_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  ylim(0.6,1.2) +
  ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout


##Two colours (manuscript version, only including new mutation):
combined_tidy_withnewmut_bis <- combined_tidy_withnewmut
combined_tidy_withnewmut_bis$generation <- as.numeric(as.character(combined_tidy_withnewmut_bis$generation))
combined_tidy_withnewmut_bis$ratio <- factor(combined_tidy_withnewmut_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout <- ggplot(data=filter(combined_tidy_withnewmut_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 and 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy_withnewmut$generation),limits = c(levels(combined_tidy_withnewmut$generation)[1],"skip",levels(combined_tidy_withnewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_withnewmut$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  ylim(0.6,1.2) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=8,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=11,colour="black"),
        axis.title=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(-1,-1,-1,-1),"cm"),
        #plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=9,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout
#ggsave("20231220_main_empirical.syn_wout.pdf", width=15, height=12, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/")


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.13,hjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=1))

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_withnewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis_syn_wout,width=unit(6,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.45,vjust=-1),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=1))

ggsave("20240703_empirical.validated_subset.syn_wout.pdf", width=11, height=8.5, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#ggsave("20240315_main_empirical.syn_wout.pdf", width=11, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/",ggplot_combined)

#STOP

```

#####Absolute counts relativised by the average coverage:
######Extract mean coverage from the qualimap reports:
```{bash}

module load qualimap/2.2.1
module load bcftools/1.9

mkdir -p /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

BAMLIST=$(cat <(ls -v /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/4separate/multi_autosomic/*autosomic.bam) <(ls -v /share/rdata/ramon.pouso/POOLS/gen140/gen140/5processed/autosomic_isolated/*autosomic.bam)) #make sure that only the desired BAMs are in the folder
rm qualimap_coverage_summary.txt
for bam in $BAMLIST
  do
  SAMPLE=$(echo $bam | rev | cut -d'/' -f1 | rev | cut -d'_' -f1)
  if [ $SAMPLE == "C1" ]
    then GEN="gen140"
  elif [ $SAMPLE == "c1" ]
    then GEN="gen5"
  else GEN=$(echo $bam | rev | cut -d'/' -f1 | rev | tr "_" "\n" | grep "gen")
  fi
  MEAN_COV=$(grep "mean coverageData" "${bam/.bam/_stats}/genome_results.txt" | awk -F "= |X" '{print $2}')
  echo -e "$SAMPLE\t$GEN\t$MEAN_COV" >> qualimap_coverage_summary.txt
  done

```

######Draw plot:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/all_sites/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.validated_subset.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = as.numeric(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

pool_cov <- read_tsv(paste0(wd_path,"qualimap_coverage_summary.txt")) %>% filter(generation!="gen5") %>% mutate(population=ifelse(grepl("sample",sample),"lines","Pb")) %>% select(population,generation,coverage)
pool_cov$population = factor(pool_cov$population,levels=c("Pb","lines"))
pool_cov$generation <- as.numeric(gsub("gen","",pool_cov$generation)) + 83
pool_cov <- pool_cov %>% arrange(generation)
pool_cov$generation = as.numeric(pool_cov$generation)
pool_cov <- pool_cov %>% arrange(population,generation)

pool_cov <- pool_cov %>% group_by(population,generation) %>% summarise(mean_cov=mean(coverage))

#pool_cov_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
combined_tidy <- left_join(pool_counts_tidy,pool_cov,by=c("population","generation"))
colnames(combined_tidy) <- c("population","generation","ratio","mean","coverage")
combined_tidy <- combined_tidy %>% mutate(mean_rel=55.43/coverage * mean)

#Combined version (Pb):
Pb_lines_pool_counts_copies_errors_ggplot_y_scales <- ggplot(data=combined_tidy, aes(generation,mean_rel)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(ratio ~ .,scales="free_y") +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.8)) + 
  ylab("Absolute derived count (corrected by coverage)") +
  #scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  #ylim(0.6,1.2) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_pool_counts_copies_errors_ggplot_y_scales
ggsave(paste0("Pb_lines_pool_counts_copies_corrected_by_coverage_",type,".y_scales.pdf"), width=12, height=12, units="cm", device="pdf", path=wd_path)

```


##Explore coverage and mapping quality:
###From the VCF:
####Obtain distribution files:
```{bash}

#Check the site-by-site distribution of the joint (i.e. total) coverage and mapping quality of all pools:

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/
module load gcc/7.2.0
module add gcc/7.2.0

VCF="crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.vcf"

#Coverage:
grep -v '^#' $VCF | awk -F ";DP=|;VT=" '{print $2}' | awk -F "," '{printf ("%s\n", $1+$2+($3*2))}' > ${VCF/.vcf/.total_coverage.txt}

#Mapping quality:
grep -v '^#' $VCF | awk -F ";MQS=|;FLANKSEQ=" '{print $2}' | awk -F "," '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > ${VCF/.vcf/.total_MQ.txt}

```

####Plot coverage:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/quality_checks/")

cov_file <- read_tsv(paste0(wd_path,"crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.total_coverage.txt"), col_names = c("coverage"))

####Then plot the data####
#Combined version:
cov_ggplot <- ggplot(cov_file, aes(x=coverage)) +
  geom_density() +
  scale_x_continuous(breaks = seq(0, 7000, by = 1000)) +
  geom_vline(aes(xintercept=median(coverage), color="median"), linetype="dashed", size=0.5) +
  geom_vline(aes(xintercept=mean(coverage), color="mean"), linetype="dashed", size=0.5) +
  scale_color_manual(name = "statistics", values = c(median = "blue", mean = "red")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        #axis.text.x=element_text(angle=45, hjust=1, size=24,colour="black"),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        legend.key.size=unit(0.5,"cm"),
        #legend.spacing.y = unit(1,"cm"),
        legend.position=c(0.865,0.83),
        legend.title=element_text()
  )
cov_ggplot
ggsave("total_coverage.pdf", width=15, height=10, units="cm", device="pdf", path=wd_path)

```

###From the BAM files:
####Qualimap reports (output isn't exactly the desired):
```{bash}

module load qualimap/2.2.1
module load bcftools/1.9

mkdir -p /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control
cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

BAMLIST=$(cat <(ls -v /share/rdata/ramon.pouso/POOLS/gen0-40/gen0-40/4separate/multi_autosomic/*autosomic.bam) <(ls -v /share/rdata/ramon.pouso/POOLS/gen140/gen140/5processed/autosomic_isolated/*autosomic.bam)) #make sure that only the desired BAMs are in the folder
for bam in $BAMLIST
  do
  SAMPLE=$(echo $bam | rev | cut -d'/' -f1 | rev | cut -d'_' -f1)
  echo -e "$SAMPLE\t$bam" >> qualimap_multisample_analysis_input.txt
  done

qualimap multi-bamqc -d qualimap_multisample_analysis_input.txt -outdir qualimap_results/ -outfile qualimap_multisample_analysis.orthologs_autosomes.qualimap -gff /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed

```

####Samtools:
#####Depth:
######Whole-genome:
#######samtools_sequence_depth.sh
```{bash}

module load samtools/1.4.1

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

samtools mpileup -s -f /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta -b all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.bam_list.txt -l /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed | awk -F"\t" '{printf ("%s\t%s\t%s\t", $1,$2-1,$2); for (i=4;i<=NF;i+=4) {printf ("%s%c", $i, i+4 <= NF ? "\t" : "\n")}}' > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.bed

#Save this code as: /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/samtools_sequence_depth.sh

```

#######Send the array job:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

qsub -cwd -l h=compute-0-9 samtools_sequence_depth.sh

```

#######Split the output by chromosomes:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

CHROMOSOMES=$(cut -f1 /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed | uniq)
for CHR in ${CHROMOSOMES[@]}
  do 
  echo $CHR
  awk -v chr=$CHR '$1==chr' all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr$CHR.sequence_depth.bed
  done

```

#######Average data by 100kb windows:
########coverage_window_average_by_chr.sh
```{bash}

export PATH=$PATH:/share/apps/bedtools2/bin:/share/apps/est-sfs-release-2.03/:/share/apps/BAMTOOLS/bin:/share/apps/bedtools2/bin
module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

CHR=`sed -n ${SGE_TASK_ID}p <(cut -f1 /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed | uniq)`
rm all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr$CHR.sequence_depth.100kb_windows.bed
BEDLIST=$(ls /share/rdata/ramon.pouso/bootstrap/block_beds_autosomes/bl*.bed | grep $CHR)
for BED in ${BEDLIST[@]}
  do
  BLOCK=$(echo $BED | rev | cut -d'/' -f1 | rev | cut -d'.' -f1)
  echo "working with block" ${BLOCK}
  #CHR=$(echo $BLOCK | cut -d'_' -f2)
  START=$(echo $BLOCK | cut -d'_' -f3)
  END=$(echo $BLOCK | cut -d'_' -f4)
  bedtools intersect -a all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr$CHR.sequence_depth.bed -b ${BED} > window_data/${BLOCK}.sequence_depth.bed
  if [ -s window_data/${BLOCK}.sequence_depth.bed ]
    then
    awk -v start=$START -v end=$END '{for (i=4;i<=NF;i++) {sum[i] += $i};} END {printf("%s\t%s\t%s\t", $1,start,end); for (i=4;i<NF;i++) printf("%s\t", sum[i]/NR); printf("%s\n",sum[NF]/NR);}' window_data/${BLOCK}.sequence_depth.bed >> all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr$CHR.sequence_depth.100kb_windows.bed
  fi
  done
touch chr${CHR}.finished

#Save this code as: /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/coverage_window_average_by_chr.sh

```

########Send the array job:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

CHR_LIST=$(cut -f1 /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed | uniq)
N_CHROM=$(echo "$CHR_LIST" | wc -l)

qsub -cwd -l h=compute-0-9 -t 1-$N_CHROM coverage_window_average_by_chr.sh

```

#######Obtain average and error:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

#First combine all chromosome files into a single file.
cat all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr*.sequence_depth.100kb_windows.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.100kb_windows.bed

#Then calculate the pool average and standard error for each window.
##Bed format (with coordinates):
awk '{sum = 0; stdev = 0; for (i = 4; i <= NF; i++) sum += $i; sum /= (NF - 3); for (i = 4; i <= NF; i++) stdev += (($i - sum)*($i - sum))/(NF - 3 - 1);  printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,sum,sqrt(stdev)/sqrt(NF - 3))}' all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.100kb_windows.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.100kb_windows.average_and_error.bed
##Txt format (with a numeric sequence, figure-ready):
awk '{sum = 0; stdev = 0; for (i = 4; i <= NF; i++) sum += $i; sum /= (NF - 3); for (i = 4; i <= NF; i++) stdev += (($i - sum)*($i - sum))/(NF - 3 - 1);  printf ("%s\t%s\t%s\t%s\n", $1,NR,sum,sqrt(stdev)/sqrt(NF - 3))}' all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.100kb_windows.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.100kb_windows.average_and_error.txt

#Calculate the number of sites used per window:
cd window_data
echo -e "window\tstart\tstop\tsites_N" > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.100kb_windows.N_sites.txt
for file in $(ls *.bed | grep -v "VCF_subset")
  do 
  BLOCK=$(echo $file | cut -d'_' -f-2)
  START=$(echo $file | cut -d'_' -f3)
  STOP=$(echo $file | cut -d'_' -f4 | cut -d'.' -f1)
  SITES=$(wc -l < $file)
  echo -e "$BLOCK\t$START\t$STOP\t$SITES" >> all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.100kb_windows.N_sites.txt
  done
  
```

#######Draw plot:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/quality_checks/")

#cov_file <- read_tsv(paste0(wd_path,"all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth_average_error.bed"), col_types = c("fndd"), col_names=c("chromosome","average","error"))
cov_file <- read_tsv(paste0(wd_path,"all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.100kb_windows.average_and_error.txt"), col_types = c("fndd"), col_names=c("chromosome","position","average","error"))
chr_breaks <- cov_file %>% group_by(chromosome) %>% summarise(max=max(position))

####Then plot the data####
#Combined version:
cov_ggplot <- ggplot(cov_file, aes(x=position,y=average)) +
  #scale_x_continuous(breaks = seq(0, 1, by = 0.1)) +
  geom_line(size=0.2) +
  geom_ribbon(aes(ymin=average-2*sqrt(44)*error, ymax=average+2*sqrt(44)*error), fill='steelblue3', alpha=0.5) + #44 is the N size (number of pools), so sqrt(44)*error is the standard deviation
  geom_vline(aes(xintercept=chr_breaks$max[1]), color="indianred", size=0.5) +
  geom_vline(aes(xintercept=chr_breaks$max[2]), color="indianred", size=0.5) +
  geom_vline(aes(xintercept=chr_breaks$max[3]), color="indianred", size=0.5) +
  scale_x_continuous(breaks = c(chr_breaks$max[1]/2,(chr_breaks$max[1]+chr_breaks$max[2])/2,(chr_breaks$max[2]+chr_breaks$max[3])/2,(chr_breaks$max[3]+chr_breaks$max[4])/2), labels = c("2L","2R","3L","3R"), expand=c(0,0)) +
  #xlim(0,1029) +
  ylab("Sequencing depth") + #ylab("Derived count relative to 4fold and\n the mean of low rec. N population") +
  xlab("Chromosome") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        #axis.text.x=element_blank(),
        #axis.title.x=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        legend.key.size=unit(0.5,"cm"),
        #legend.spacing.y = unit(1,"cm"),
        legend.position=c(0.865,0.83),
        legend.title=element_text()
  )
cov_ggplot
ggsave(paste0("sequencing_depth_distribution.100kb_windows.pdf"), width=20, height=10, units="cm", device="pdf", path=wd_path)

```

######Whole-genome (chr by chr):
#######samtools_sequence_depth_by_chr.sh
```{bash}

module load samtools/1.4.1

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

CHR=`sed -n ${SGE_TASK_ID}p <(cut -f1 /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed | uniq)`

samtools mpileup -s -f /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta -b all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.bam_list.txt -l /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.chr$CHR.6field_bed | awk -F"\t" '{printf ("%s\t%s\t", $1,NR); for (i=4;i<=NF;i+=4) {printf ("%s%c", $i, i+4 <= NF ? "\t" : "\n")}}' > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr$CHR.sequence_depth.bed

#Save this code as: /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/samtools_sequence_depth_by_chr.sh

```

#######Send the array job:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

CHR_LIST=$(cut -f1 /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed | uniq)
N_CHROM=$(echo "$CHR_LIST" | wc -l)
for CHR in $CHR_LIST
 do
 echo $CHR
 awk -v chr=$CHR '$1 == chr {print}' /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed > /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.chr$CHR.6field_bed
 done

qsub -cwd -l h=compute-0-9 -t 1-$N_CHROM samtools_sequence_depth_by_chr.sh

```

######VCF subset:
#######samtools_sequence_depth_VCF.sh
```{bash}

module load samtools/1.4.1

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

samtools mpileup -s -f /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta -b all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.bam_list.txt -l /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.pileup
awk -F"\t" '{printf ("%s\t%s\t%s\t", $1,$2-1,$2); for (i=4;i<=NF;i+=4) {printf ("%s%c", $i, i+4 <= NF ? "\t" : "\n")}}' all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.pileup > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.bed

#Save this code as: /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/samtools_sequence_depth_VCF.sh

```

#######Send the array job:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

grep -v '^#' /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.vcf | awk -F"\t" '$1 != "X" {printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' > /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/crisp_all_pools_gen0-140_masked.recode_snps.gen0-140_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom_complete.bed

qsub -cwd -l h=compute-0-9 samtools_sequence_depth_VCF.sh

```

#######Split the output by chromosomes:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

CHROMOSOMES=$(cut -f1 /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed | uniq)
for CHR in ${CHROMOSOMES[@]}
  do 
  echo $CHR
  awk -v chr=$CHR '$1==chr' all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr$CHR.sequence_depth.VCF_subset.bed
  done

```

#######Average data by 100kb windows:
########coverage_window_average_by_chr.VCF_subset.sh
```{bash}

export PATH=$PATH:/share/apps/bedtools2/bin:/share/apps/est-sfs-release-2.03/:/share/apps/BAMTOOLS/bin:/share/apps/bedtools2/bin
module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

CHR=`sed -n ${SGE_TASK_ID}p <(cut -f1 /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed | uniq)`
rm all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr$CHR.sequence_depth.VCF_subset.100kb_windows.bed
BEDLIST=$(ls /share/rdata/ramon.pouso/bootstrap/block_beds_autosomes/bl*.bed | grep $CHR)
for BED in ${BEDLIST[@]}
  do
  BLOCK=$(echo $BED | rev | cut -d'/' -f1 | rev | cut -d'.' -f1)
  echo "working with block" ${BLOCK}
  #CHR=$(echo $BLOCK | cut -d'_' -f2)
  START=$(echo $BLOCK | cut -d'_' -f3)
  END=$(echo $BLOCK | cut -d'_' -f4)
  bedtools intersect -a all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr$CHR.sequence_depth.VCF_subset.bed -b ${BED} > window_data/${BLOCK}.sequence_depth.VCF_subset.bed
  if [ -s window_data/${BLOCK}.sequence_depth.VCF_subset.bed ]
    then
    awk -v start=$START -v end=$END '{for (i=4;i<=NF;i++) {sum[i] += $i};} END {printf("%s\t%s\t%s\t", $1,start,end); for (i=4;i<NF;i++) printf("%s\t", sum[i]/NR); printf("%s\n",sum[NF]/NR);}' window_data/${BLOCK}.sequence_depth.VCF_subset.bed >> all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr$CHR.sequence_depth.VCF_subset.100kb_windows.bed
  fi
  done
touch chr${CHR}.VCF_subset.finished

#Save this code as: /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/coverage_window_average_by_chr.VCF_subset.sh

```

########Send the array job:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

CHR_LIST=$(cut -f1 /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed | uniq)
N_CHROM=$(echo "$CHR_LIST" | wc -l)

qsub -cwd -l h=compute-0-9 -t 1-$N_CHROM coverage_window_average_by_chr.VCF_subset.sh

```

#######Obtain average and error:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

#First combine all chromosome files into a single file.
cat all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr*.sequence_depth.VCF_subset.100kb_windows.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.bed

#Then calculate the pool average and standard error for each window.
##Bed format (with coordinates):
awk '{sum = 0; stdev = 0; for (i = 4; i <= NF; i++) sum += $i; sum /= (NF - 3); for (i = 4; i <= NF; i++) stdev += (($i - sum)*($i - sum))/(NF - 3 - 1);  printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,sum,sqrt(stdev)/sqrt(NF - 3))}' all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.average_and_error.bed
##Txt format (with a numeric sequence, figure-ready):
awk '{sum = 0; stdev = 0; for (i = 4; i <= NF; i++) sum += $i; sum /= (NF - 3); for (i = 4; i <= NF; i++) stdev += (($i - sum)*($i - sum))/(NF - 3 - 1);  printf ("%s\t%s\t%s\t%s\n", $1,NR,sum,sqrt(stdev)/sqrt(NF - 3))}' all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.average_and_error.txt

#Calculate the number of sites used per window:
cd window_data
echo -e "window\tstart\tstop\tsites_N" > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.N_sites.txt
for file in $(ls *VCF_subset.bed)
  do 
  BLOCK=$(echo $file | cut -d'_' -f-2)
  START=$(echo $file | cut -d'_' -f3)
  STOP=$(echo $file | cut -d'_' -f4 | cut -d'.' -f1)
  SITES=$(wc -l < $file)
  echo -e "$BLOCK\t$START\t$STOP\t$SITES" >> all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.N_sites.txt
  done

#Filter out windows:
module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

##With <10 SNPs.
tail -n+2 window_data/all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.N_sites.txt | awk -F"_|\t" '$5>=10 {printf ("%s\t%s\t%s\t%s\n", $2,$3,$4,$5)}' | bedtools intersect -a all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.average_and_error.bed -b stdin | awk '{printf ("%s\t%s\t%s\t%s\n", $1,NR,$4,$5)}' > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.filter_10_SNPs.average_and_error.txt

##With <15 SNPs.
tail -n+2 window_data/all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.N_sites.txt | awk -F"_|\t" '$5>=15 {printf ("%s\t%s\t%s\t%s\n", $2,$3,$4,$5)}' | bedtools intersect -a all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.average_and_error.bed -b stdin | awk '{printf ("%s\t%s\t%s\t%s\n", $1,NR,$4,$5)}' > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.filter_15_SNPs.average_and_error.txt

```

#######Draw plot:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/quality_checks/")

#cov_file <- read_tsv(paste0(wd_path,"all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth_average_error.bed"), col_types = c("fndd"), col_names=c("chromosome","average","error"))
cov_file <- read_tsv(paste0(wd_path,"all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.filter_15_SNPs.average_and_error.txt"), col_types = c("fndd"), col_names=c("chromosome","position","average","error"))
chr_breaks <- cov_file %>% group_by(chromosome) %>% summarise(max=max(position))

####Then plot the data####
#Combined version:
cov_ggplot <- ggplot(cov_file, aes(x=position,y=average)) +
  #scale_x_continuous(breaks = seq(0, 1, by = 0.1)) +
  geom_line(size=0.2) +
  geom_ribbon(aes(ymin=average-2*sqrt(44)*error, ymax=average+2*sqrt(44)*error), fill='steelblue3', alpha=0.5) + #44 is the N size (number of pools), so sqrt(44)*error is the standard deviation
  geom_vline(aes(xintercept=chr_breaks$max[1]), color="indianred", size=0.5) +
  geom_vline(aes(xintercept=chr_breaks$max[2]), color="indianred", size=0.5) +
  geom_vline(aes(xintercept=chr_breaks$max[3]), color="indianred", size=0.5) +
  expand_limits(y=0) +
  scale_x_continuous(breaks = c(chr_breaks$max[1]/2,(chr_breaks$max[1]+chr_breaks$max[2])/2,(chr_breaks$max[2]+chr_breaks$max[3])/2,(chr_breaks$max[3]+chr_breaks$max[4])/2), labels = c("2L","2R","3L","3R"), expand=c(0,0)) +
  scale_y_continuous(breaks = c(0,25,50,75,100,125), limits=c(0,125), expand=c(0,0)) +
  #ylim(0,125) +
  ylab("Sequencing depth") + #ylab("Derived count relative to 4fold and\n the mean of low rec. N population") +
  xlab("Chromosome") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        #axis.text.x=element_blank(),
        #axis.title.x=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        legend.key.size=unit(0.5,"cm"),
        #legend.spacing.y = unit(1,"cm"),
        legend.position=c(0.865,0.83),
        legend.title=element_text()
  )
cov_ggplot
ggsave(paste0("sequencing_depth_distribution.VCF_subset.100kb_windows.filter_15_SNPs.pdf"), width=20, height=10, units="cm", device="pdf", path=wd_path)

```

#####MQ:
######MQ_window_average_by_chr.sh
```{bash}

module load samtools/1.4.1

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

CHR=`sed -n ${SGE_TASK_ID}p <(cut -f1 /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed | uniq)`
FILELIST=$(cat all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.bam_list.txt)
BEDLIST=$(ls /share/rdata/ramon.pouso/bootstrap/block_beds_autosomes/bl*.bed | grep $CHR)
for FILE in ${FILELIST[@]}
  do
  SAMPLE=$(echo $FILE | cut -d'/' -f10 | cut -d'_' -f-3)
  echo "working with sample" ${SAMPLE}
  if [ -f ${SAMPLE}_chr$CHR.MQ.100kb_windows.bed ]; then rm ${SAMPLE}_chr$CHR.MQ.100kb_windows.bed; fi
  for BED in ${BEDLIST[@]}
    do
    BLOCK=$(echo $BED | rev | cut -d'/' -f1 | rev | cut -d'.' -f1)
    #echo "working with block" ${BLOCK}
    #CHR=$(echo $BLOCK | cut -d'_' -f2)
    START=$(echo $BLOCK | cut -d'_' -f3)
    END=$(echo $BLOCK | cut -d'_' -f4)
    samtools view $FILE $CHR:$START-$END | awk -v chr=$CHR -v start=$START -v end=$END '{sum+=$5} END {printf("%s\t%s\t%s\t%s\n", chr,start,end,sum/NR)}' >> ${SAMPLE}_chr$CHR.MQ.100kb_windows.bed
    done
  done
touch chr${CHR}.MQ.finished

#Save this code as: /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/MQ_window_average_by_chr.sh

```

######Send the array job:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

CHR_LIST=$(cut -f1 /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed | uniq)
N_CHROM=$(echo "$CHR_LIST" | wc -l)

qsub -cwd -l h=compute-0-9 -t 1-$N_CHROM MQ_window_average_by_chr.sh

```

######Obtain average and error:
```{bash}

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

#First combine all sample files into a single multi-sample file for each chromosome.
CHR_LIST=$(ls chr*.MQ.finished | cut -d'.' -f1 | cut -c 4-5)
for CHR in ${CHR_LIST[@]}
  do
  echo $CHR
  paste *chr${CHR}.MQ.100kb_windows.bed | awk '{printf("%s\t%s\t%s\t", $1,$2,$3); for (i=4; i <= NF; i+=4) printf("%s%c", $i, i+4 <= NF ? "\t" : "\n");}' > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr${CHR}.MQ.100kb_windows.bed
  done

#Then combine all chromosome files into a single file.
cat all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_chr*.MQ.100kb_windows.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.MQ.100kb_windows.bed

#Then calculate the pool average and standard error for each window.
##Bed format (with coordinates):
awk '{sum = 0; stdev = 0; for (i = 4; i <= NF; i++) sum += $i; sum /= (NF - 3); for (i = 4; i <= NF; i++) stdev += (($i - sum)*($i - sum))/(NF - 3 - 1);  printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,sum,sqrt(stdev)/sqrt(NF - 3))}' all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.MQ.100kb_windows.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.MQ.100kb_windows.average_and_error.bed
##Txt format (with a numeric sequence, figure-ready):
awk '{sum = 0; stdev = 0; for (i = 4; i <= NF; i++) sum += $i; sum /= (NF - 3); for (i = 4; i <= NF; i++) stdev += (($i - sum)*($i - sum))/(NF - 3 - 1);  printf ("%s\t%s\t%s\t%s\n", $1,NR,sum,sqrt(stdev)/sqrt(NF - 3))}' all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.MQ.100kb_windows.bed > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.MQ.100kb_windows.average_and_error.txt

#Filter out windows (using the number of SNPs per window as calculated in the coverage section):
module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/POOLS/all_gens_0_140/quality_control/

##With <10 SNPs.
tail -n+2 window_data/all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.N_sites.txt | awk -F"_|\t" '$5>=10 {printf ("%s\t%s\t%s\t%s\n", $2,$3,$4,$5)}' | bedtools intersect -a all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.MQ.100kb_windows.average_and_error.bed -b stdin | awk '{printf ("%s\t%s\t%s\t%s\n", $1,NR,$4,$5)}' > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.MQ.100kb_windows.filter_10_SNPs.average_and_error.txt

##With <15 SNPs.
tail -n+2 window_data/all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth.VCF_subset.100kb_windows.N_sites.txt | awk -F"_|\t" '$5>=15 {printf ("%s\t%s\t%s\t%s\n", $2,$3,$4,$5)}' | bedtools intersect -a all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.MQ.100kb_windows.average_and_error.bed -b stdin | awk '{printf ("%s\t%s\t%s\t%s\n", $1,NR,$4,$5)}' > all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.MQ.100kb_windows.filter_15_SNPs.average_and_error.txt

```

######Draw plot:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/quality_checks/")

#cov_file <- read_tsv(paste0(wd_path,"all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.sequence_depth_average_error.bed"), col_types = c("fndd"), col_names=c("chromosome","average","error"))
cov_file <- read_tsv(paste0(wd_path,"all_samples_bwa_iso_rmdup_mq30_rg_multirealigned_autosomic.MQ.100kb_windows.filter_15_SNPs.average_and_error.txt"), col_types = c("fndd"), col_names=c("chromosome","position","average","error"))
chr_breaks <- cov_file %>% group_by(chromosome) %>% summarise(max=max(position))

####Then plot the data####
#Combined version:
cov_ggplot <- ggplot(cov_file, aes(x=position,y=average)) +
  #scale_x_continuous(breaks = seq(0, 1, by = 0.1)) +
  geom_line(size=0.2) +
  geom_ribbon(aes(ymin=average-2*sqrt(44)*error, ymax=average+2*sqrt(44)*error), fill='steelblue3', alpha=0.5) + #44 is the N size (number of pools), so sqrt(44)*error is the standard deviation
  geom_vline(aes(xintercept=chr_breaks$max[1]), color="indianred", size=0.5) +
  geom_vline(aes(xintercept=chr_breaks$max[2]), color="indianred", size=0.5) +
  geom_vline(aes(xintercept=chr_breaks$max[3]), color="indianred", size=0.5) +
  expand_limits(y=0) +
  scale_x_continuous(breaks = c(chr_breaks$max[1]/2,(chr_breaks$max[1]+chr_breaks$max[2])/2,(chr_breaks$max[2]+chr_breaks$max[3])/2,(chr_breaks$max[3]+chr_breaks$max[4])/2), labels = c("2L","2R","3L","3R"), expand=c(0,0)) +
  scale_y_continuous(breaks = c(0,25,50,75,100,125), limits=c(0,125), expand=c(0,0)) +
  #ylim(0,125) +
  ylab("Mapping quality") + #ylab("Derived count relative to 4fold and\n the mean of low rec. N population") +
  xlab("Chromosome") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        #axis.text.x=element_blank(),
        #axis.title.x=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        legend.key.size=unit(0.5,"cm"),
        #legend.spacing.y = unit(1,"cm"),
        legend.position=c(0.865,0.83),
        legend.title=element_text()
  )
cov_ggplot
ggsave(paste0("MQ_distribution.filter_15_SNPs.100kb_windows.pdf"), width=20, height=10, units="cm", device="pdf", path=wd_path)

```

##Additional simulations:
###s,h tests:
####Regular parameters:
#####Download files:
```{bash}

#Rename the files that will be downloaded:

cd /share/rdata2/dani_k/consanguinidad_lenta/simulations/results/infNatPop

FOLDERS=$(ls -d *L_lethal0.015.*Purging)
for dir in $FOLDERS
  do 
  cd $dir
  echo $dir
  indir=$(ls -d TP*)
  cd $indir
  PARAM=$(echo $PWD | cut -d'/' -f9)
  mv derived_count.dat derived_count_${PARAM}.dat
  mv derived_count_se_relative.dat derived_count_se_relative_${PARAM}.dat
  cd ../..
  done

#Download the files, from outside the server:
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata2/dani_k/consanguinidad_lenta/simulations/results/infNatPop/*L_lethal0.015.*Purging/TP2600.AL80.s0.05.s0.5/derived_count*Purging.dat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/

#From outside the server:
cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/
FILES=$(ls derived_count_*L*Purging.dat)
for file in ${FILES[@]}
  do 
  echo "$file"
  cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}
  done

```

#####Simulated ratio of averages, with replicate errors:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/
#FILES=$(ls derived_count_*L*U.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/")

parameters_list <- list.files(path=wd_path, pattern = "\\Purging.txt$") %>% grep(pattern="_se_relative_", invert=T, value=T)
parameters_variables <- vector(mode="list",length=length(parameters_list))

counter <- 0
for (files in parameters_list) {
parameters <- gsub("derived_count_","",gsub(".txt","",files))
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,"derived_count_",parameters,".txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,"derived_count_se_relative_",parameters,".txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store the dataframe in a list, and rename the element as parameters:
counter <- counter + 1
names(parameters_variables)[counter] <- parameters
parameters_variables[[counter]] <- average_combined_tidy_bis

#Store each dataframe separately for the combined figure:
#if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral") {
#  average_combined_tidy_neutral_withnewmut <- average_combined_tidy_bis
#} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive") {
#  average_combined_tidy_additive_withnewmut <- average_combined_tidy_bis
#} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") {
#  average_combined_tidy_purging_withnewmut <- average_combined_tidy_bis
#}
}

list2env(parameters_variables,envir=.GlobalEnv)

#Plot the data in a loop:
plots_variables <- vector(mode="list",length=length(parameters_list))
for (element in c(1:length(parameters_variables))) {
parameters <- print(names(parameters_variables[element]))

purging_ggplot <- ggplot(data=filter(parameters_variables[[element]],ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle(parameters) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0,0),"cm"),
        plot.title=element_text(size=8, face="bold", margin=margin(b=0.1, unit="cm")),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
purging_ggplot

#Store the plot in a list, and rename the element as parameters:
names(plots_variables)[element] <- parameters
plots_variables[[element]] <- purging_ggplot
}

library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(plots_variables[[1]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[2]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[3]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[4]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[5]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[6]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[7]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[8]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[9]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[10]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[11]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[12]],width=unit(4,"cm"),height=unit(4,"cm")),ncol=3,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.48,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=2),right=textGrob(expression(bold("s = 0.001                                        s = 0.01                                        s = 0.1                                         s = 0.2")),rot=-90,gp=gpar(fontsize=11,fontface="bold"),x=-0.75,vjust=0,hjust=0.51),top=textGrob(expression(bold("h = 0.05                                                                                   h = 0.283                                                                                 h = 0.45")),gp=gpar(fontsize=11,fontface="bold"),x=0.15,hjust=0))

ggsave("20240614_h_vs_s_test_simulations.ratio_of_averages.syn_wout.pdf", width=32, height=24, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/",ggplot_combined)

#Stop
STOP

```

####No additional lethals:
#####Download files:
```{bash}

#Rename the files that will be downloaded:
cd /share/rdata2/dani_k/consanguinidad_lenta/simulations/results/infNatPop
FOLDERS=$(ls -d *L_lethal0.0.*Purging)
for dir in $FOLDERS
  do 
  cd $dir
  echo $dir
  indir=$(ls -d TP*)
  cd $indir
  PARAM=$(echo $PWD | cut -d'/' -f9)
  mv derived_count.dat derived_count_${PARAM}.dat
  mv derived_count_se_relative.dat derived_count_se_relative_${PARAM}.dat
  cd ../..
  done

#Download the files, from outside the server:
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata2/dani_k/consanguinidad_lenta/simulations/results/infNatPop/*L_lethal0.0.*Purging/TP2600.AL80.s0.05.s0.5/derived_count*Purging.dat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/

#Convert from .dat to .txt, from outside the server:
cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/
FILES=$(ls derived_count_*L_lethal0.0.*Purging.dat) #find . -mtime -1
for file in ${FILES[@]}
  do 
  echo "$file"
  cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}
  done

```

#####Simulated ratio of averages, with replicate errors:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/")

parameters_list <- list.files(path=wd_path, pattern = "\\.txt$") %>% grep(pattern="_se_relative_", invert=T, value=T) %>% grep(pattern="L_lethal0.0.K1000", value=T) %>% grep(pattern="h0.45", invert=T, value=T) %>% grep(pattern="s0.001", invert=T, value=T)
parameters_variables <- vector(mode="list",length=length(parameters_list))

counter <- 0
for (files in parameters_list) {
parameters <- gsub("derived_count_","",gsub(".txt","",files))
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,"derived_count_",parameters,".txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,"derived_count_se_relative_",parameters,".txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store the dataframe in a list, and rename the element as parameters:
counter <- counter + 1
names(parameters_variables)[counter] <- parameters
parameters_variables[[counter]] <- average_combined_tidy_bis

#Store each dataframe separately for the combined figure:
#if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral") {
#  average_combined_tidy_neutral_withnewmut <- average_combined_tidy_bis
#} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive") {
#  average_combined_tidy_additive_withnewmut <- average_combined_tidy_bis
#} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") {
#  average_combined_tidy_purging_withnewmut <- average_combined_tidy_bis
#}
}

list2env(parameters_variables,envir=.GlobalEnv)

#Plot the data in a loop:
plots_variables <- vector(mode="list",length=length(parameters_list))
for (element in c(1:length(parameters_variables))) {
parameters <- print(names(parameters_variables[element]))

purging_ggplot <- ggplot(data=filter(parameters_variables[[element]],ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle(parameters) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0,0),"cm"),
        plot.title=element_text(size=8, face="bold", margin=margin(b=0.1, unit="cm")),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
purging_ggplot

#Store the plot in a list, and rename the element as parameters:
names(plots_variables)[element] <- parameters
plots_variables[[element]] <- purging_ggplot
}

library(grid)
library(gridExtra)
library(egg)

#Combine the plots:
##4s x 3h:
ggplot_combined <- grid.arrange(set_panel_size(plots_variables[[1]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[2]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[3]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[4]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[5]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[6]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[7]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[8]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[9]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[10]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[11]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[12]],width=unit(4,"cm"),height=unit(4,"cm")),ncol=3,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.48,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=2),right=textGrob(expression(bold("s = 0.001                                        s = 0.01                                        s = 0.1                                         s = 0.2")),rot=-90,gp=gpar(fontsize=11,fontface="bold"),x=-0.75,vjust=0,hjust=0.51),top=textGrob(expression(bold("h = 0.05                                                                                   h = 0.283                                                                                 h = 0.45")),gp=gpar(fontsize=11,fontface="bold"),x=0.15,hjust=0))

ggsave("20240618_h_vs_s_test_simulations_wout_lethals.ratio_of_averages.syn_wout.pdf", width=32, height=24, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/",ggplot_combined)


##4h x 3s:
ggplot_combined <- grid.arrange(set_panel_size(plots_variables[[1]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[2]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[4]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[3]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[5]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[6]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[8]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[7]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[9]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[10]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[12]],width=unit(4,"cm"),height=unit(4,"cm")),set_panel_size(plots_variables[[11]],width=unit(4,"cm"),height=unit(4,"cm")),ncol=4,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.48,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")),rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=1),right=textGrob(expression(bold("s = 0.01                                        s = 0.1                                         s = 0.2")),rot=-90,gp=gpar(fontsize=11,fontface="bold"),x=-0.75,vjust=-1,hjust=0.51),top=textGrob(expression(bold("h = 0.05                                                                              h = 0.283                                                                             h = 0.5                                                                       h = 0.5 (constant)")),gp=gpar(fontsize=11,fontface="bold"),x=0.11,hjust=0))

ggsave("20240626_h_vs_s_test_simulations_wout_lethals.ratio_of_averages.syn_wout.pdf", width=40, height=18, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/",ggplot_combined)

#Stop
STOP

```

###Purging vs additive vs neutral, infinite natural population:
####Simulated ratio of averages, with replicate errors:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/
#FILES=$(ls derived_count_*L*U.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive", "L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,"derived_count_",parameters,"_doubleU.txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,"derived_count_se_relative_",parameters,"_doubleU.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Neutral") {
  average_combined_tidy_neutral_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.5.Additive") {
  average_combined_tidy_additive_withnewmut <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging") {
  average_combined_tidy_purging_withnewmut <- average_combined_tidy_bis
}
}


#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut <- ggplot(data=filter(average_combined_tidy_neutral_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0,-2.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        #plot.title=element_text(hjust=0.5),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut <- ggplot(data=filter(average_combined_tidy_additive_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.3,1.15),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.75,0.95,0.75),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut
  
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut <- ggplot(data=filter(average_combined_tidy_purging_withnewmut,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Including new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.5,-2.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut

#Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut <- ggplot(average_combined_tidy_purging_withnewmut,aes(generation,mean)) + geom_blank()
#Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut <- ggplot(average_combined_tidy_purging_withnewmut,aes(generation,mean)) + geom_blank()

library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral_withnewmut,width=unit(6,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive_withnewmut,width=unit(6,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_withnewmut,width=unit(6,"cm"),height=unit(6,"cm")),ncol=1,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=11,fontface="bold"),x=0.38,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-083 and 4-fold syn.")), rot=90,gp=gpar(fontsize=11,fontface="bold"),vjust=2),right=textGrob(expression(bold("Neutral model                                         Additive model                                      Purging model")),rot=-90,gp=gpar(fontsize=11,fontface="bold"),x=-5,vjust=0,hjust=0.51))

ggsave("20240613_main_simulations.ratio_of_averages.syn_wout.doubleU.pdf", width=18, height=22.5, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/",ggplot_combined)

#Stop
STOP

```

###Kyriazis model:
####Download files:
```{bash}

#Rename the files that will be downloaded:

cd /share/rdata2/dani_k/consanguinidad_lenta/simulations/results/infNatPop/kyriazis_L0.315.L_lethal0.000945.K1000.beta0.186.s0.01314833.h0.283.Purging/TP2600.AL80.s0.05.s0.5

PARAM=$(echo $PWD | cut -d'/' -f9)
mv derived_count.dat derived_count_${PARAM}.dat
mv derived_count_se_relative.dat derived_count_se_relative_${PARAM}.dat

#Download the files, from outside the server:
export SSHPASS=$(cat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/rua2.txt)
sshpass -e scp ramon.pouso@rua2.uvigo.es://share/rdata2/dani_k/consanguinidad_lenta/simulations/results/infNatPop/kyriazis*Purging/TP2600.AL80.s0.05.s0.5/derived_count*Purging.dat /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/

#From outside the server:
cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/
FILES=$(ls derived_count_*kyriazis_*L*Purging.dat)
for file in ${FILES[@]}
  do 
  echo "$file"
  cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}
  done

```

#####Simulated ratio of averages, with replicate errors:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/
#FILES=$(ls derived_count_*L*U.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/")

parameters <- gsub("derived_count_","",gsub(".txt","",list.files(path=wd_path, pattern = "kyriazis") %>% grep(pattern="_se_relative_", invert=T, value=T) %>% grep(pattern="txt", value=T)))
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,"derived_count_",parameters,".txt")) 
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==83) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,"derived_count_se_relative_",parameters,".txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10","Line11","Line12","Line13","Line14","Line15","Line16","Line17","Line18","Line19"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0


#Plot the data:
purging_ggplot <- ggplot(data=filter(average_combined_tidy_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(10),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=3,position=position_dodge(10)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative to Pb-083 and 4-fold syn.") +
  xlab("Generations") +
  scale_y_continuous(breaks = seq(0, 2, by = 0.5)) +
  ylim(0,2) +
  scale_shape_manual(values=c(16,18)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(71,235)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle(parameters) +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=10,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        #axis.title.x=element_blank(),
        #axis.title.y=element_blank(),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        plot.title=element_text(size=8, face="bold", margin=margin(b=0.1, unit="cm")),
        strip.text=element_text(size=10,colour="black"),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
purging_ggplot
ggsave("20240619_kyriazis_simulations.ratio_of_averages.syn_wout.pdf", width=18, height=12, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/counts/simulations/excl_newmut_gen83/infiniteNatPop/",purging_ggplot)

```
