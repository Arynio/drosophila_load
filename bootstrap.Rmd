---
title: "bootstrap"
output: html_document
---

#1. Define bootstrap blocks:
##Autosomes.
```{bash}

cd /share/rdata/ramon.pouso/bootstrap/

#Obtain the length of the analysed autosomes:
awk '($1=="2L") || ($1=="2R") || ($1=="3L") || ($1=="3R") {print $2}' /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.length.txt | paste -sd+ | bc #108990206

#Since the autosomes measure 109Mb, we'd ideally split them into 1090 blocks of 100kb. However we can only define 1088 blocks (the missing ones would be split among the remaining bases of each autosome):
BLOCK_LENGTH=100000
awk -F"\t" '($1=="2L") || ($1=="2R") || ($1=="3L") || ($1=="3R") {printf ("%s\t%s\t%s\t%s\n", $1,0,$2,$2)}' /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.length.txt > dmel-autosomes-r6.14.length.bed

#Obtain the number of subdivision blocks for each scaffold, as well as the starting point of the last block:
awk -F"\t" -v bl=$BLOCK_LENGTH '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$4-bl,int($4/bl))}' dmel-autosomes-r6.14.length.bed | sort -k4,4nr > dmel-autosomes-r6.14.length.modified.bed

#For each chromosome, calculate $DIFF (the average distance between the starting points of different blocks i.e. the length of a block + the interblock distance, without considering the last block). Then define the starting and finishing point of each block (except for the last one) accounting for the interblock distance. Then define the last block at the very end of the scaffold. Finally, output all blocks to a new file.
rm bed_file_bootstrap_blocks_autosomes.bed
while read -r SCAFFOLD BEGIN END LENGTH WOUT_LAST N_BLOCKS; do
  echo $SCAFFOLD "has" $N_BLOCKS "block(s)"
  DIFF=$(echo "scale=6; $WOUT_LAST/($N_BLOCKS-1)" | bc | awk '{printf "%s", int($0)}')
  for ((b=1; b<N_BLOCKS; b++))
    do
    CURRENT_DIFF=$((DIFF*(b-1)))
    START=$((BEGIN+1+CURRENT_DIFF))
    STOP=$((START+BLOCK_LENGTH-1))
    echo -e "$SCAFFOLD\t$START\t$STOP" >> bed_file_bootstrap_blocks_autosomes.bed
    done
  echo -e "$SCAFFOLD\t$((WOUT_LAST+1))\t$LENGTH" >> bed_file_bootstrap_blocks_autosomes.bed
done < dmel-autosomes-r6.14.length.modified.bed

#Sanity check: test whether all blocks measure exactly the same as $BLOCK_LENGTH. They do!
awk -F"\t" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$3-$2+1)}' bed_file_bootstrap_blocks_autosomes.bed | cut -f4 | sort | uniq

#Sort the bed by scaffold and position.
sort -k1,1 -k2,2n bed_file_bootstrap_blocks_autosomes.bed | awk -F"\t" '{printf ("%s\t%s\t%s\t%s%04d_%s_%s_%s\n", $1,$2,$3,"bl",NR,$1,$2,$3)}' > bed_file_bootstrap_blocks_autosomes_sorted.bed
mv bed_file_bootstrap_blocks_autosomes_sorted.bed bed_file_bootstrap_blocks_autosomes.bed

#Finally, generate a .bed file for each block (row).
mkdir -p block_beds_autosomes
cd block_beds_autosomes
awk '{filename = sprintf("%s.bed", $4); print >filename; close(filename)}' ./../bed_file_bootstrap_blocks_autosomes.bed

```

##Xchr.
```{bash}

cd /share/rdata/ramon.pouso/bootstrap/

#Obtain the length of the Xchr:
awk '($1=="X") {print $2}' /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.length.txt | paste -sd+ | bc #23542271

#Since the Xchr measures 23.54Mb, we'll split it into 235 blocks of 100kb. 42271 bases will remain unassigned:
BLOCK_LENGTH=100000
awk -F"\t" '($1=="X") {printf ("%s\t%s\t%s\t%s\n", $1,0,$2,$2)}' /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.length.txt > dmel-Xchr-r6.14.length.bed

#Obtain the number of subdivision blocks for each scaffold, as well as the starting point of the last block:
awk -F"\t" -v bl=$BLOCK_LENGTH '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$4-bl,int($4/bl))}' dmel-Xchr-r6.14.length.bed | sort -k4,4nr > dmel-Xchr-r6.14.length.modified.bed


#For each chromosome, calculate $DIFF (the average distance between the starting points of different blocks i.e. the length of a block + the interblock distance, without considering the last block). Then define the starting and finishing point of each block (except for the last one) accounting for the interblock distance. Then define the last block at the very end of the scaffold. Finally, output all blocks to a new file.
rm bed_file_bootstrap_blocks_Xchr.bed
while read -r SCAFFOLD BEGIN END LENGTH WOUT_LAST N_BLOCKS; do
  echo $SCAFFOLD "has" $N_BLOCKS "block(s)"
  DIFF=$(echo "scale=6; $WOUT_LAST/($N_BLOCKS-1)" | bc | awk '{printf "%s", int($0)}')
  for ((b=1; b<N_BLOCKS; b++))
    do
    CURRENT_DIFF=$((DIFF*(b-1)))
    START=$((BEGIN+1+CURRENT_DIFF))
    STOP=$((START+BLOCK_LENGTH-1))
    echo -e "$SCAFFOLD\t$START\t$STOP" >> bed_file_bootstrap_blocks_Xchr.bed
    done
  echo -e "$SCAFFOLD\t$((WOUT_LAST+1))\t$LENGTH" >> bed_file_bootstrap_blocks_Xchr.bed
done < dmel-Xchr-r6.14.length.modified.bed

#Sanity check: test whether all blocks measure exactly the same as $BLOCK_LENGTH. They do!
awk -F"\t" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$3-$2+1)}' bed_file_bootstrap_blocks_Xchr.bed | cut -f4 | sort | uniq

#Sort the bed by scaffold and position.
sort -k1,1 -k2,2n bed_file_bootstrap_blocks_Xchr.bed | awk -F"\t" '{printf ("%s\t%s\t%s\t%s%04d_%s_%s_%s\n", $1,$2,$3,"bl",NR,$1,$2,$3)}' > bed_file_bootstrap_blocks_Xchr_sorted.bed
mv bed_file_bootstrap_blocks_Xchr_sorted.bed bed_file_bootstrap_blocks_Xchr.bed

#Finally, generate a .bed file for each block (row).
mkdir -p block_beds_Xchr
cd block_beds_Xchr
awk '{filename = sprintf("%s.bed", $4); print >filename; close(filename)}' ./../bed_file_bootstrap_blocks_Xchr.bed

```

#2. Define parallelisation parameters (this should be performed for each variable and genomic region).
```{r, eval=FALSE, engine='bash'}

REGION=(Xchr) #autosomes #Xchr
STATISTIC=(derived_allele_counts) #derived_allele_counts #derived_heterozygous_counts #derived_homozygous_counts
PARALLEL=10

mkdir -p /share/rdata/ramon.pouso/bootstrap/$STATISTIC/$REGION/block_list
cd /share/rdata/ramon.pouso/bootstrap/

rm $STATISTIC/$REGION/block_list/block_list_*.txt
BLOCK_N=$(ll -rth block_beds_${REGION}/bl*.bed | wc -l)
PARTITION_N=$(echo "scale=3; $BLOCK_N/$PARALLEL" | bc | awk '{printf "%s", int($0)}')
for ((part=1; part < ${PARALLEL[@]}; part++));
  do
  echo $part
  PARTbis=$(printf "%02d\n" $part)
  START=$(((part-1)*PARTITION_N+1))
  ls block_beds_${REGION}/ | tail -n+$START | head -n$PARTITION_N > $STATISTIC/$REGION/block_list/block_list_${PARTbis}.txt
  done
part=${PARALLEL[@]}
echo $part
PARTbis=$(printf "%02d\n" $part)
START=$(((part-1)*PARTITION_N+1)) 
ls block_beds_${REGION}/ | tail -n+$START > $STATISTIC/$REGION/block_list/block_list_${PARTbis}.txt

```

#3. Obtain statistics for each block in parallel runs.
###Derived allele counts.
####All sites:
```{r, eval=FALSE, engine='bash'}

#Run it as follows:
PARALLEL=2
REGION="Xchr" #where REGION should be replaced with either "autosomes" or "Xchr"
cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/$REGION
mkdir -p block_counts
qsub -cwd -l h=compute-0-9 -t 1-$PARALLEL /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/derived_allele_counts.sh $REGION

***************************** #save code from here on as /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/derived_allele_counts.sh

REGION=$1 #autosomes or Xchr
CHUNK=$(printf "%02d" ${SGE_TASK_ID}) #chunk of parallelisation

module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/bootstrap/

echo "generating parallel derived allele counts for chunk" $CHUNK
echo "retrieving blocks in chunk" $CHUNK
BLOCKLIST=$(cut -d'.' -f1 derived_allele_counts/$REGION/block_list/block_list_${CHUNK}.txt)
echo "retrieving pools"
POOL_LIST=($(ls -v `find "/share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories" -name '*_gen0-140_pool_'${REGION}'.txt' -print`))
for BLOCK in ${BLOCKLIST[@]}
  do 
  echo "working with block" ${BLOCK}
  BED=$(readlink -f block_beds_${REGION}/${BLOCK}.bed)
  rm derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${BLOCK}.txt
  
  #echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\tfourfold_cov\ttolerated_V\ttolerated_D\ttolerated_cov\tdeleterious_V\tdeleterious_D\tdeleterious_cov\tLoF_V\tLoF_D\tLoF_cov" > derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${BLOCK}.txt
  echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${BLOCK}.txt
  for pool in "${POOL_LIST[@]}"
    do
    echo "${pool}"
    SAMPLE=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f1)
    GEN=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f2)

    echo "subsetting VCF for block" $BLOCK "and pool" $pool
    bedtools intersect -a ${pool} -b ${BED} -header > ${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    p=${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    
    FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
    if [ "$FOURFOLD_V" -eq 0 ]
      then 
      FOURFOLD_A=0
      FOURFOLD_D=0
      #FOURFOLD_COV=0
    else
      FOURFOLD_A=$(grep "CUSTOM=fourfold;" $p | awk '{print $10}' | paste -sd+ | bc)
      FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
      #FOURFOLD_COV=$((FOURFOLD_A+FOURFOLD_D))
    fi
    
    MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
    if [ "$MISTOL_V" -eq 0 ]
      then 
      MISTOL_A=0
      MISTOL_D=0
      #MISTOL_COV=0
    else
      MISTOL_A=$(grep "CUSTOM=tolerated;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
      #MISTOL_COV=$((MISTOL_A+MISTOL_D))
    fi

    MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
    if [ "$MISDEL_V" -eq 0 ]
      then 
      MISDEL_A=0
      MISDEL_D=0
      #MISDEL_COV=0
    else
      MISDEL_A=$(grep "CUSTOM=deleterious;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
      #MISDEL_COV=$((MISDEL_A+MISDEL_D))
    fi

    LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
    if [ "$LOF_V" -eq 0 ]
      then 
      LOF_A=0
      LOF_D=0
      #LOF_COV=0
    else
      LOF_A=$(grep "CUSTOM=LoF;" $p | awk '{print $10}' | paste -sd+ | bc)
      LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
      #LOF_COV=$((LOF_A+LOF_D))
    fi
    #echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$FOURFOLD_COV\t$MISTOL_V\t$MISTOL_D\t$MISTOL_COV\t$MISDEL_V\t$MISDEL_D\t$MISDEL_COV\t$LOF_V\t$LOF_D\t$LOF_COV" >> derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${BLOCK}.txt
    echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${BLOCK}.txt
    rm ${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    done
  done

```

####Low/High recombination subset.
```{r, eval=FALSE, engine='bash'}

#Run it as follows:
PARALLEL=2
REGION="autosomes" #autosomes or Xchr
RECOMBINATION="high" #low or high
cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/$REGION
qsub -cwd -l h=compute-0-9 -t 1-$PARALLEL /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/derived_allele_counts_recombination.sh $REGION $RECOMBINATION

***************************** #save code from here on as /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/derived_allele_counts_recombination.sh

REGION=$1 #autosomes or Xchr
RECOMBINATION=$2 #low or high
CHUNK=$(printf "%02d" ${SGE_TASK_ID}) #chunk of parallelisation

module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/bootstrap/

echo "generating parallel derived allele counts for chunk" $CHUNK
echo "retrieving blocks in chunk" $CHUNK
BLOCKLIST=$(cut -d'.' -f1 cut -d'.' -f1 derived_allele_counts/$REGION/block_list/block_list_${CHUNK}.txt)
echo "retrieving pools"
POOL_LIST=($(ls -v `find "/share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories" -name '*_gen0-140_pool_'${REGION}'.'${RECOMBINATION}'_recombination.txt' -print`))
for BLOCK in ${BLOCKLIST[@]}
  do 
  echo "working with block" ${BLOCK}
  BED=$(readlink -f block_beds_${REGION}/${BLOCK}.bed)
  rm derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.${BLOCK}.txt
  
  echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\tfourfold_cov\ttolerated_V\ttolerated_D\ttolerated_cov\tdeleterious_V\tdeleterious_D\tdeleterious_cov\tLoF_V\tLoF_D\tLoF_cov" > derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.${BLOCK}.txt
  for pool in "${POOL_LIST[@]}"
    do
    echo "${pool}"
    SAMPLE=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f1)
    GEN=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f2)

    echo "subsetting VCF for block" $BLOCK "and pool" $pool
    bedtools intersect -a ${pool} -b ${BED} -header > ${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    p=${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    
    FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
    if [ "$FOURFOLD_V" -eq 0 ]
      then 
      FOURFOLD_A=0
      FOURFOLD_D=0
      FOURFOLD_COV=0
    else
      FOURFOLD_A=$(grep "CUSTOM=fourfold;" $p | awk '{print $10}' | paste -sd+ | bc)
      FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
      FOURFOLD_COV=$((FOURFOLD_A+FOURFOLD_D))
    fi
    
    MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
    if [ "$MISTOL_V" -eq 0 ]
      then 
      MISTOL_A=0
      MISTOL_D=0
      MISTOL_COV=0
    else
      MISTOL_A=$(grep "CUSTOM=tolerated;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
      MISTOL_COV=$((MISTOL_A+MISTOL_D))
    fi

    MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
    if [ "$MISDEL_V" -eq 0 ]
      then 
      MISDEL_A=0
      MISDEL_D=0
      MISDEL_COV=0
    else
      MISDEL_A=$(grep "CUSTOM=deleterious;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
      MISDEL_COV=$((MISDEL_A+MISDEL_D))
    fi

    LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
    if [ "$LOF_V" -eq 0 ]
      then 
      LOF_A=0
      LOF_D=0
      LOF_COV=0
    else
      LOF_A=$(grep "CUSTOM=LoF;" $p | awk '{print $10}' | paste -sd+ | bc)
      LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
      LOF_COV=$((LOF_A+LOF_D))
    fi
    echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$FOURFOLD_COV\t$MISTOL_V\t$MISTOL_D\t$MISTOL_COV\t$MISDEL_V\t$MISDEL_D\t$MISDEL_COV\t$LOF_V\t$LOF_D\t$LOF_COV" >> derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.${RECOMBINATION}_recombination.${BLOCK}.txt
    rm ${pool/.txt/_derived_allele_counts.${BLOCK}.txt}
    done
  done

```

####Valid SNP subset:
```{r, eval=FALSE, engine='bash'}

#Run it as follows:
PARALLEL=20
REGION="autosomes" #where REGION should be replaced with either "autosomes" or "Xchr"
cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/$REGION
mkdir -p block_counts
qsub -cwd -l h=compute-0-9 -t 1-$PARALLEL /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/derived_allele_counts_validated_subset.sh $REGION

***************************** #save code from here on as /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/derived_allele_counts_validated_subset.sh

REGION=$1 #autosomes or Xchr
CHUNK=$(printf "%02d" ${SGE_TASK_ID}) #chunk of parallelisation

export PATH=$PATH:/share/apps/bedtools2/bin:/share/apps/est-sfs-release-2.03/:/share/apps/BAMTOOLS/bin:/share/apps/bedtools2/bin
module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata/ramon.pouso/bootstrap/

echo "generating parallel derived allele counts for chunk" $CHUNK
echo "retrieving blocks in chunk" $CHUNK
BLOCKLIST=$(cut -d'.' -f1 derived_allele_counts/$REGION/block_list/block_list_${CHUNK}.txt)
echo "retrieving pools"
POOL_LIST=($(ls -v `find "/share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories" -name '*_gen0-140_pool.validated_subset_'${REGION}'.txt' -print`))
for BLOCK in ${BLOCKLIST[@]}
  do 
  echo "working with block" ${BLOCK}
  BED=$(readlink -f block_beds_${REGION}/${BLOCK}.bed)
  rm derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.${BLOCK}.txt
  
  #echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\tfourfold_cov\ttolerated_V\ttolerated_D\ttolerated_cov\tdeleterious_V\tdeleterious_D\tdeleterious_cov\tLoF_V\tLoF_D\tLoF_cov" > derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.${BLOCK}.txt
  echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.${BLOCK}.txt
  for pool in "${POOL_LIST[@]}"
    do
    echo "${pool}"
    SAMPLE=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f1)
    GEN=$(echo "${pool}" | rev | cut -d'/' -f1 | rev | cut -d'_' -f2)

    echo "subsetting VCF for block" $BLOCK "and pool" $pool
    bedtools intersect -a ${pool} -b ${BED} -header > ${pool/.txt/_derived_allele_counts.validated_subset.${BLOCK}.txt}
    p=${pool/.txt/_derived_allele_counts.validated_subset.${BLOCK}.txt}
    
    FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
    if [ "$FOURFOLD_V" -eq 0 ]
      then 
      FOURFOLD_A=0
      FOURFOLD_D=0
      #FOURFOLD_COV=0
    else
      FOURFOLD_A=$(grep "CUSTOM=fourfold;" $p | awk '{print $10}' | paste -sd+ | bc)
      FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
      #FOURFOLD_COV=$((FOURFOLD_A+FOURFOLD_D))
    fi
    
    MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
    if [ "$MISTOL_V" -eq 0 ]
      then 
      MISTOL_A=0
      MISTOL_D=0
      #MISTOL_COV=0
    else
      MISTOL_A=$(grep "CUSTOM=tolerated;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
      #MISTOL_COV=$((MISTOL_A+MISTOL_D))
    fi

    MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
    if [ "$MISDEL_V" -eq 0 ]
      then 
      MISDEL_A=0
      MISDEL_D=0
      #MISDEL_COV=0
    else
      MISDEL_A=$(grep "CUSTOM=deleterious;" $p | awk '{print $10}' | paste -sd+ | bc)
      MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
      #MISDEL_COV=$((MISDEL_A+MISDEL_D))
    fi

    LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
    if [ "$LOF_V" -eq 0 ]
      then 
      LOF_A=0
      LOF_D=0
      #LOF_COV=0
    else
      LOF_A=$(grep "CUSTOM=LoF;" $p | awk '{print $10}' | paste -sd+ | bc)
      LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
      #LOF_COV=$((LOF_A+LOF_D))
    fi
    #echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$FOURFOLD_COV\t$MISTOL_V\t$MISTOL_D\t$MISTOL_COV\t$MISDEL_V\t$MISDEL_D\t$MISDEL_COV\t$LOF_V\t$LOF_D\t$LOF_COV" >> derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.${BLOCK}.txt
    echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> derived_allele_counts/$REGION/block_counts/counts_pool_gen0-140_${REGION}_summary.validated_subset.${BLOCK}.txt
    rm ${pool/.txt/_derived_allele_counts.validated_subset.${BLOCK}.txt}
    done
  done

```

#4. Generate the synthetic genomes:
###Autosomes or Xchr.
```{bash}

#This should only be performed once (for each N_BOOT size). The same coordinates will be carried over to other analyses (low and high recombination, etc.).
N_BOOT=1000 #100 #1000
REGION="Xchr" #autosomes or Xchr
cd /share/rdata/ramon.pouso/bootstrap/block_beds_${REGION}
#BLOCK_N=$(ll -rth bl*.bed | wc -l)
if [ "$REGION" == "autosomes" ]
  then 
  BLOCK_N=1090
elif [ "$REGION" == "Xchr" ]
  then 
  BLOCK_N=235
fi

#Generate a huge pool of genome blocks (50 of each):
rm ../blocks_${REGION}_bootstrap.list
for i in {1..50}
  do
  ls bl*.bed >> ../blocks_${REGION}_bootstrap.list #List each block 50 times to generate the pool for the randomisation
  done
sed -i -e 's/.bed/.txt/g' ../blocks_${REGION}_bootstrap.list

cd /share/rdata/ramon.pouso/bootstrap/
#$BLOCK_N blocks from the pool will be drawn randomly to generate a synthetic genome; this will be performed N_BOOT times in total:
mkdir -p bootstrapped_genomes_coordinates
for boot in $(seq 1 $N_BOOT)
  do
  #echo "drawing blocks for bootstrapped genome number" $boot
  shuf -n$BLOCK_N blocks_${REGION}_bootstrap.list > bootstrapped_genomes_coordinates/bootstrapped_genome_${REGION}_${boot}.list
  done

```

#5. Perform the bootstrap, obtain the bootstrap error, and relativise it.
##Derived allele counts.
###Empirical data average and error:
####Autosomes/Xchr:
```{bash}

REGION="autosomes" #autosomes or Xchr
cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/$REGION/block_counts/

#First, generate some headers and info files (this should only be performed once):
head -n1 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) > pool_headers.txt #Retrieve headers for files with pools
printf 'Pb\n%.0s' {1..6} > pop_codes.txt #then generate the population column content
printf 'lines\n%.0s' {1..2} >> pop_codes.txt
tail -n+2 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) | cut -f-2 > pool_gen.txt #Retrieve first 2 columns with pool data

#Next, obtain the population average and sampling error (standard error) for the empirical data
##Average:
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt)))) > /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.empirmean.txt

tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.empirmean.txt | cut -f-2 > pop_gen.txt

##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",0); printf("%.3f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.3f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt)))) > /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.empirerror.txt

```

####Whole-genome:
```{bash}

REGION="whole-genome"
cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/$REGION/
head -n1 <$(ls ../autosomes/block_counts/counts_pool_gen0-140_autosomes_summary.bl*.txt | head -n1) > pool_headers.txt #Retrieve headers for files with pools
printf 'Pb\n%.0s' {1..6} > pop_codes.txt #then generate the population column content
printf 'lines\n%.0s' {1..2} >> pop_codes.txt
tail -n+2 <$(ls ../autosomes/block_counts/counts_pool_gen0-140_autosomes_summary.bl*.txt | head -n1) | cut -f-2 > pool_gen.txt #Retrieve first 2 columns with pool data

#First combine the autosomal and Xchr counts:
cat pool_headers.txt <(paste pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_autosomes_summary.txt) <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_Xchr_summary.txt))) > /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt

#Next, obtain the population average and sampling error (standard error):
##Average:
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt)))) > /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.empirmean.txt

tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.empirmean.txt | cut -f-2 > pop_gen.txt

##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",0); printf("%.3f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.3f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.txt)))) > /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.empirerror.txt

```

####Valid SNPs subset:
```{bash}

REGION="autosomes" #autosomes or Xchr
cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/$REGION/block_counts/

#First, generate some headers and info files (this should only be performed once):
head -n1 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) > pool_headers.txt #Retrieve headers for files with pools
printf 'Pb\n%.0s' {1..6} > pop_codes.txt #then generate the population column content
printf 'lines\n%.0s' {1..2} >> pop_codes.txt
tail -n+2 <$(ls counts_pool_gen0-140_${REGION}_summary.bl*.txt | head -n1) | cut -f-2 > pool_gen.txt #Retrieve first 2 columns with pool data

#Next, obtain the population average and sampling error (standard error) for the empirical data
##Average:
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt)))) > /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.validated_subset.empirmean.txt

tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.validated_subset.empirmean.txt | cut -f-2 > pop_gen.txt

##Standard error: sqrt(variance(N)/N); we'll be using the N-1 version of the variance formula.
cat pool_headers.txt <(paste pop_codes.txt <(cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",0); printf("%.3f\n",0);}}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt) | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2","i] += $i; sumsq[$2","i]+=$i*$i;}} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",(((sumsq[p","i]-sum[p","i]*sum[p","i]/N[p])/(N[p]-1))/N[p])**0.5); printf("%.3f\n",(((sumsq[p","NF]-sum[p","NF]*sum[p","NF]/N[p])/(N[p]-1))/N[p])**0.5); }}' <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_summary.validated_subset.txt)))) > /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_${REGION}_average.validated_subset.empirerror.txt

```

###Synthetic genomes counts:
```{bash}


!!! FOR THE LINES USE ONLY THE STANDARD ERROR BETWEEN LINES. FOR PB USE THE BOOTSTRAPPED ERROR. SEE "Reunión telemática purga" EMAIL FROM 31/5/22.


N_BOOT=1000 #100 #1000
mkdir -p /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/whole-genome/
cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/

#Next, generate several bootstrapped w-g counts by adding the counts of 1090 autosomal and 235 Xchr blocks pulled at random from the pool, and obtain the population averages:
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  #Autosomes:
  cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/autosomes/block_counts/
  ##First, edit the filenames of the input blocks so that they match the current variables:
  echo "generating autosomal counts for bootstrapped genome number" $boot
  sed -e 's/^/counts_pool_gen0-140_autosomes_summary./' /share/rdata/ramon.pouso/bootstrap/bootstrapped_genomes_coordinates/bootstrapped_genome_autosomes_${boot}.list > bootstrapped_genome_autosomes_${boot}.list
  ##Next, generate the counts for each bootstrapped genome:
  paste pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' $(cat bootstrapped_genome_autosomes_${boot}.list) | tail -n+2) > counts_pool_gen0-140_autosomes_summary.boot_${boot}.txt

  #Xchr:
  cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/Xchr/block_counts/
  ##First, edit the filenames of the input blocks so that they match the current variables:
  echo "generating Xchr counts for bootstrapped genome number" $boot
  sed -e 's/^/counts_pool_gen0-140_Xchr_summary./' /share/rdata/ramon.pouso/bootstrap/bootstrapped_genomes_coordinates/bootstrapped_genome_Xchr_${boot}.list > bootstrapped_genome_Xchr_${boot}.list
  ##Next, generate the counts for each bootstrapped genome:
  paste pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' $(cat bootstrapped_genome_Xchr_${boot}.list) | tail -n+2) > counts_pool_gen0-140_Xchr_summary.boot_${boot}.txt
  
  ##Whole-genome (combine autosomes and Xchr):
  cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/
  paste whole-genome/pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' autosomes/block_counts/counts_pool_gen0-140_autosomes_summary.boot_${boot}.txt Xchr/block_counts/counts_pool_gen0-140_Xchr_summary.boot_${boot}.txt) > whole-genome/counts_pool_gen0-140_whole-genome_summary.boot_${boot}.txt
  
  #Next, obtain the population average for each bootstrap:
  cd whole-genome/
  echo "calculating population averages for bootstrapped genome number" $boot
  cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_whole-genome_summary.boot_${boot}.txt | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_whole-genome_summary.boot_${boot}.txt) > counts_pool_gen0-140_whole-genome_average.boot_${boot}.txt #(sum["ki."i]/N["ki"]) to relativise by Kirov
  done


cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/whole-genome
#Next, obtain the population average of derived counts across bootstrapped genomes, but first store the correct files for the current $BOOT_N in an input list, so that only those (and not those from other bootstraps) are called:
ls -v counts_pool_gen0-140_whole-genome_average.boot_*[[:digit:]]*.txt | awk -v nboot="$N_BOOT" -F"_|\\\\." '$7 <= nboot {print $0}' > counts_pool_gen0-140_whole-genome_average.Nboot_${N_BOOT}.list

cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=2;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=2;i<=NF;i++) printf "%.1f\t ",total[j","i]/nboot; print "";}}' $(<counts_pool_gen0-140_whole-genome_average.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_whole-genome_average.bootmean.txt


N_BOOT=1000
TOTAL=0
touch kaka.txt
LIST=$(cat counts_pool_gen0-140_whole-genome_average.Nboot_${N_BOOT}.list)
for BLOCK in ${LIST[@]}
  do
  echo $BLOCK
  CURRENT=$(head -n1 $BLOCK | cut -f2 | cut -d'.' -f1)
  echo $CURRENT >> kaka.txt
  TOTAL=$((TOTAL+CURRENT))
  done
echo $TOTAL



#sed 's/ 0.0/ 1.1/g' OR sed 's/\t0.0/\t1.1/g'
#^ use this to remove 0s

#Next, obtain the bootstrap error of derived counts across bootstrapped genomes. The bootstrap error is the standard deviation of the N bootstraps, so it can be obtained as the sqrt(var(N)). We'll be using the N-1 version of the variance formula:
cat pool_headers.txt <(paste pop_gen.txt <(awk -v nboot="$N_BOOT" '{for (i=2;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END{for (j=1;j<=FNR;j++) {for (i=2;i<=NF;i++) printf "%.5f\t",((sumsq[j","i]-total[j","i]*total[j","i]/nboot)/(nboot-1))**0.5; print "";}}' $(<counts_pool_gen0-140_whole-genome_average.Nboot_${N_BOOT}.list))) > counts_pool_gen0-140_whole-genome_average.booterror.txt

#Since averages are different between the empirical data and the bootstrap, we need to correct the errors. 
##As a first step, the empirical means should be divided by the bootstrap means to obtain the correction factor for the bootstrap errors:
cat pool_headers.txt <(paste <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_whole-genome_average.empirmean.txt) <(tail -n+2 counts_pool_gen0-140_whole-genome_average.bootmean.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i/$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_whole-genome_average.bootcorrectionfactor.txt
##Then the errors can be multiplied by the correction factors in order to obtain the expected errors for the empirical means:
cat pool_headers.txt <(paste <(tail -n+2 counts_pool_gen0-140_whole-genome_average.bootcorrectionfactor.txt) <(tail -n+2 counts_pool_gen0-140_whole-genome_average.booterror.txt) | awk '{h=NF/2;for (i=3;i<=h;i++) $i=$i*$(i+h);NF=h};1' | tr " " "\t") > counts_pool_gen0-140_whole-genome_average.booterrorcorrected.txt


#Per population adequate error: Eglobal(M) = [EB^2(M) + ET^2(M)]^0.5 where EB is the per population mean of the (corrected) bootstrap error, and ET is the per population empirical standard error (sampling error).
cat pool_headers.txt <(paste pop_gen.txt <(awk '{for (i=3;i<=NF;i++) {total[FNR","i]+=$i; sumsq[FNR","i]+=$i*$i; }} END {for (j=1;j<=FNR;j++) {for (i=3;i<NF;i++) printf "%.8f\t",(sumsq[j","i])**0.5; printf "%.8f\n",(sumsq[j","NF])**0.5;}}' <(tail -n+2 counts_pool_gen0-140_whole-genome_average.booterrorcorrected.txt) <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_whole-genome_average.empirerror.txt))) > counts_pool_gen0-140_whole-genome_average.totalerror.txt

#Per population mixed error: booterrorcorrected for the PB (actually, it would be the total error, but the empirical here is 0 since only one population is considered), and empirerror for the lines (because repetition already accounts for the evolutionary error, thus the bootrstrap is redundant).
cat pool_headers.txt <(tail -n+2 counts_pool_gen0-140_whole-genome_average.booterrorcorrected.txt | awk '$1=="Pb"') <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_whole-genome_average.empirerror.txt | awk '$1=="lines"') > counts_pool_gen0-140_whole-genome_average.adequateerror.txt


#In order to relativise by the Pb-000 population average, divide both the population average and the total error by the Pb-000 empirical population averages:
##Empirical population averages divided by the empirical Pb-000 population average:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_whole-genome_average.empirmean.txt | cut -f3-) <(tail -n+2 /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_whole-genome_average.empirmean.txt | cut -f3-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > counts_pool_gen0-140_whole-genome_average.empirmean_Pb-000_rel.txt
##Total error:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_whole-genome_average.empirmean.txt | cut -f3-) <(tail -n+2 counts_pool_gen0-140_whole-genome_average.totalerror.txt | cut -f3-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > counts_pool_gen0-140_whole-genome_average.totalerror_Pb-000_rel.txt
##Adequate error:
cat pool_headers.txt <(paste pop_gen.txt <(cat <(grep 'gen0' /share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_whole-genome_average.empirmean.txt | cut -f3-) <(tail -n+2 counts_pool_gen0-140_whole-genome_average.adequateerror.txt | cut -f3-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > counts_pool_gen0-140_whole-genome_average.adequateerror_Pb-000_rel.txt


#Other files can also be relativised:
##Empirical errors divided by the empirical Kirov population average:
cat pop_headers.txt <(paste pops.txt <(cat <(grep 'ki' ../../../${CALLING}_ann_population_average_${VAR}_${TYPE}.empirmean.txt | cut -f2-) <(tail -n+2 ../../../${CALLING}_ann_population_average_${VAR}_${TYPE}.empirerror.txt | cut -f2-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > ../../../${CALLING}_ann_population_average_${VAR}_${TYPE}.empirerror_ki_rel.txt
##Bootstrap errors divided by the empirical Kirov population average:
cat pop_headers.txt <(paste pops.txt <(cat <(grep 'ki' ../../../${CALLING}_ann_population_average_${VAR}_${TYPE}.empirmean.txt | cut -f2-) <(tail -n+2 ${CALLING}_ann_population_average_${VAR}_${TYPE}.booterror.txt | cut -f2-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > ${CALLING}_ann_population_average_${VAR}_${TYPE}.booterror_ki_rel.txt
##Bootstrap corrected errors divided by the empirical Kirov population average:
cat pop_headers.txt <(paste pops.txt <(cat <(grep 'ki' ../../../${CALLING}_ann_population_average_${VAR}_${TYPE}.empirmean.txt | cut -f2-) <(tail -n+2 ${CALLING}_ann_population_average_${VAR}_${TYPE}.booterrorcorrected.txt | cut -f2-) | column -t |
awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > ${CALLING}_ann_population_average_${VAR}_${TYPE}.booterrorcorrected_ki_rel.txt

```

###Synthetic genomes counts (valid SNP subset):
```{bash}

N_BOOT=1000 #100 #1000
mkdir -p /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/whole-genome/
cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/

#Next, generate several bootstrapped w-g counts by adding the counts of 1090 autosomal and 235 Xchr blocks pulled at random from the pool, and obtain the population averages:
for boot in $(seq 1 $N_BOOT) #100 (4mins) #1000
  do
  #Autosomes:
  cd /share/rdata/ramon.pouso/bootstrap/derived_allele_counts/autosomes/block_counts/
  ##First, edit the filenames of the input blocks so that they match the current variables:
  echo "generating autosomal counts for bootstrapped genome number" $boot
  sed -e 's/^/counts_pool_gen0-140_autosomes_summary.validated_subset./' /share/rdata/ramon.pouso/bootstrap/bootstrapped_genomes_coordinates/bootstrapped_genome_autosomes_${boot}.list > bootstrapped_genome_autosomes_${boot}.validated_subset.list
  ##Next, generate the counts for each bootstrapped genome:
  paste pool_gen.txt <(awk '{for (i=3;i<=NF;i++) total[FNR","i]+=$i;} END{for (j=1;j<=FNR;j++) {for (i=3;i<=NF;i++) printf "%s\t",total[j","i]; print "";}}' $(cat bootstrapped_genome_autosomes_${boot}.validated_subset.list) | tail -n+2) > counts_pool_gen0-140_autosomes_summary.validated_subset.boot_${boot}.txt
  cat <(gawk '!($1~/sample/) {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.9f\t",sum[p"."i]/N[p]); printf("%.9f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_autosomes_summary.validated_subset.boot_${boot}.txt | sort -t n -k2,2g) <(gawk '$1~/sample/ {N[$2]++; for (i=3;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=3;i<NF;i++) printf("%.9f\t",sum[p"."i]/N[p]); printf("%.9f\n",sum[p"."NF]/N[p]);}}' counts_pool_gen0-140_autosomes_summary.validated_subset.boot_${boot}.txt) > counts_pool_gen0-140_autosomes_average.validated_subset.boot_${boot}.txt
  done

```

#6: Download files:
##Derived allele counts.
```{bash}

#Empirical mean relativised by Pb:
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/bootstrap/derived_allele_counts/whole-genome/counts_pool_gen0-140_whole-genome_average.empirmean_Pb-000_rel.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap
#Total error relativised by Pb:
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/bootstrap/derived_allele_counts/whole-genome/counts_pool_gen0-140_whole-genome_average.totalerror_Pb-000_rel.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap
#Adequate error relativised by Pb:
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/bootstrap/derived_allele_counts/whole-genome/counts_pool_gen0-140_whole-genome_average.adequateerror_Pb-000_rel.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap
#Empirical error:
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/counts/sites_in_0-140_VCF/pools_counts/gen0-140/key_categories/counts_pool_gen0-140_whole-genome_average.empirerror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap
#Bootstrap error:
scp ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/bootstrap/derived_allele_counts/whole-genome/counts_pool_gen0-140_whole-genome_average.booterror.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap

```

#7. Plot counts.
##Derived count ratios (relative to 4fold and Pb-000):
###Sites in Pb-000:
####Double ratio:
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "autosomes" #autosomes #Xchr #whole-genome

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/sites_in_Pb000/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))


pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.Pb-000_4fold_rel.empirmean.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation)) + 83
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)
pool_counts <- pool_counts %>% setNames(gsub("_D","",names(.)))

# pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_counts_4FR
pool_counts_tidy <- pool_counts %>% gather(ratio,value,-generation,-population,factor_key=T)

pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.Pb-000_4fold_rel.adequateerror.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.))) %>% filter(generation!="gen5")
#pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
#names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation)) + 83
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)
pool_errors <- pool_errors %>% setNames(gsub("_D","",names(.)))
pool_errors[c(1),c(4:6)] <- NA

# pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
# pool_errors_4FR
pool_errors_tidy <- pool_errors %>% gather(ratio,value,-generation,-population,factor_key=T)

# combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
# colnames(combined_tidy) <- c("population","generation","ratio","mean","error")
combined_tidy_nonewmut <- left_join(pool_counts_tidy,pool_errors_tidy,by=c("population","generation","ratio"))
colnames(combined_tidy_nonewmut) <- c("population","generation","ratio","mean","error")

#Combined version (Pb):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy_nonewmut,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy_nonewmut$generation),limits = c(levels(combined_tidy_nonewmut$generation)[1],"skip",levels(combined_tidy_nonewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_nonewmut$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Excluding new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=10,colour="black"),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,0),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot
#ggsave(paste0("Pb_lines_relativised_pool_counts_copies_adequateerrors_4FR_",type,".bootstrap.pdf"), width=12, height=9, units="cm", device="pdf", path=wd_path)


#Paper versions:
##Various colours:
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_nonewmut_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy_nonewmut,ratio!="fourfold",ratio!="tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_discrete(breaks = levels(combined_tidy_nonewmut$generation),limits = c(levels(combined_tidy_nonewmut$generation)[1],"skip",levels(combined_tidy_nonewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_nonewmut$generation)[5])) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Excluding new mutation") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_text(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,0),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_nonewmut_relativised_pool_counts_copies_errors_4FR_ggplot

##Two colours:
combined_tidy_nonewmut_bis <- combined_tidy_nonewmut
combined_tidy_nonewmut_bis$generation <- as.numeric(as.character(combined_tidy_nonewmut_bis$generation))
combined_tidy_nonewmut_bis$ratio <- factor(combined_tidy_nonewmut_bis$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))
#Combined with the version without new mutation (obtained in the bootstrap.Rmd script):
Pb_lines_nonewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis <- ggplot(data=filter(combined_tidy_nonewmut_bis,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(6),linewidth=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(6)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative to Pb-083 4-fold syn.") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy_nonewmut$generation),limits = c(levels(combined_tidy_nonewmut$generation)[1],"skip",levels(combined_tidy_nonewmut$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy_nonewmut$generation)[5])) +
  scale_shape_manual(values=c(16,18)) +
  ylim(0.6,1.2) +
  ggtitle("Excluding new mutation") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_text(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0.5,0),"cm"),
        plot.title=element_text(hjust=0.5),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_nonewmut_relativised_pool_counts_copies_errors_4FR_ggplot_bis

```

####OLD: Gen0-140 pools Pb and line averages (combined version):
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "whole-genome" #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))



pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.empirmean_Pb-000_rel.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.)))
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_4FR


pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.totalerror_Pb-000_rel.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.)))
pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_4FR

combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
colnames(combined_tidy) <- c("population","generation","ratio","mean","error")

#Combined version (Pb):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy,ratio!="fourfold", generation!=5), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count\n relative to 4-fold syn. and Pb-000") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Pools") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_errors_4FR_",type,".bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

####OLD: Gen0-140 pools Pb booterror and line averages empirerror (combined version):
```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

type <- "whole-genome" #autosomes #Xchr

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/Analisis_dani/bootstrap/")
#codes_dictionary <- read_tsv(paste0(wd_path,"pop_codes_dictionary.txt"),col_names=c("old","population"))



pool_counts <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.empirmean_Pb-000_rel.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.)))
#pool_counts <- left_join(pool_counts,codes_dictionary,by=c("sample"="old"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","lines"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_4FR


pool_errors <- read_tsv(paste0(wd_path,"counts_pool_gen0-140_",type,"_average.adequateerror_Pb-000_rel.txt")) %>% select(.,sample,generation,contains("_D")) %>% rename_at(vars("sample"),funs(gsub("sample","population",.)))
pool_errors <- cbind(pool_errors,pool_counts$fourfold_D)
names(pool_errors)[names(pool_errors) == 'pool_counts$fourfold_D'] <- 'counts_fourfold_D'
#pool_errors <- left_join(pool_errors,codes_dictionary,by=c("population"="old"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","lines"))
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_4FR <- pool_errors %>% mutate(fourfold=fourfold_D/counts_fourfold_D,tolerated=tolerated_D/counts_fourfold_D,deleterious=deleterious_D/counts_fourfold_D,LoF=LoF_D/counts_fourfold_D) %>% select(!contains("_D")) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_4FR

combined_tidy <- left_join(pool_counts_4FR,pool_errors_4FR,by=c("population","generation","ratio"))
colnames(combined_tidy) <- c("population","generation","ratio","mean","error")

#Combined version (Pb):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot <- ggplot(data=filter(combined_tidy,ratio!="fourfold", generation!=5), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, colour=generation, group=population), position=position_dodge(0.8),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=population),size=2,position=position_dodge(0.8)) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count\n relative to 4-fold syn. and Pb-000") +
  scale_y_continuous(breaks = seq(0.6, 1.0, by = 0.1)) +
  scale_shape_manual(values=c(1,16)) +
  ylim(0.6,1.2) +
  ggtitle("Pools") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot
ggsave(paste0("Pb_lines_relativised_pool_counts_copies_adequateerrors_4FR_",type,".bootstrap.pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```