---
title: "fast_inbreeding_analysis"
output: html_document
date: "2022-11-16"
---


This is the re-made script for the fast inbreeding project (after the original was lost). It keeps all the logic and steps from the original script (which are necessary for the processing and analysis of the fast inbreeding files), but with less detail. Unless otherwise specified, all contents will be included in the following path: /share/rdata2/dani_k/consanguinidad_rapida

#1. Process raw reads:
##Check copy process:
```{R, engine='bash'}

cd /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/

#Run md5sum on all .tar files. Then do:
cat *md5 > md5sum_summary.txt

#Do the same in the source directory. Check that both md5sum_summary.txt files are identical.

```

##Uncompress files:
```{R, engine='bash'}

cd /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/

tar -xvf *.tar

```


##Rename FASTQ files:
###sample_names_dictionary.txt
```{R, engine='bash'}

14SE1002    pool01_gen0
14SE1004    pool02_gen0
14SE1005    pool03_gen0
14SE1008    pool04_gen0
14SE1010    pool05_gen0
0_14    pool06_gen0
0_35    pool07_gen0
0_11V   pool08_gen0
0_8   pool09_gen0
0_11    pool10_gen0
14SE1016    pool01_gen6
14SE1018    pool02_gen6
14SE1019    pool03_gen6
14SE1022    pool04_gen6
14SE1024    pool05_gen6
6_14    pool06_gen6
6_35    pool07_gen6
6_11V   pool08_gen6
6_8   pool09_gen6
6_11    pool10_gen6

```

###Rename folders and FASTQ files:
```{R, engine='bash'}

cd /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/

while read OLD NEW;
  do
  mv Sample_${OLD} Sample_${NEW}
  cd Sample_${NEW}
  #cd Sample_${OLD} #
  #echo Sample_${NEW} #
  OLD_FILES=$(ls ${OLD}*.fastq.gz)
  for file in ${OLD_FILES[@]}
    do
    mv $file ${file/$OLD/$NEW}
    #echo ${file/$OLD/$NEW} #
    done
  cd /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/
  done < sample_names_dictionary.txt
  
```


##Check fastqc quality:
###fastqc_reports.sh
```{R, engine='bash'}

module load fastqc/0.11.8

FOLDER=$(ls -d */ | cat -n | awk -v id=$SGE_TASK_ID -F "\t" '{if ($1==id) printf ("%s\n", $2)}')
cd $FOLDER

for file in $(ls *.fastq.gz)
  do
  echo $file
  fastqc $file
  done

```

###Send parallel array-jobs:
```{R, engine='bash'}

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/fastqc_reports.sh

```


##Trim reads:
###erne_trim.sh
```{R, engine='bash'}

module load erne/2.1.1

cd /DATA/rdata2/dani_k/consanguinidad_rapida/FASTQ/
FASTQ_LIST=$(ls ./*/*.fastq.gz | rev | cut -d'_' -f3- | rev | sort | uniq)
for sample in ${FASTQ_LIST[@]}
  do
  echo "${sample}"
  FOLDER=$(echo "${sample}" | cut -d"/" -f2)
  cd /DATA/rdata2/dani_k/consanguinidad_rapida/FASTQ/$FOLDER
  FASTQ=$(echo "${sample}" | cut -d"/" -f3)
  erne-filter --min-size 36 --query1 "${FASTQ}_R1_001.fastq.gz" --query2 "${FASTQ}_R2_001.fastq.gz" --output-prefix "${FASTQ}_trimmed"
  done

#Save this code as: /DATA/rdata2/dani_k/consanguinidad_rapida/FASTQ/erne_trim.sh

```

###Send array-jobs:
```{R, engine='bash'}

#It seems like there is no need for adapter removal in this project, since this step was already performed by the team at the sequencing facility. On the other hand, reads need to be trimmed.

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/
qsub -cwd -l h=compute-0-9 /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/erne_trim.sh

```


##Compress reads:
###gzip_reads.sh
```{R, engine='bash'}

FOLDER=$(ls -d */ | cat -n | awk -v id=$SGE_TASK_ID -F "\t" '{if ($1==id) printf ("%s\n", $2)}')
cd $FOLDER

for file in $(ls *.fastq)
  do
  echo "Compressing $file"
  gzip $file
  done

#Save this code as: /DATA/rdata2/dani_k/consanguinidad_rapida/FASTQ/gzip_reads.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#Compress trimmed reads for storage purposes.

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/gzip_reads.sh

```


##Merge reads:
###merge_reads.sh
```{R, engine='bash'}

cd /DATA/rdata2/dani_k/consanguinidad_rapida/FASTQ
FOLDER=$(ls -d Sample_pool* | cat -n | awk -v id=$SGE_TASK_ID -F "\t" '{if ($1==id) printf ("%s\n", $2)}')
echo $FOLDER
cd $FOLDER
ADAPTER=$(ls ${FOLDER/Sample_/}*_trimmed_1.fastq.gz | head -n1 | cut -d'_' -f3)
cat ${FOLDER/Sample_/}*_trimmed_1.fastq.gz > ${FOLDER/Sample_/}_${ADAPTER}_Lmerged_trimmed_1.fastq.gz
cat ${FOLDER/Sample_/}*_trimmed_2.fastq.gz > ${FOLDER/Sample_/}_${ADAPTER}_Lmerged_trimmed_2.fastq.gz
cat ${FOLDER/Sample_/}*_trimmed_unpaired.fastq.gz > ${FOLDER/Sample_/}_${ADAPTER}_Lmerged_trimmed_unpaired.fastq.gz

#Save this code as: /DATA/rdata2/dani_k/consanguinidad_rapida/FASTQ/merge_reads.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#For each pool, merge all FASTQ files into a single file.

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/merge_reads.sh

```


##Align reads:
###bwa_mem_align_reads.sh
```{R, engine='bash'}

module load bwa/0.7.15
cd /DATA/rdata2/dani_k/consanguinidad_rapida/FASTQ

GEN=$1
FOLDER=$(ls -d Sample_pool*_$GEN | cat -n | awk -v id=$SGE_TASK_ID -F "\t" '{if ($1==id) printf ("%s\n", $2)}')
echo $FOLDER
cd $FOLDER
ADAPTER=$(ls ${FOLDER/Sample_/}*_trimmed_1.fastq.gz | head -n1 | cut -d'_' -f3)

echo "Aligning reads"
bwa mem -t 4 -M /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta.gz ${FOLDER/Sample_/}_${ADAPTER}_Lmerged_trimmed_1.fastq.gz ${FOLDER/Sample_/}_${ADAPTER}_Lmerged_trimmed_2.fastq.gz > /DATA/rdata2/dani_k/consanguinidad_rapida/BAM/${FOLDER/Sample_/}_trimmed_bwa.sam

#Save this code as: /DATA/rdata2/dani_k/consanguinidad_rapida/FASTQ/bwa_mem_align_reads.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#NOTE: I believe I actually launched it in two halves, each using 10 processors.
GEN="gen0" #"gen0" #"gen6"

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/FASTQ/bwa_mem_align_reads.sh $GEN

```


#2. Process aligned reads:
##Compress from SAM to BAM:
###sam_to_bam.sh
```{R, engine='bash'}

cd /DATA/rdata2/dani_k/consanguinidad_rapida/BAM
module load samtools/1.4.1

GEN=$1
SAM=$(ls pool*_${GEN}_trimmed_bwa.sam | head -n$SGE_TASK_ID | tail -n1)

samtools view -b -o ${SAM/.sam/.bam} $SAM

#Save this code as: /DATA/rdata2/dani_k/consanguinidad_rapida/BAM/sam_to_bam.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#For some reason that I don't remember, the path of this script starts with DATA instead of share. The actual working directory is the same, but I guess it was accessed from DATA due to environment or speed reasons. If this doesn't work, use sam_to_bam.1.sh instead, which is the same script but called from share instead of DATA.

GEN="gen0" #"gen0" #"gen6"

#Launch it as follows:
cd /DATA/rdata2/dani_k/consanguinidad_rapida/BAM/
qsub -cwd -l h=compute-0-9 -t 1-20 /DATA/rdata2/dani_k/consanguinidad_rapida/BAM/sam_to_bam.sh $GEN

```

##Sort BAMs:
###bam_sort.sh
```{R, engine='bash'}

cd /DATA/rdata2/dani_k/consanguinidad_rapida/BAM
module load samtools/1.4.1

BAM=$(ls pool*_trimmed_bwa.bam | head -n$SGE_TASK_ID | tail -n1)

samtools sort $BAM -o ${BAM/.bam/.sorted.bam}

#Save this code as: /DATA/rdata2/dani_k/consanguinidad_rapida/BAM/bam_sort.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#Same as the previous script, this one is launched from DATA instead of share.

#Launch it as follows:
cd /DATA/rdata2/dani_k/consanguinidad_rapida/BAM
qsub -cwd -l h=compute-0-9 -t 1-20 /DATA/rdata2/dani_k/consanguinidad_rapida/BAM/bam_sort.sh

```

##Index BAMs:
###bam_index.sh
```{R, engine='bash'}

module load samtools/1.4.1
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM

BAM=$(ls pool*_trimmed_bwa.sorted.bam | head -n$SGE_TASK_ID | tail -n1)

samtools index $BAM

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_index.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_index.sh

```

##Isolate BAMs:
###bam_isolate.sh
```{R, engine='bash'}

module load samtools/1.4.1
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM

BAM=$(ls pool*_trimmed_bwa.sorted.bam | head -n$SGE_TASK_ID | tail -n1)

samtools view -o ${BAM/.bam/.iso.bam} $BAM 2L 2R 3L 3R 4 X

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_isolate.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_isolate.sh

```

##Index isolated BAMs:
###bam_iso_index.sh
```{R, engine='bash'}

module load samtools/1.4.1
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM

BAM=$(ls pool*_trimmed_bwa.sorted.iso.bam | head -n$SGE_TASK_ID | tail -n1)

samtools index $BAM

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_iso_index.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_iso_index.sh

```

##Remove duplicate reads:
###bam_rmdup.sh
```{R, engine='bash'}

module load samtools/1.4.1
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM

BAM=$(ls pool*_trimmed_bwa.sorted.iso.bam | head -n$SGE_TASK_ID | tail -n1)

samtools rmdup $BAM ${BAM/.iso.bam/.iso_rmdup.bam}

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_rmdup.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_rmdup.sh

```

##Filter by mapping quality:
###bam_mapqual.sh
```{R, engine='bash'}

module load samtools/1.4.1
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM

BAM=$(ls pool*_trimmed_bwa.sorted.iso_rmdup.bam | head -n$SGE_TASK_ID | tail -n1)

samtools view -q $1 -o ${BAM/rmdup.bam/rmdup_mq$1.bam} $BAM

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_mapqual.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_mapqual.sh QUAL #replace QUAL by the minimum desired mapping quality (in this case, it's 30)

```

##Add read groups:
###bam_readgr.sh
```{R, engine='bash'}

module load java/jre/1.8.0_73
module load picard/2.14.0
module load samtools/1.4.1
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM

BAM=$(ls pool*_trimmed_bwa.sorted.iso_rmdup_mq30.bam | head -n$SGE_TASK_ID | tail -n1)
SAMPLE=$(echo $BAM | cut -d'_' -f-2)

picard AddOrReplaceReadGroups I=$BAM O=${BAM/.bam/_rg.bam} RGLB=$SAMPLE RGPL=Illumina RGPU=unk RGSM=$SAMPLE
samtools index ${BAM/.bam/_rg.bam}

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_readgr.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_readgr.sh

```

##Perform INDEL realignment:
###Obtain realignment targets:
####gatk_realign_target.sh
```{R, engine='bash'}

module load java/jre/1.8.0_73
module load GATK/3.8
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM

gatk -T RealignerTargetCreator -I multirealignment_bam.list -o multirealignment_target.list -R /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/BAM/gatk_realign_target.sh

```

####Send array-job:
```{R, engine='bash'}

#Note that /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta was already indexed before as part of another project. Otherwise it needs to be indexed before running this script.

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM/
ls pool*_trimmed_bwa.sorted.iso_rmdup_mq30_rg.bam > multirealignment_bam.list
qsub -cwd -l h=compute-0-9 /share/rdata2/dani_k/consanguinidad_rapida/BAM/gatk_realign_target.sh

```

###Perform multirealignment:
####gatk_multirealignment.sh
```{R, engine='bash'}

module load java/jre/1.8.0_73
module load GATK/3.8
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM

BAM=$(ls pool*_trimmed_bwa.sorted.iso_rmdup_mq30_rg.bam | head -n$SGE_TASK_ID | tail -n1)

java -Xmx4g -jar /share/apps/GATK/3.8/GenomeAnalysisTK.jar -T IndelRealigner -I $BAM -o ${BAM/.bam/_realigned.bam} -targetIntervals $1 -R /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/BAM/gatk_multirealignment.sh

```

####Send parallel array-jobs:
```{R, engine='bash'}

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/BAM/gatk_multirealignment.sh multirealignment_target.list #Pass as an additional argument the target list obtained with the previous script

```

##Isolate chromosomes:
###bam_chromosomes.sh
```{R, engine='bash'}

module load samtools/1.4.1
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM

CHR=$1
BAM=$(ls pool*_trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned.bam | head -n$SGE_TASK_ID | tail -n1)

samtools view -o chr$CHR/${BAM/.bam/.chr$CHR.bam} $BAM $CHR

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_chromosomes.sh

```

###Send parallel array-jobs:
```{R, engine='bash'}

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/BAM/bam_chromosomes.sh CHR #where CHR should be replaced with 2L, 2R, 3L, 3R or 4

```

##Perform qualimap analysis:
###Autosomes:
####qualimap_regions_autosomes.sh
```{R, engine='bash'}

module load qualimap/2.2.1
BAM=$(ls pool*trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned.bam | head -n$SGE_TASK_ID | tail -n1)
qualimap bamqc --java-mem-size=3G -c -bam $BAM -outdir qualimap_results/${BAM/.bam/.qualimap}/ -outfile ${BAM/.bam/_orthologs.autosomes.qualimap} -gff /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.autosomes.6field_bed
# $1 is the input bam, $2 is the name of the pdf output, $3 is the regions file (which can be a gff file or a 6-column bed file).
mv qualimap_results/${BAM/.bam/.qualimap}/genome_results.txt qualimap_results/${BAM/.bam/.qualimap}/${BAM/.bam/_orthologs.autosomes.qualimap.txt}

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/BAM/qualimap_regions_autosomes.sh

```

####Send parallel array-jobs:
```{R, engine='bash'}

#If necessary, obtain first the autosomes version of the whole-genome orthologous regions (/share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.6field_bed) by excluding the X chromosome.

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/BAM/qualimap_regions_autosomes.sh

```

###X chromosome:
####qualimap_regions_Xchr.sh
```{R, engine='bash'}

module load qualimap/2.2.1
BAM=$(ls pool*trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned.bam | head -n$SGE_TASK_ID | tail -n1)
qualimap bamqc --java-mem-size=3G -c -bam $BAM -outdir qualimap_results/${BAM/.bam/.qualimap}/ -outfile ${BAM/.bam/_orthologs.Xchr.qualimap} -gff /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.Xchr.6field_bed
# $1 is the input bam, $2 is the name of the pdf output, $3 is the regions file (which can be a gff file or a 6-column bed file).
mv qualimap_results/${BAM/.bam/.qualimap}/genome_results.txt qualimap_results/${BAM/.bam/.qualimap}/${BAM/.bam/_orthologs.Xchr.qualimap.txt}

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/BAM/qualimap_regions_Xchr.sh

```

####Send parallel array-jobs:
```{R, engine='bash'}

#If necessary, obtain first the Xchr version of the whole-genome orthologous regions (/share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.6field_bed) by keeping only the X chromosome.

#Launch it as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/BAM/
qsub -cwd -l h=compute-0-9 -t 1-20 /share/rdata2/dani_k/consanguinidad_rapida/BAM/qualimap_regions_Xchr.sh

```


#3. Perform the CRISP calling:
##Generate input BAMlist:
###List pools and their size:
```{R, engine='bash'}

pool01_gen0   30
pool02_gen0   30
pool03_gen0   30
pool04_gen0   30
pool05_gen0   30
pool06_gen0   30
pool07_gen0   30
pool08_gen0   30
pool09_gen0   30
pool10_gen0   30
pool01_gen6   28
pool02_gen6   30
pool03_gen6   30
pool04_gen6   30
pool05_gen6   25
pool06_gen6   30
pool07_gen6   30
pool08_gen6   30
pool09_gen6   30
pool10_gen6   34

#Store the lines above as: /share/rdata2/dani_k/consanguinidad_rapida/variants/sample_size_dictionary.txt

```

###Generate BAMlist for each chromosome:
```{R, engine='bash'}

cd /share/rdata2/dani_k/consanguinidad_rapida/variants

CHRLIST=(2L 2R 3L 3R X)

for CHR in ${CHRLIST[@]}
  do
  echo "CHR" $CHR
  if [ $CHR == "X" ]
    then
    PLOIDY=1
    else
    PLOIDY=2
  fi
  while read -r POOL SIZE
    do
    BAM=$(ls /share/rdata2/dani_k/consanguinidad_rapida/BAM/chr${CHR}/${POOL}_trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned.chr${CHR}.bam)
    echo -e "$BAM\tPS=$((SIZE*PLOIDY))" >> crisp_input_bam.chr${CHR}.list
    done < sample_size_dictionary.txt
  done

```

##Perform the calling:
###crisp_all_pools_chr.sh
```{R, engine='bash'}

module load crisp/1.0
cd /share/rdata2/dani_k/consanguinidad_rapida/variants

CHR=$1

CRISP --ref /share/rdata/ramon.pouso/reference/indexed_reference/dmel-all-chromosome-r6.14.fasta --VCF crisp_all_pools_gen0-6.chr${CHR}.vcf \
--bams crisp_input_bam.chr$CHR.list > crisp_all_pools_gen0-6.chr${CHR}.log

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_chr.sh

```

###Launch it for each chromosome:
```{R, engine='bash'}

#Launch this as follows:
cd /share/rdata2/dani_k/consanguinidad_rapida/variants
qsub -cwd -l h=compute-0-9 /share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_chr.sh CHR #where CHR should be replaced with 2L, 2R, 3L, 3R or X

```


#4. Combine and process the VCFs:
##Combine VCFs:
```{bash}

module load bcftools/1.9
module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata2/dani_k/consanguinidad_rapida/variants

#Concatenate all single chromosome VCFs into a single whole-genome one:
bcftools concat crisp_all_pools_gen0-6.chr*.vcf.gz > crisp_all_pools_gen0-6.all_sites.vcf

```

##Filter the combined VCF:
```{bash}

module load bcftools/1.9
module load gcc/7.2.0
module add gcc/7.2.0
module load vcftools/0.1.17

cd /share/rdata2/dani_k/consanguinidad_rapida/variants

#Keep only those sites within the previously selected orthologous regions.
bedtools intersect -a crisp_all_pools_gen0-6.all_sites.vcf -b /share/rdata/ramon.pouso/outgroups/orthologs/dmel_dsim_dyak_orthologs.db_coord_sorted_merged.bed -header > crisp_all_pools_gen0-6.all_sites.orthologs.confident.vcf

#Remove multialelic SNPs and indels, monomorphic SNPs, and SNPs in the close proximity of indels (10 bp).
bcftools filter --SnpGap 10 crisp_all_pools_gen0-6.all_sites.orthologs.confident.vcf | bcftools view -m2 -M2 -v snps -O v -o crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.vcf

#Mask repetitive regions
vcftools --vcf crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.vcf --exclude-bed /share/rdata/ramon.pouso/reference/indexed_reference/dmel-r6.14_mask.bed --recode --recode-INFO-all --out crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.vcf
mv crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.vcf.recode.vcf crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.vcf #fix bad output name from vcftools
#And edit some problematic spaces in the header (otherwise vcftools won't be able to deal with them later on):
sed -i 's/Description=" >/Description=">/g' crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.vcf

#Next, apply the high depth and EMfail filters. On the one hand, we'll retrieve all sites with depth higher than the average + 3SD for each pool (i.e., sites with depth ≥ 3SD in any pool will be excluded from all pools). On the other hand, we'll retrieve sites with the flag EMfail. Finally we'll filter all of them out from the VCF.
#Note that the unfiltered VCF is used as the source to detect unwanted SNPs.
rm crisp_all_pools_gen0-6_masked.recode_snps.gen0-6_all_sites.orthologs.confident.DP_EM_filter_raw.bed
touch crisp_all_pools_gen0-6_masked.recode_snps.gen0-6_all_sites.orthologs.confident.DP_EM_filter_raw.bed
##Extract sites with excess DP:
POP_LIST=$(bcftools query -l crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.vcf)
for POP in ${POP_LIST[@]}
  do
  echo $POP
  VCF_COL=$((9 + $(bcftools query -l crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.vcf | grep -n "^$POP" | cut -d':' -f1)))
  ###Autosomic:
  AVG_AUTO=$(grep "mean coverageData" /share/rdata2/dani_k/consanguinidad_rapida/BAM/qualimap_results/"$POP"_trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned.qualimap/"$POP"_trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned_orthologs.autosomes.qualimap.txt | awk -F"= |X" '{printf ("%s\n",$2)}')
  SD_AUTO=$(grep "std coverageData" /share/rdata2/dani_k/consanguinidad_rapida/BAM/qualimap_results/"$POP"_trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned.qualimap/"$POP"_trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned_orthologs.autosomes.qualimap.txt | awk -F"= |X" '{printf ("%s\n",$2)}')
  FILTER_AUTO=$(echo $AVG_AUTO + 3*$SD_AUTO | bc)
  grep -v '^#' crisp_all_pools_gen0-6.all_sites.orthologs.confident.vcf | cut -f-2,$VCF_COL | awk -v filter="$FILTER_AUTO" -F"\t|:" '{if ($1 != "X" && $5 >= filter) printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' >> crisp_all_pools_gen0-6_masked.recode_snps.gen0-6_all_sites.orthologs.confident.DP_EM_filter_raw.bed
  ###Xchr:
  AVG_X=$(grep "mean coverageData" /share/rdata2/dani_k/consanguinidad_rapida/BAM/qualimap_results/"$POP"_trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned.qualimap/"$POP"_trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned_orthologs.Xchr.qualimap.txt | awk -F"= |X" '{printf ("%s\n",$2)}')
  SD_X=$(grep "std coverageData" /share/rdata2/dani_k/consanguinidad_rapida/BAM/qualimap_results/"$POP"_trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned.qualimap/"$POP"_trimmed_bwa.sorted.iso_rmdup_mq30_rg_realigned_orthologs.Xchr.qualimap.txt | awk -F"= |X" '{printf ("%s\n",$2)}')
  FILTER_X=$(echo $AVG_X + 3*$SD_X | bc)
  grep -v '^#' crisp_all_pools_gen0-6.all_sites.orthologs.confident.vcf | cut -f-2,$VCF_COL | awk -v filter="$FILTER_X" -F"\t|:" '{if ($1 == "X" && $5 >= filter) printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' >> crisp_all_pools_gen0-6_masked.recode_snps.gen0-6_all_sites.orthologs.confident.DP_EM_filter_raw.bed
  done
##Extract sites with EMfail flag:
grep -v '^#' crisp_all_pools_gen0-6.all_sites.orthologs.confident.vcf | grep "EMfail" | awk -F"\t" '{printf ("%s\t%s\t%s\n", $1,$2-1,$2)}' >> crisp_all_pools_gen0-6_masked.recode_snps.gen0-6_all_sites.orthologs.confident.DP_EM_filter_raw.bed
##Sort sites and remove duplicates:
sort -k1,1 -k2,2n crisp_all_pools_gen0-6_masked.recode_snps.gen0-6_all_sites.orthologs.confident.DP_EM_filter_raw.bed | uniq > crisp_all_pools_gen0-6_masked.recode_snps.gen0-6_all_sites.orthologs.confident.DP_EM_filter_sorted.bed
##Finally, remove from the VCF all sites identified in these last few steps:
bedtools subtract -a crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.vcf -b crisp_all_pools_gen0-6_masked.recode_snps.gen0-6_all_sites.orthologs.confident.DP_EM_filter_sorted.bed -header > crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.vcf

```

#5. Two parsimony polarisation.
##README.
```{bash}

#This section will extract the ancestral state as that common to both simulans and yakuba. Sites which do not comply with this criterion will be excluded from the analysis.

```

##Extract outgroup state:
```{R, engine='bash'}

module load gcc/7.2.0
module add gcc/7.2.0

#Extract the outgroup state for sites in the final VCF:
##Simulans:
cd /share/rdata/ramon.pouso/outgroups/simulans/3processed
bedtools getfasta -fi bwa_simulans_iso_rmdup_mq30_rg_multirealigned_major.fasta -bed <(grep -v '^#' /share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.vcf | awk -F "\t" '{printf ("%s\t%s\t%s\n", $1,$2-1,$2)}') -tab > bwa_simulans_iso_rmdup_mq30_rg_multirealigned_major.variants.txt
awk -F"\t|:|-" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' bwa_simulans_iso_rmdup_mq30_rg_multirealigned_major.variants.txt > bwa_simulans_iso_rmdup_mq30_rg_multirealigned_major.variants.bed
##Yakuba:
cd /share/rdata/ramon.pouso/outgroups/yakuba/3processed
bedtools getfasta -fi bwa_yakuba_iso_rmdup_mq30_rg_multirealigned_major.fasta -bed <(grep -v '^#' /share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.vcf | awk -F "\t" '{printf ("%s\t%s\t%s\n", $1,$2-1,$2)}') -tab > bwa_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.txt
awk -F"\t|:|-" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' bwa_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.txt > bwa_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.bed

#Combine info from both outgroups:
cd /share/rdata/ramon.pouso/outgroups/
bedtools intersect -a /share/rdata/ramon.pouso/outgroups/simulans/3processed/bwa_simulans_iso_rmdup_mq30_rg_multirealigned_major.variants.bed -b /share/rdata/ramon.pouso/outgroups/yakuba/3processed/bwa_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.bed -wa -wb | awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8)}' > bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.bed

#Keep only sites that match between the two species:
awk -F "\t" '($4==$5) {print $0}' bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.bed > bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match.bed

#Exclude sites with no info (N):
awk -F "\t" '($4!="N") {print $0}' bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match.bed > bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match_woutN.bed

#Keep only those sites which are inconsistent between the outgroup state and the REF state from the VCF (i.e., those for which the REF allele in the VCF does not match the ancestral state), and at the same time consistent with the ALT state (i.e., otherwise we're dealing with sites that are triallelic across the outgroups plus the focal species):
bedtools intersect -a bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match_woutN.bed -b <(grep -v '^#' /share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.vcf | awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$4,$5)}') -wa -wb | awk -F "\t" '($4!=$9 && $4==$10) {printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$9)}' > bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match_woutN.ref_inconsistent.bed #Column #4 in this file will be the ANC allele, and column #5 the REF allele.

```

##Generate ancestral state fasta reference.
###Transform reference fasta to tab format:
```{bash}

cd /share/rdata/ramon.pouso/reference/indexed_reference/

#Transform fasta to tab (not really tab separated, only the last column) format to ease the editing.
/share/rdata/ramon.pouso/seqkit fx2tab dmel-all-chromosome-r6.14.fasta > dmel-all-chromosome-r6.14.tab

```

###two_parsimony_ancestral_fasta.sh
```{bash}

#Run it as follows: qsub -cwd -l h=compute-0-9 -t 1-5 /share/rdata/ramon.pouso/reference/indexed_reference/two_parsimony_ancestral_fasta.sh

cd /share/rdata/ramon.pouso/reference/indexed_reference/

#Retrieve scaffold corresponding to the current array level:
CHROMOSOME=`sed -n ${SGE_TASK_ID}p <(cut -f1 /share/rdata/ramon.pouso/outgroups/bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match_woutN.ref_inconsistent.bed | sort | uniq)`

#Generate input files:
##Bed with to-change alleles for the scaffold:
echo "generating input file for chromosome" $CHROMOSOME
awk -v chr=$CHROMOSOME '$1==chr' /share/rdata/ramon.pouso/outgroups/bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match_woutN.ref_inconsistent.bed > /share/rdata/ramon.pouso/outgroups/bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match_woutN.ref_inconsistent.chr${CHROMOSOME}.bed
##Tab-reference for the scaffold:
grep -w "ID=$CHROMOSOME;" dmel-all-chromosome-r6.14.tab > ${CHROMOSOME}.two_parsimony_ancestral-r6.14.tab

#Next, edit the melano fasta in order to generate the ancestral fasta:
##First loop over the inconsistent variants (those for which the polarisation is the reverse), grep the scaffold which they belong to, edit the base, and use that file as the input for the next variant in the same scaffold:
COUNTER=0
TOTAL=$(wc -l < /share/rdata/ramon.pouso/outgroups/bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match_woutN.ref_inconsistent.chr${CHROMOSOME}.bed)
echo "editing fasta for chromosome" $CHROMOSOME
while read -r SCAFFOLD START STOP ANCESTRAL REFERENCE; do
  #Print the sequence replacing only the current variant, and replace the previous input with this output:
  awk -v stop=$STOP -v ancestral=$ANCESTRAL -F"\t" '{printf ("%s\t%s%s%s\n", $1,substr($2,1,stop-1),ancestral,substr($2,stop+1))}' $SCAFFOLD.two_parsimony_ancestral-r6.14.tab > $SCAFFOLD.tmp && mv $SCAFFOLD.tmp $SCAFFOLD.two_parsimony_ancestral-r6.14.tab
  ((COUNTER++))
  if [ $(( $COUNTER % 500 )) == 0 ]
    then
    echo "processed $COUNTER sites out of $TOTAL"
  fi
 done < /share/rdata/ramon.pouso/outgroups/bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match_woutN.ref_inconsistent.chr${CHROMOSOME}.bed
touch chr${CHROMOSOME}.finished
echo "finished processing chromosome" $CHROMOSOME

```

###Combine all scaffolds back into the ancestral fasta:
```{bash}

cd /share/rdata/ramon.pouso/reference/indexed_reference/
#Check if the editing of the last scaffold is now complete, and if so, append all scaffolds to generate the new ancestral file (containing only the modified scaffolds).
if [ $(ls chr*.finished | wc -l) == 5 ]
  then
  cat *.two_parsimony_ancestral-r6.14.tab > two_parsimony_ancestral-all-chromosome-r6.14.tab
  else
  echo "keep waiting"
fi
#rm chr*.finished
#rm *.two_parsimony_ancestral-r6.14.tab

#Next, include all the other scaffolds, i.e. those that remained unchanged:
grep -v -w -f <(cat *.two_parsimony_ancestral-r6.14.tab | cut -d' ' -f1 | awk '{print "ID="$0";"}') dmel-all-chromosome-r6.14.tab | awk -F"\t" '{printf ("%s\t%s\n", $1,$2)}' >> two_parsimony_ancestral-all-chromosome-r6.14.tab #Check that it has 1870 lines, same as dmel-all-chromosome-r6.14.tab

#Next convert the file back to fasta format:
/share/rdata/ramon.pouso/seqkit tab2fx <(awk -F"\t| " '{printf ("%s\t%s\n",$1,$10)}' two_parsimony_ancestral-all-chromosome-r6.14.tab) > two_parsimony_ancestral-all-chromosome-r6.14.fa

#Finally, obtain the (bgzip) compressed version of the fasta, and its index file:
module load samtools/1.4.1 
/DATA/APPS/freebayes/25.03.19/SeqLib/htslib/bgzip -c two_parsimony_ancestral-all-chromosome-r6.14.fa > two_parsimony_ancestral-all-chromosome-r6.14.fa.gz
samtools faidx two_parsimony_ancestral-all-chromosome-r6.14.fa.gz


#Chech if it worked fine. Cols 3 and 4 should be identical, and different from cols 5 and 6, which should also be the same:
rm kaka.borrar
while read -r SCAFFOLD START STOP ANCESTRAL REFERENCE; do
  OLD=$(grep "ID=$SCAFFOLD;" dmel-all-chromosome-r6.14.tab | awk -F"\t" '{printf ("%s\n", $2)}' | cut -c$STOP)
  NEW=$(grep "$SCAFFOLD" two_parsimony_ancestral-all-chromosome-r6.14.tab | awk -F"\t" '{printf ("%s\n", $2)}' | cut -c$STOP)
  echo -e "$SCAFFOLD\t$STOP\t$REFERENCE\t$OLD\t$ANCESTRAL\t$NEW" >> kaka.borrar
 done < /share/rdata/ramon.pouso/outgroups/bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match_woutN.ref_inconsistent.bed
#Seems like all key positions have changed correctly, while random ones are still the same.

```

###Index the ancestral state fasta reference.
```{bash}

cd /share/rdata/ramon.pouso/reference/indexed_reference/
module load samtools/1.4.1

samtools faidx two_parsimony_ancestral-all-chromosome-r6.14.fa
samtools dict two_parsimony_ancestral-all-chromosome-r6.14.fa -o two_parsimony_ancestral-all-chromosome-r6.14.dict

```

##Carry out the VCF polarisation.
###Filter polarisable sites:
```{bash}

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata2/dani_k/consanguinidad_rapida/variants/

#Keep only SNPs with available ancestral inference.
bedtools intersect -a crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.vcf -b /share/rdata/ramon.pouso/outgroups/bwa_simulans_yakuba_iso_rmdup_mq30_rg_multirealigned_major.variants.simulans_yakuba_match_woutN.bed -header > crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.vcf

```

###Fill the ancestral allele data:
```{bash}

#Code to annotate the AA (ancestral alleles) subfield from the INFO field in the VCF.
module load vcftools/0.1.17 
module load samtools/1.4.1 
export PERL5LIB=/DATA/APPS/vcftools/0.1.17/lib/site_perl/5.24.1/

cat crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.vcf | fill-aa -a /share/rdata/ramon.pouso/reference/indexed_reference/two_parsimony_ancestral-all-chromosome-r6.14.fa.gz > crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.aafilled.vcf

```

###Polarise the AA-filled VCF:
```{bash}

module load bcftools/1.9
cd /share/rdata2/dani_k/consanguinidad_rapida/variants/

#Polarize the VCF:
FILE=kaka.aafilled.vcf #crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.aafilled.vcf
N_IND=$(bcftools query -l $FILE | wc -l)
ID_FIRST=$(bcftools query -l $FILE | head -n1)
N_FIRST=$(grep -v '##' $FILE | grep '#' | tr "\t" "\n" | grep -n $ID_FIRST | cut -d':' -f1)
grep -v '#' $FILE | awk -F"\t|AA=" '$4==$9' > ${FILE/.vcf/.consistent.vcf}
grep -v '#' $FILE | awk -F"\t|AA=" '$5==$9' | awk -F";AF=|;EMstats=" '{printf ("%s;AF=%s;EMstats=%s\n", $1,1-$2,$3)}' > ${FILE/.vcf/.inconsistent.vcf}
cut -f-$((N_FIRST-1)) ${FILE/.vcf/.inconsistent.vcf} | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$5,$4,$6,$7,$8,$9,$10)}' > ${FILE/.vcf/.inconsistent.polarized.vcf}
for col in $(seq $N_FIRST $((N_FIRST+N_IND-1)))
  do
  echo "processing individual in column number" $col
  paste ${FILE/.vcf/.inconsistent.polarized.vcf} <(cut -f$col ${FILE/.vcf/.inconsistent.vcf} | awk -F":|," '$1 == "\." {printf ("%s:%s:%s:%s,%s:%s,%s:%s,%s\n", $1,$2,$3,$5,$4,$7,$6,$9,$8)} $1 != "\." {printf ("%s,%s:%s:%s:%s,%s:%s,%s:%s,%s\n", $2,$1,$3,$4,$6,$5,$8,$7,$10,$9)}') > ${FILE/.vcf/.inconsistent.temp}
  mv ${FILE/.vcf/.inconsistent.temp} ${FILE/.vcf/.inconsistent.polarized.vcf} #if the first field of each individual is just a dot, define 9 columns and swap them accordingly; otherwise define 10 columns and swap them accordingly.
  done
cat <(grep '#' $FILE) ${FILE/.vcf/.consistent.vcf} ${FILE/.vcf/.inconsistent.polarized.vcf} | bcftools sort > ${FILE/.aafilled.vcf/.polarized.vcf}

#Note: the files named "polarisable_test" were created in the original version of this script (now lost). These files use the ancestral inference from the slow inbreeding project, obtained with est-sfs. The code to generate those (obsolete) files isn't included in this new version of the script.

```

#6. Carry out general annotation with ANNOVAR:
##Build the drosophila database.
###Good complete version (changes codes in the UCSC database).
```{R, engine='bash'}

cd /share/rdata/ramon.pouso/reference/indexed_reference/annovar_database/
mkdir two_parsimony_ancestral_dm6
cd two_parsimony_ancestral_dm6

#Note: any code involving annotate_variation.pl won't work because apparently the server blocks its attempts to download files from an external website, so I had to replace it with alternative code.

#The following commented section doesn't need to be repeated:
<!-- #First download, uncompress and rename the gene database: -->
<!-- wget https://hgdownload.cse.ucsc.edu/goldenPath/dm6/database/refGene.txt.gz -->
<!-- gunzip -c refGene.txt.gz > dm6_refGene.txt -->

<!-- #Next, download the chromosome names equivalence file (aka "alias" or "dictionary"), which we'll need to edit the gene database so that the scaffolds use the same nomenclature as our files: -->
<!-- wget https://hgdownload.cse.ucsc.edu/goldenPath/dm6/bigZips/dm6.chromAlias.txt -->
<!-- nano dm6.chromAlias.txt #edit it to add "mitochondrion_genome" in the fourth column for the row that starts with chrM. -->

<!-- #Then we can replace all database names with the UCSC names, which are used in our VCFs and fasta files. -->
<!-- DB_CODES=$(cut -f3 dm6_refGene.txt | sort | uniq) -->
<!-- for old_code in ${DB_CODES[@]} -->
<!--   do -->
<!--   new_code=$(awk -v old=$old_code '$1==old' /share/rdata/ramon.pouso/reference/indexed_reference/annovar_database/ancestral_dm6/dm6.chromAlias.txt | cut -f4) -->
<!--   echo "${old_code} -> ${new_code}" -->
<!--   sed -i -e "s/\<$old_code\>/$new_code/g" dm6_refGene.txt -->
<!--   done -->

<!-- diff <(cut -f-2,4- dm6_refGene.txt) <(cut -f-2,4- refGene.txt) #checks whether the previous loop modified any other field. Since no lines are returned, both files are identical (outside of the 3rd column, which was changed). -->

#The following has to be repeated, since the new polarisation means that the ancestral genome has changed:
#Copy the ancestral fasta (obtained in the polarisation.Rmd script) to the aproppriate folder:
scp -p /share/rdata/ramon.pouso/reference/indexed_reference/two_parsimony_ancestral-all-chromosome-r6.14.fa dm6_seq/dm6_ancestral_dmel-all-chromosome-r6.14.fa

#Next, use annovar to build the gene database:
module load annovar/4.19
retrieve_seq_from_fasta.pl dm6_refGene.txt -seqfile dm6_seq/dm6_ancestral_dmel-all-chromosome-r6.14.fa -format refGene -outfile dm6_refGeneMrna.fa

```

###Good non-redundant version (changes codes in the UCSC database).
```{R, engine='bash'}

#This version is a clone of the good complete version from which we'll remove all isoforms except for the longest one. Hence this is the "non-redundant" or "main isoforms" version of the annovar database, which we'll use to simplify the subsequent PROVEAN annotation.

#The following commented section doesn't need to be repeated:
<!-- #First, download the .gtf gene database from the UCSC: -->
<!-- cd /share/rdata/ramon.pouso/reference/indexed_reference/ -->
<!-- wget https://hgdownload.soe.ucsc.edu/goldenPath/dm6/bigZips/genes/dm6.refGene.gtf.gz -->
<!-- gunzip dm6.refGene.gtf.gz -->

<!-- #Then extract the list of transcripts, calculate their size, and keep the largest one for each chromosome. -->
<!-- awk -F"\t|gene_id |; transcript_id |;  gene_name " '($1 == "chr2L" || $1 == "chr2R" || $1 == "chr3L" || $1 == "chr3R" || $1 == "chr4" || $1 == "chrX") && $3=="transcript" {printf ("%s\t%s\t%s\t%s\n"),$1,$5-$4,$10,$11}' dm6.refGene.gtf | sed 's/"//g' | sort -k1,1 -k3,3 -k2,2nr | sort -k3,3 -u | sort -k1,1 -k3,3 > dm6nr.refGene.txt -->
<!-- grep -Ff <(cut -f4 dm6nr.refGene.txt) dm6.refGene.gtf > dm6nr.refGene.gtf -->

#Next, clone the previous ancestral database and rename it and some of its files to include the code "nr" (non-redundant):
cd /share/rdata/ramon.pouso/reference/indexed_reference/annovar_database/
#scp -pr two_parsimony_ancestral_dm6 nr_two_parsimony_ancestral_dm6
cd nr_two_parsimony_ancestral_dm6
mv dm6_seq dm6nr_seq
mv dm6nr_seq/dm6_ancestral_dmel-all-chromosome-r6.14.fa dm6nr_seq/dm6nr_ancestral_dmel-all-chromosome-r6.14.fa
mv dm6.chromAlias.txt dm6nr.chromAlias.txt
rm dm6_refGeneMrna.fa

#Then subset the dm6 annovar database so that only main isoforms are kept, and remove the original database.
grep -Ff <(cut -f4 /share/rdata/ramon.pouso/reference/indexed_reference/dm6nr.refGene.txt) dm6_refGene.txt > dm6nr_refGene.txt
rm dm6_refGene.txt

#Next, use annovar to build the gene database:
module load annovar/4.19
retrieve_seq_from_fasta.pl dm6nr_refGene.txt -seqfile dm6nr_seq/dm6nr_ancestral_dmel-all-chromosome-r6.14.fa -format refGene -outfile dm6nr_refGeneMrna.fa

```

##Annotate the VCFs.
###Non-redundant version.
```{R, engine='bash'}

module load annovar/4.19
module load gcc/7.2.0 
module add gcc/7.2.0 


cd /share/rdata2/dani_k/consanguinidad_rapida/variants/
FILE=crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.vcf
FILE=kaka.vcf
#First convert from VCF to table (annovar can't deal with the particular format of the pool. VCFs).
convert2annovar.pl -format vcf4old --outfile ${FILE/.vcf/.annovar} $FILE

#Next, annotate the table. The resulting file is automatically labelled as .vcf by the programme, even though it really isn't a VCF.
table_annovar.pl ${FILE/.vcf/.annovar} /share/rdata/ramon.pouso/reference/indexed_reference/annovar_database/nr_two_parsimony_ancestral_dm6 -vcfinput --outfile ${FILE/.vcf/.nr_annovar} -buildver dm6nr --protocol refGene --operation g

#Convert the annotated table to a .bed.
mv ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.vcf ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.tab
awk -F"\t|;ANNOVAR_DATE" '{printf ("%s\t%s\t%s\tANNOVAR_DATE%s\n"),$1,$2-1,$3,$9}' ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.tab > ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.bed

#Then intersect the polarized VCF with the annotated BED and edit it to obtain the annotated VCF:
grep '^#' $FILE > ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.vcf
bedtools intersect -a $FILE -b ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.bed -wb | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s;%s\n"),$1,$2-1,$2,$3,$4,$5,$6,$7,$8,$NF}' | bedtools intersect -a stdin -b $FILE -wb | cut -f1,3-9,18- >> ${FILE/.vcf/.nr_annovar}.dm6nr_multianno.vcf

```

#7. Carry out SIFT annotation:
##Install the programme and download the database.
```{R, engine='bash'}

#Doesn't need to be repeated:
<!-- https://sift.bii.a-star.edu.sg/sift4g/SIFT4G_codes.html -->
<!-- https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB#DBfromGTF -->

<!-- #I'm following instructions from https://sift.bii.a-star.edu.sg/sift4g/Commandline.html -->

<!-- mkdir -p /share/rdata/ramon.pouso/reference/indexed_reference/sift_database/ -->
<!-- cd /share/rdata/ramon.pouso/reference/indexed_reference/sift_database/ -->

<!-- #First download and uncompress the database. -->
<!-- wget https://sift.bii.a-star.edu.sg/sift4g/public//Drosophila_melanogaster/BDGP6.83.zip --no-check-certificate -->
<!-- jar xf BDGP6.83.zip #The unzipped folder will have three files for each chromosome: a compressed chromosome file (.gz); a regions file (.regions); a chromosome statistics file (.txt). -->

<!-- #Then download the jar file to execute the programme. -->
<!-- wget -P /share/rdata/ramon.pouso https://github.com/pauline-ng/SIFT4G_Annotator/raw/master/SIFT4G_Annotator.jar -->

```

##Generate custom ancestral drosophila database:
```{R, engine='bash'}

#I'm following instructions from: https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB#DBfromGTF

#The following commented lines don't need to be processed again:
<!-- #First, install sift4g: -->
<!-- cd $LUSTRE -->
<!-- mkdir -p sift4g_annotation -->
<!-- cd sift4g_annotation -->
<!-- git clone --recursive https://github.com/rvaser/sift4g.git sift4g -->
<!-- cd sift4g/ -->
<!-- make -->

<!-- #Next download the UniProt ref90 protein database: -->
<!-- cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/sift_prot_db -->
<!-- wget https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/uniref90.fasta.gz -->
<!-- gunzip uniref90.fasta.gz -->

<!-- #Next, copy the database-builder scripts: -->
<!-- git clone https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB.git scripts_to_build_SIFT_db -->
<!-- cd scripts_to_build_SIFT_db/test_files/ -->

<!-- #Create directory for the target species, and copy the target species files (reference fasta and annotation file): -->
<!-- mkdir -p nr_ancestral_dm6 -->
<!-- cd nr_ancestral_dm6 -->
<!-- #Put genomic fasta file in chr-src, and split it by chromosome: -->
<!-- mkdir -p chr-src -->

#First copy the previous database and rename it as "two_parsimony_nr_ancestral_dm6":
cd $LUSTRE/sift4g_annotation/scripts_to_build_SIFT_db/test_files #eventually I moved the entire sift4g folder from $LUSTRE to $STORE
scp -pr nr_ancestral_dm6 two_parsimony_nr_ancestral_dm6
scp -p nr_ancestral_dm6.config.txt two_parsimony_nr_ancestral_dm6.config.txt

#Next, edit all paths within the config file (since everything is now in CESGA FT3 rather than FT2, the path is a bit different and "nlsas/" needs to be added after "scratch/"):
nano two_parsimony_nr_ancestral_dm6.config.txt #edit the following lines:
PARENT_DIR=/mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/test_files/two_parsimony_nr_ancestral_dm6
ORG=ancestral_drosophila_melanogaster
ORG_VERSION=two_parsimony_nr_ancestral_dm6

#Copy the new genomic fasta file to chr-src, and split it by chromosome:
cd two_parsimony_nr_ancestral_dm6
scp -p ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/reference/indexed_reference/two_parsimony_ancestral-all-chromosome-r6.14.fa.gz chr-src/
cd chr-src/
gunzip two_parsimony_ancestral-all-chromosome-r6.14.fa.gz
awk 'BEGIN {O="";} /^>/ { O=sprintf("%s.fa",substr($0,2));} {if(O!="") print >> O;}' two_parsimony_ancestral-all-chromosome-r6.14.fa
rm two_parsimony_ancestral-all-chromosome-r6.14.fa
rm *.gz #delete the old files
#Put gene annotation file in gene-annotation-src:
cd ..
mkdir -p gene-annotation-src
scp -p ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/reference/indexed_reference/dm6nr.refGene.gtf.gz gene-annotation-src/
gunzip gene-annotation-src/dm6nr.refGene.gtf.gz
awk -F"\t" '{OFS = FS} { gsub(/chr/,"", $1); print }' gene-annotation-src/dm6nr.refGene.gtf | gzip > gene-annotation-src/dm6nr.refGene.gtf.gz #remove the "chr" part from the chromosome names in the .gtf file, since it's using a different nomenclature than the .fa file and it was crashing the programme.
rm gene-annotation-src/dm6nr.refGene.gtf

#Next remove the files and folders which will be redone:
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/test_files/two_parsimony_nr_ancestral_dm6
rm -r SIFT_predictions
rm -r singleRecords*
rm -r nr_ancestral_dm6
rm -r subst/
rm -r fasta/
rm all_prot.fasta
rm *log
rm Log2.txt

******************>

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db

#Finally, build the database using the following command:
sbatch make-SIFT-db-all.sh #But first store in make-SIFT-db-all.sh the following lines:

#!/bin/bash
#SBATCH -p thinnodes
#SBATCH -n 2
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=24
#SBATCH --mem-per-cpu=10GB
#SBATCH -J make-SIFT-db-all
#SBATCH -o make-SIFT-db-all_%A.out
#SBATCH -t 16:00:00 # execution time
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db
perl make-SIFT-db-all.pl -config /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/test_files/two_parsimony_nr_ancestral_dm6.config.txt

#I encountered this bug: https://github.com/rvaser/sift4g/issues/10 and edited the code as suggested here. However I kept running into the same problem until I realised that the programme doesn't remove the all_prot.fasta file, so it keeps appending the wrong sequences. Notwithstanding, even after manually removing it, I kept running into the alignment issues. So I posted a message in the linked issue, and followed rvaser's instructions over there.

#Since the first steps of the pipeline are working fine and don't need to be repeated, I downloaded https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/3877234/make-SIFT-db-starting_from_SIFT4G.pl.txt and used this script for subsequent attempts:
sbatch make-SIFT-db-starting_from_SIFT4G.sh #But first store in make-SIFT-db-starting_from_SIFT4G.sh the following lines:

#!/bin/bash
#SBATCH -p thinnodes
#SBATCH -n 2 --ntasks-per-node=1 --cpus-per-task=24
#SBATCH --mem-per-cpu=10GB
#SBATCH -J make-SIFT-db-starting_from_SIFT4G
#SBATCH -o make-SIFT-db-starting_from_SIFT4G_%A.out
#SBATCH -t 16:00:00 # execution time
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/
perl make-SIFT-db-starting_from_SIFT4G.pl.txt -config /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/test_files/two_parsimony_nr_ancestral_dm6.config.txt

#Next I kept running into some extra errors while populating the databases, so I posted yet another issue: https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/53 . According to Pauline, these error messages matter not.

```

##Run the programme:
####nr version:
#####Upload the VCFs and the SIFT4G jar file to CESGA:
```{R, engine='bash'}

cd /mnt/netapp2/Store_uni/home/uvi/bg/dkr/sift4g_annotation

#In CESGA, create the destination folders:
mkdir -p /mnt/netapp2/Store_uni/home/uvi/bg/dkr/sift4g_annotation/annotation/two_parsimony_pools_gen0-6/

#From the cluster, copy the following files:
##ANNOVAR-annotated VCF:
scp -p /share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf uvibgdkr@ft3.cesga.es://mnt/netapp2/Store_uni/home/uvi/bg/dkr/sift4g_annotation/annotation/two_parsimony_pools_gen0-6/
##SIFT4G jar file:
#scp -p /share/rdata/ramon.pouso/sift4g/SIFT4G_Annotator_v2.4.jar uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/sift4g_annotation/sift4g/

```

#####Annotate the files:
```{R, engine='bash'}

#Launch it as follows for each VCF (don't copy them from here to the terminal; invisible spaces will break it):
cd /mnt/netapp2/Store_uni/home/uvi/bg/dkr/sift4g_annotation/annotation/two_parsimony_pools_gen0-6/
java -jar/mnt/netapp2/Store_uni/home/uvi/bg/dkr/sift4g_annotation/sift4g/SIFT4G_Annotator_v2.4.jar -c -t -i crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf -d /mnt/netapp2/Store_uni/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/test_files/two_parsimony_nr_ancestral_dm6/two_parsimony_nr_ancestral_dm6/ -r ./

#If this doesn't work from the standard interactive shell in CESGA, then request dedicated interactive nodes, and run the former core from there. E.g.: compute -c 2 --mem 20

```

#####Download the VCFs from CESGA:
```{R, engine='bash'}

#From the cluster, copy the following files:
scp -p uvibgdkr@ft3.cesga.es://mnt/netapp2/Store_uni/home/uvi/bg/dkr/sift4g_annotation/annotation/two_parsimony_pools_gen0-6/crisp_all_pools_gen0-6_masked.recode_snps.gen0-6_all_sites.orthologs.confident.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno_SIFTpredictions.vcf /share/rdata2/dani_k/consanguinidad_rapida/variants/

```

##Analyse the output:
###Default thresholds:
```{bash}

#It's important to select the relevant annotation per site when there is more than one. Extract the name of the gene from the annovar part, then also from the sift part, and keep only the matching one!

cd /share/rdata2/dani_k/consanguinidad_rapida/variants/
VCF=crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno_SIFTpredictions.vcf

#One entry: 
grep -v '^#' $VCF | grep 'nonsynonymous_SNV' | grep 'SIFT' | awk '!($5 ~ ",")' | awk -F";Gene\\\\.refGene=|;GeneDetail\\\\.refGene=|;AAChange\\\\.refGene=|;ALLELE_END|;SIFTINFO=|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$9,$11,$13)}' | awk 'BEGIN{FS=OFS="\t"} {gsub(":","_", $4);gsub("\\(","_");gsub("\\)","_");print}' | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$10)}' | grep -v "," > ${VCF/.vcf/.clean.txt}
#Multiple entries:
grep -v '^#' $VCF | grep 'nonsynonymous_SNV' | grep 'SIFT' | awk '!($5 ~ ",")' | awk -F";Gene\\\\.refGene=|;GeneDetail\\\\.refGene=|;AAChange\\\\.refGene=|;ALLELE_END|;SIFTINFO=|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$9,$11,$13)}' | awk 'BEGIN{FS=OFS="\t"} {gsub(":","_", $4);gsub("\\(","_");gsub("\\)","_");print}' | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$10)}' | grep "," | sed 's/,/\t/g' | awk '{for(i=6;i<=NF;i++){if($i ~ $5){printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$i)}}}' >> ${VCF/.vcf/.clean.txt}

#Classify the mutations in deleterious and tolerated categories:
module load gcc/7.2.0
module add gcc/7.2.0
grep "DELETERIOUS" ${VCF/.vcf/.clean.txt} | bedtools sort > gen0-6_all_sites_missense_variants_SIFT_scores_deleterious.bed #14710 (25.8% of the total 57069)
grep "TOLERATED" ${VCF/.vcf/.clean.txt} | bedtools sort > gen0-6_all_sites_missense_variants_SIFT_scores_tolerated.bed #42301 (74.1% of the total 57069)

#Check genes with parentheses:
#grep -v '^#' $VCF | grep 'synonymous_SNV' | grep 'SIFT' | awk -F";Gene\\\\.refGene=|;GeneDetail\\\\.refGene=|;AAChange\\\\.refGene=|;ALLELE_END|;SIFTINFO=|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$9,$11,$13)}' | awk -F"\t" '{gsub(/:/,"_", $4); print}' | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$10)}' | awk '$5 ~ "\\("' | grep "," | sed 's/,/\t/g' | awk -F"\t" '{gsub("\\(","_");gsub("\\)","_");print}' | awk '{for(i=6;i<=NF;i++){if($i ~ $5){printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$i)}}}' | less -S

```

#8. Carry out PROVEAN annotation.
##Prepare necessary files to build the database.
###Prepare list of genes with new or changed missense mutations.
```{bash}

#This and the next step will be performed in the cluster, but the rest in CESGA. The idea here is to obtain the list of mutations which have changed (due to a different polarisation) or have been included for the first time in the new dataset:
mkdir -p /share/rdata2/dani_k/consanguinidad_rapida/variants/provean
cd /share/rdata2/dani_k/consanguinidad_rapida/variants/provean
module load gcc/7.2.0
module add gcc/7.2.0

VCF="/share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf"

#Extract list of sites which are annotated as exonic and nonsynonymous, and convert to bed format:
grep -e 'refGene=exonic;.*nonsynonymous' $VCF > fast_inbreeding_nonsynonymous_vcf.txt
awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$4,$5)}' fast_inbreeding_nonsynonymous_vcf.txt > fast_inbreeding_nonsynonymous_vcf.bed

/share/rdata/ramon.pouso/provean/pools_individuals_nonsynonymous_vcf.bed #original slow inbreeding dataset
/share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean/pools_individuals_nonsynonymous_vcf.bed #latest slow inbreeding dataset

#Extract list of sites exclusive to the new dataset, plus those whose polarisation changed between datasets:
##Sites exclusive to the fast inbreeding dataset:
bedtools subtract -a fast_inbreeding_nonsynonymous_vcf.bed -b <(cat /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean/pools_individuals_nonsynonymous_vcf.bed /share/rdata/ramon.pouso/provean/pools_individuals_nonsynonymous_vcf.bed | cut -f-3 | sort -k1,1 -k2,2n | uniq) > fast_inbreeding_nonsynonymous_vcf.diff.bed #23607
##Sites whose polarisation changed between one of the two slow inbreeding datasets and the fast inbreeding one, which were not already changed in the other slow inbreeding dataset:
bedtools subtract -a fast_inbreeding_nonsynonymous_vcf.bed -b fast_inbreeding_nonsynonymous_vcf.diff.bed | bedtools intersect -a stdin -b /share/rdata/ramon.pouso/provean/pools_individuals_nonsynonymous_vcf.bed -wa -wb | awk '$4 != $9' | bedtools intersect -a stdin -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean/pools_individuals_nonsynonymous_vcf.bed -wa -wb | awk '$4 != $14' | cut -f-5 >> fast_inbreeding_nonsynonymous_vcf.diff.bed #170
##Sites whose polarisation changed between the latest slow inbreeding dataset and the fast inbreeding one, which were not present in the original slow inbreeding dataset:
bedtools subtract -a /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean/pools_individuals_nonsynonymous_vcf.bed -b /share/rdata/ramon.pouso/provean/pools_individuals_nonsynonymous_vcf.bed | bedtools intersect -a fast_inbreeding_nonsynonymous_vcf.bed -b stdin -wa -wb | awk '$4 != $9' | cut -f-5 >> fast_inbreeding_nonsynonymous_vcf.diff.bed #73
##Sites whose polarisation changed between the latest slow inbreeding dataset and the fast inbreeding one, which were not present in the original slow inbreeding dataset:
bedtools subtract -a /share/rdata/ramon.pouso/provean/pools_individuals_nonsynonymous_vcf.bed -b /share/rdata/ramon.pouso/POOLS/all_gens_0_140/variants/provean/pools_individuals_nonsynonymous_vcf.bed | bedtools intersect -a fast_inbreeding_nonsynonymous_vcf.bed -b stdin -wa -wb | awk '$4 != $9' | cut -f-5 >> fast_inbreeding_nonsynonymous_vcf.diff.bed #1

##Sort them and keep only the unique entries:
sort -k1,1 -k2,2n fast_inbreeding_nonsynonymous_vcf.diff.bed > fast_inbreeding_nonsynonymous_vcf.diff_sorted.bed && mv fast_inbreeding_nonsynonymous_vcf.diff_sorted.bed fast_inbreeding_nonsynonymous_vcf.diff.bed #23851 entries, which is 72 less than the original file in the cluster (23923 entries). I can't recreate the code to generate that exact file because it had a mistake thanks to which some mutations from the original slow inbreeding project but missing from the latest slow inbreeding project were also included here, even though there was no polarisation change between them. When testing this, I replaced by mistake the original fast_inbreeding_nonsynonymous_vcf.diff.bed file with the new, correct one. The rest of the files such as fast_inbreeding_nonsynonymous_gene_names.txt are still the original, and thus include the extra unnnecessary SNPs. In the end none of this matters much: I simply unnecessarily repeated PROVEAN for those 72 genes.

#Generate list with coordinates, gene and transcript names, and aminoacid changes:
bedtools intersect -a $VCF -b fast_inbreeding_nonsynonymous_vcf.diff.bed | awk -F"\t|;AAChange.refGene=|;ALLELE_END" '{printf ("%s\t%s\t%s\n", $1,$2,$9)}' | awk -F"\t|:|," '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$7)}' | awk -F"\t" '{OFS = FS} { gsub(/p\./,"", $5); print }' | grep -v "RNA" | sort -k1,1 -k2,2n | uniq > fast_inbreeding_nonsynonymous_gene_names.txt

#Generate the same list for all missense sites in the VCF (and not just the new/changed ones), which will be necessary later on:
bedtools intersect -a $VCF -b fast_inbreeding_nonsynonymous_vcf.bed | awk -F"\t|;AAChange.refGene=|;ALLELE_END" '{printf ("%s\t%s\t%s\n", $1,$2,$9)}' | awk -F"\t|:|," '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$7)}' | awk -F"\t" '{OFS = FS} { gsub(/p\./,"", $5); print }' | grep -v "RNA" | sort -k1,1 -k2,2n | uniq > fast_inbreeding_nonsynonymous_gene_names_complete.txt

#Sanity checks:
cut -f3 fast_inbreeding_nonsynonymous_gene_names.txt | sort -u | wc -l #8160 genes
cut -f4 fast_inbreeding_nonsynonymous_gene_names.txt | sort -u | wc -l #8160 transcripts
#If the number of unique gene names and transcript names is the same, the script worked. In a previous version both numbers were different, which allowed me to discover that some genes with parenthesis in their names were introducing bugs. I modified the code to the current version, and now everything checks.

scp fast_inbreeding_nonsynonymous_gene_names.txt uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
scp fast_inbreeding_nonsynonymous_gene_names_complete.txt uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

```

###Prepare annotation and fasta files.
```{bash}

cd /share/rdata/ramon.pouso/reference/indexed_reference/

#Upload the non-redundant version of the .gtf file obtained in the ANNOVAR section:
#scp dm6nr.refGene.gtf uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation #Can be skipped, since it's the same as before

#Upload the ancestral version of the .fa file obtained in the polarisation script:
scp two_parsimony_ancestral-all-chromosome-r6.14.fa uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

```

##Build Provean database.
###Generate for each gene a file with its aminoacid changes (in the format required by Provean).
```{bash}

#This analysis will be run from here on in CESGA, in the following path:
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

#Extract all variants from each gene and store them in variant files.
mkdir -p fi_genes_variants
GENES=$(cat fast_inbreeding_nonsynonymous_gene_names.txt | cut -f 3 | sort -u)
for gen in ${GENES[@]}
  do
  echo "$gen"
  awk -v gene_name=$gen '$3 == gene_name {print $5}' fast_inbreeding_nonsynonymous_gene_names.txt > fi_genes_variants/"$gen".var
  done
  
#Replace parentheses with low dashes, since provean.sh isn't able to parse files with brackets in their name. Also remove square brackets.
cd fi_genes_variants
GENES=$(ls *\(*)
for old_name in ${GENES[@]}
  do
  echo "$old_name"
  new_name=$(echo "$old_name" | sed -e 's/(/_/g;s/)/_/g;s/\[//g;s/\]//g')
  echo "$new_name"
  mv "$old_name" "$new_name"
  done

```

###Generate for each gene a fasta file with its protein sequence.
####Retrieve the whole nucleotide sequence.
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

#First generate a more readable version of the non-redundant annotation file, which keeps only necessary data, and transforms coordinates from 1-based (GTF format) to 0-based (BED format):
#awk -F'\t|gene_id \"|"; transcript_id |; exon_id "|"; gene_name' '($1 == "chr2L" || $1 == "chr2R" || $1 == "chr3L" || $1 == "chr3R" || $1 == "chr4" || $1 == "chrX") && $3=="CDS" {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n"),$1,$4-1,$5,$7,$8,$10,$12}' dm6nr.refGene.gtf > dm6nr.refGene.txt #Can be skipped, since it's the same as before

#Then cross it with the list of genes with nonsynonymous variants to obtain coordinates for all CDS from all genes that will be analysed with Provean. I tried to do it faster using grep -Fwf but some genes have special characters (such as "-") which are not considered part of a word, so it introduces some mistakes. So it's best to use this loop instead:
GENES=$(cat fast_inbreeding_nonsynonymous_gene_names.txt | cut -f 3 | sort -u)
COUNTER=0
rm fast_inbreeding_nonsynonymous.cds_list.dm6nr.refGene.txt
for gen in ${GENES[@]}
  do
  #echo "${gen}"
  awk -v gene_name=$gen '$6 == gene_name' dm6nr.refGene.txt >> fast_inbreeding_nonsynonymous.cds_list.dm6nr.refGene.txt
  ((COUNTER++))
  if [ $(( $COUNTER % 100 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $(echo "$GENES" | wc -l)"
  fi
  done
awk -F"\t" '{OFS = FS} { gsub(/chr/,"", $1); print }' fast_inbreeding_nonsynonymous.cds_list.dm6nr.refGene.txt > fast_inbreeding_nonsynonymous.cds_list.dm6nr.refGene.bed #Remove the "chr" from the chromosome names to convert them into the same format that the fasta uses.

  ##Sanity checks:
  cut -f6 fast_inbreeding_nonsynonymous.cds_list.dm6nr.refGene.bed | uniq | wc -l #8081 genes instead of the 8160 found in fast_inbreeding_nonsynonymous_gene_names.txt because some of the genes in the annovar database are not included in the UCSC .gtf file. 
  comm -3 <(cut -f3 fast_inbreeding_nonsynonymous_gene_names.txt | sort -u) <(cut -f6 fast_inbreeding_nonsynonymous.cds_list.dm6nr.refGene.bed | sort -u) | wc -l #79, which is the correct result of 8160-8081 
  comm -3 <(cut -f3 fast_inbreeding_nonsynonymous_gene_names.txt | sort -u) <(cut -f6 fast_inbreeding_nonsynonymous.cds_list.dm6nr.refGene.bed | sort -u) | less -S #All results are displayed in the first column, which means that all missing entries are missing in the second file, and none from the second file are missing in the first one.

#Retrieve reference sequences for all CDS (from the ancestral fasta to account for polarisation).
module load bedtools/2.30.0
rm two_parsimony_ancestral-all-chromosome-r6.14.fa.fai
bedtools getfasta -fi two_parsimony_ancestral-all-chromosome-r6.14.fa -bed fast_inbreeding_nonsynonymous.cds_list.dm6nr.refGene.bed -fo fast_inbreeding_nonsynonymous.cds_sequence.fa

  ##Sanity checks:
  grep -v '>' fast_inbreeding_nonsynonymous.cds_sequence.fa | wc -l #35715, which is the same number of CDS (lines) in the file fast_inbreeding_nonsynonymous.cds_list.dm6nr.refGene.bed.

#Paste each CDS' sequence with the rest of the information.
paste fast_inbreeding_nonsynonymous.cds_list.dm6nr.refGene.bed <(grep -v '>' fast_inbreeding_nonsynonymous.cds_sequence.fa) > fast_inbreeding_nonsynonymous.cds_list_and_sequence.dm6nr.refGene.bed

  ##Sanity checks:
  awk '{printf ("%s\t%s\n"),$3-$2,length($8)}' fast_inbreeding_nonsynonymous.cds_list_and_sequence.dm6nr.refGene.bed | awk '$1==$2' | wc -l #35715, which means that all retrieved sequences have the correct length (the same as the difference between their start and their end points).

#Fuse all exons from each gene and store them in a file together with the gene name and the strand information.
GENES=$(cat fast_inbreeding_nonsynonymous.cds_list_and_sequence.dm6nr.refGene.bed | cut -f 6 | sort -u)
TOTAL=$(echo "$GENES" | wc -l)
COUNTER=0
rm fast_inbreeding_nonsynonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed
for gen in ${GENES[@]}
  do
  #echo "${gen}"
  STRAND=$(awk -F"\t" -v gen=$gen '$6 == gen' fast_inbreeding_nonsynonymous.cds_list_and_sequence.dm6nr.refGene.bed | shuf -n1 | cut -f 4)
  CODING_SEQUENCE=$(awk -F"\t" -v gen=$gen '$6 == gen {print $8}' fast_inbreeding_nonsynonymous.cds_list_and_sequence.dm6nr.refGene.bed | tr -d '\n')
  echo -e "$gen\t$STRAND\t$CODING_SEQUENCE" >> fast_inbreeding_nonsynonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed
  ((COUNTER++))
  if [ $(( $COUNTER % 50 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $(echo "$GENES" | wc -l)"
  fi
  done

#Translate the exons to proteins using an external website and store each protein in a fasta file:
mkdir -p fi_genes_fasta
TOTAL=$(cat fast_inbreeding_nonsynonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed | wc -l)
COUNTER=0
while read -r GENE STRAND CODING_SEQUENCE; do
  #GENE=$(echo "$entry" | cut -f 1)
  echo $GENE
  #STRAND=$(echo "$entry" | cut -f 2)
  #echo $STRAND
  #CODING_SEQUENCE=$(echo "$entry" | cut -f 3)
  #echo $CODING_SEQUENCE
  if [ $STRAND == "+" ]
    then
    curl -s -d "dna_sequence=$CODING_SEQUENCE&output_format=fasta" -A "${GENE}" https://web.expasy.org/cgi-bin/translate/dna2aa.cgi | awk '/:5'\''3'\'' Frame 1$/,/:5'\''3'\'' Frame 2$/' | head -n-1 | sed -r '/^\s*$/d' | sed 's/-/X/g' > fi_genes_fasta/"$GENE".fa #sends the DNA sequence to the expasy website, then selects the lines for the proper strand (here: +) between the header for Frame 1 and the header for Frame 2, then removes the header for Frame 2, then removes any empty line that may exist, then replaces any existing hyphen by an X (unknown aminoacid) so that Provean doesn't crash.
  elif [ $STRAND == "-" ]
    then
    curl -s -d "dna_sequence=$CODING_SEQUENCE&output_format=fasta" -A "${GENE}" https://web.expasy.org/cgi-bin/translate/dna2aa.cgi | awk '/:3'\''5'\'' Frame 1$/,/:3'\''5'\'' Frame 2$/' | head -n-1 | sed -r '/^\s*$/d' | sed 's/-/X/g' > fi_genes_fasta/"$GENE".fa #sends the DNA sequence to the expasy website, then selects the lines for the proper strand (here: -) between the header for Frame 1 and the header for Frame 2, then removes the header for Frame 2, then removes any empty line that may exist, then replaces any existing hyphen by an X (unknown aminoacid) so that Provean doesn't crash.
  fi
  ((COUNTER++))
  if [ $(( $COUNTER % 2 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $TOTAL"
  fi
  sleep 1
  done < fast_inbreeding_nonsynonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed

```

####Fix some gene names:
```{bash}

#Replace parentheses with low dashes, since provean.sh isn't able to parse files with brackets in their name. Also remove square brackets.
cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/fi_genes_fasta
GENES=$(ls *\(*)
for old_name in ${GENES[@]}
  do
  echo "$old_name"
  new_name=$(echo "$old_name" | sed -e 's/(/_/g;s/)/_/g;s/\[//g;s/\]//g')
  echo "$new_name"
  mv "$old_name" "$new_name"
  done

```

##Configure Provean:
```{bash}

#None of this chunk needs to be repeated.

<!-- cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/ -->

<!-- #Provean didn't work in CESGA because it was linked with the most recent versions of ncbi-blast+ and the blast nr databases, so I downloaded the required version of both: -->
<!-- ##blast+ v2.4.0: -->
<!-- wget https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/2.4.0/ncbi-blast-2.4.0+-x64-linux.tar.gz -->
<!-- #/mnt/lustre/scratch/home/uvi/bg/dkr -->
<!-- tar xvzf ncbi-blast-2.4.0+-x64-linux.tar.gz -->
<!-- ##nr protein database v4 -->
<!-- cd ncbi-blast-2.4.0+/ -->
<!-- wget https://ftp.ncbi.nlm.nih.gov/blast/db/v4/nr_v4* /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/ncbi-blast-2.4.0+ -->
<!-- tar xvzf nr_v4* -->

<!-- #Next, I copied the executable provean files to my local folder: -->
<!-- cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation -->
<!-- scp -p /mnt/netapp1/Optcesga_FT2_RHEL7/2020/software/Compiler/gcccore/system/provean/1.1.5/bin/provean ./ -->
<!-- scp -p /mnt/netapp1/Optcesga_FT2_RHEL7/2020/software/Compiler/gcccore/system/provean/1.1.5/bin/provean.sh ./  -->
<!-- nano provean.sh #Then I edited the configuration paths in the provean.sh files to match the following: -->
<!-- #################### -->
<!-- # CONFIGURATION -->
<!-- #################### -->
<!-- # Specify the path to database and program -->
<!-- # -->
<!-- BLAST_DB="/mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/ncbi-blast-2.4.0+/blastdb_v4nr/nr" -->
<!-- PSIBLAST="/mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/ncbi-blast-2.4.0+/bin/psiblast" -->
<!-- CD_HIT="/opt/cesga/2020/software/Compiler/gcccore/system/cd-hit/4.8.1/bin/cd-hit" -->
<!-- BLASTDBCMD="/mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/ncbi-blast-2.4.0+/bin/blastdbcmd" -->
<!-- # END CONFIGURATION -->
<!-- #################### -->

```

##Run Provean.
###Prepare the list of genes and the output folder:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
cut -f1 fast_inbreeding_nonsynonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed > fi_gene_list.txt
sed -i -e 's/(/_/g;s/)/_/g;s/\[//g;s/\]//g' fi_gene_list.txt #replace parentheses with low dashes, since provean.sh isn't able to parse files with brackets in their name. Also remove square brackets.

mkdir -p fi_provean_output
mkdir -p fi_genes_support

```

###Parallel runs (N=20) of all genes:
####Choose the partition number:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
PARALLEL=20 #define the desired value, and the script will do the rest

FILENAME=fi_gene_list.txt
TOTAL=$(wc -l < $FILENAME)
BLOCK_SIZE=$(echo "scale=0; $TOTAL/$PARALLEL" | bc)
for ((i=1; i<PARALLEL; i++))
  do
  START=$((((i-1))*BLOCK_SIZE+1))
  echo $START
  END=$((BLOCK_SIZE*i))
  echo $END
  sed -n "${START},${END}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}
  done
START=$((((i-1))*BLOCK_SIZE+1))
echo $START
echo $TOTAL
sed -n "${START},${TOTAL}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}

```

####fi_provean_parallel_first_twenty.sh
```{bash}

#!/bin/bash
#SBATCH -C clk
#SBATCH -J fi_provean_parallel_first_twenty
#SBATCH -o fi_provean_parallel_first_twenty.%A.chunk_%a.out
#SBATCH -t 168:00:00              # Run time (hh:mm:ss)
#SBATCH -c 10
#SBATCH --mem-per-cpu=10GB
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
module load gcccore/system provean/1.1.5

# Retrieve files:
FILENAME=fi_gene_list.txt
echo "Running provean; chunk number" ${SLURM_ARRAY_TASK_ID}
TOTAL=$(wc -l < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt})
COUNTER=0

while read -r GENE; do
#  if [ ! -f provean_output/${GENE}.provean ]
#    then
    echo "Processing gene $GENE"
    /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/provean.sh --num_threads $SLURM_CPUS_PER_TASK -q fi_genes_fasta/"$GENE".fa -v fi_genes_variants/"$GENE".var --save_supporting_set fi_genes_support/"$GENE".sss > fi_provean_output/"$GENE".provean
#    else
#    echo "$GENE already processed"
#  fi
  ((COUNTER++))
  if [ $(( $COUNTER % 10 )) == 0 ]
    then
    echo "Processed $COUNTER genes out of $TOTAL"
  fi
  done < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt}
ll -rth

```

####clk nodes:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
PARALLEL=20 #define the desired value (same as in the "Choose the partition number" section):
sbatch --array=1-$PARALLEL /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/fi_provean_parallel_first_twenty.sh

#sbatch --array=10,20 /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/fi_provean_parallel_first_twenty.sh #For listing specific chunks, use a comma.

```

####Remove incomplete genes:
```{bash}

cd /mnt/lustre/scratch/home/uvi/bg/dkr/provean_annotation
JOB_ID=4010122 #Introduce the finished job id.
START=1 #Introduce the first chunk.
END=20 #Introduce the last chunk.

for chunk in $(seq $START $END)
  do
  if grep -Eq "TIME LIMIT|CANCELLED" fi_provean_parallel_first_twenty.$JOB_ID.chunk_$chunk.out
    then
    INTERRUPTED_GENE=$(grep "Processing gene" fi_provean_parallel_first_twenty.$JOB_ID.chunk_$chunk.out | tail -n1 | cut -d' ' -f3)
    echo "removing interrupted $INTERRUPTED_GENE.provean from fi_provean_parallel_first_twenty.$JOB_ID.chunk_$chunk.out"
    #rm fi_provean_output/$INTERRUPTED_GENE.provean
  fi
  done
  
#Check manually if any other files need to be removed, e.g. empty "gen.provean" files.

```

###Parallel runs (N=20) of all genes in reverse order:
####Choose the partition number:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
PARALLEL=20 #define the desired value, and the script will do the rest

FILENAME=fi_gene_list.txt
FILELIST=$(ls -v ${FILENAME/.txt/.chunk_*.txt} | grep -v 'remaining')
for FILE in ${FILELIST[@]}
  do
  tac $FILE > ${FILE/.chunk/.rev_chunk} #generate reverse version of the gene lists.
  done

```

####fi_provean_parallel_reverse_run.sh
```{bash}

#!/bin/bash
#SBATCH -C clk
#SBATCH -J fi_provean_parallel_reverse_run
#SBATCH -o fi_provean_parallel_reverse_run.%A.chunk_%a.out
#SBATCH -t 168:00:00              # Run time (hh:mm:ss)
#SBATCH -c 10
#SBATCH --mem-per-cpu=10GB
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com


cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
module load gcccore/system provean/1.1.5

#Retrieve files:
FILENAME=fi_gene_list.txt
echo "Running provean; chunk number" ${SLURM_ARRAY_TASK_ID}
TOTAL=$(wc -l < ${FILENAME/.txt/.rev_chunk_${SLURM_ARRAY_TASK_ID}.txt})
COUNTER=0

while read -r GENE; do
if [[ $(find "fi_provean_output/${GENE}.provean" -mtime +100 2>/dev/null) ]] || [ ! -f fi_provean_output/${GENE}.provean ]
    then
    echo "Processing gene $GENE"
    /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/provean.sh --num_threads $SLURM_CPUS_PER_TASK -q fi_genes_fasta/"$GENE".fa -v fi_genes_variants/"$GENE".var --save_supporting_set fi_genes_support/"$GENE".sss > fi_provean_output/"$GENE".provean
    else
    echo "$GENE already processed"
  fi
  ((COUNTER++))
  if [ $(( $COUNTER % 10 )) == 0 ]
    then
    echo "Processed $COUNTER genes out of $TOTAL"
  fi
  done < ${FILENAME/.txt/.rev_chunk_${SLURM_ARRAY_TASK_ID}.txt}

```

####clk nodes:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
PARALLEL=20 #define the desired value:

sbatch --array=1-$PARALLEL /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/fi_provean_parallel_reverse_run.sh

```

####Remove incomplete genes:
```{bash}

cd /mnt/lustre/scratch/home/uvi/bg/dkr/provean_annotation
JOB_ID=4241434 #Introduce the finished job id.
START=1 #Introduce the first chunk.
END=20 #Introduce the last chunk.

for chunk in $(seq $START $END)
  do
  if grep -Eq "TIME LIMIT|CANCELLED" fi_provean_parallel_reverse_run.$JOB_ID.chunk_$chunk.out
    then
    INTERRUPTED_GENE=$(grep "Processing gene" fi_provean_parallel_reverse_run.$JOB_ID.chunk_$chunk.out | tail -n1 | cut -d' ' -f3)
    echo "removing interrupted $INTERRUPTED_GENE.provean from fi_provean_parallel_reverse_run.$JOB_ID.chunk_$chunk.out"
    #rm fi_provean_output/$INTERRUPTED_GENE.provean
  fi
  done

#Check manually if any other files need to be removed, e.g. empty "gen.provean" files.

```

###Parallel runs (N=20) of all remaining genes:
####Extract all unfinished and remaining genes:
```{bash}

DAYS_SINCE=100 #define the maximum number of days to consider a processed GENE valid

#Then extract all unfinished genes:
rm fi_gene_list.remaining.txt
  while read -r GENE
    do
    if [[ $(find "fi_provean_output/${GENE}.provean" -mtime +$DAYS_SINCE -print) ]] || [ ! -f fi_provean_output/${GENE}.provean ]
      then #if [ ! -f fi_provean_output/${GENE}.provean ]
      echo $GENE
      echo ${GENE} >> fi_gene_list.remaining.txt
    fi
    done < fi_gene_list.txt

```

####Choose the partition number:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
PARALLEL=20 #define the desired value, and the script will do the rest

FILENAME=fi_gene_list.remaining.txt
TOTAL=$(wc -l < $FILENAME)
BLOCK_SIZE=$(echo "scale=0; $TOTAL/$PARALLEL" | bc)
for ((i=1; i<PARALLEL; i++))
  do
  START=$((((i-1))*BLOCK_SIZE+1))
  echo $START
  END=$((BLOCK_SIZE*i))
  echo $END
  sed -n "${START},${END}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}
  done
START=$((((i-1))*BLOCK_SIZE+1))
echo $START
echo $TOTAL
sed -n "${START},${TOTAL}p" $FILENAME > ${FILENAME/.txt/.chunk_${i}.txt}

```

####fi_parallel_provean_remaining.sh
```{bash}

#!/bin/bash
#SBATCH -C clk
#SBATCH -J fi_provean_parallel_remaining
#SBATCH -o fi_provean_parallel_remaining.%A.chunk_%a.out
#SBATCH -t 168:00:00              # Run time (hh:mm:ss)
#SBATCH -c 10
#SBATCH --mem-per-cpu=10GB
#SBATCH --mail-type=TIME_LIMIT_80
#SBATCH --mail-user=dkmanruiz@gmail.com

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
module load gcccore/system provean/1.1.5

# Retrieve files:
FILENAME=fi_gene_list.remaining.txt
echo "Running provean; chunk number" ${SLURM_ARRAY_TASK_ID}
TOTAL=$(wc -l < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt})
COUNTER=0

while read -r GENE; do
  if [[ $(find "fi_provean_output/${GENE}.provean" -mtime +100 2>/dev/null) ]] || [ ! -f fi_provean_output/${GENE}.provean ]
    then
    echo "Processing gene $GENE"
    /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/provean.sh --num_threads $SLURM_CPUS_PER_TASK -q fi_genes_fasta/"$GENE".fa -v fi_genes_variants/"$GENE".var --save_supporting_set fi_genes_support/"$GENE".sss > fi_provean_output/"$GENE".provean
    else
    echo "$GENE already processed"
  fi
  ((COUNTER++))
  if [ $(( $COUNTER % 5 )) == 0 ]
    then
    echo "Processed $COUNTER genes out of $TOTAL"
  fi
  done < ${FILENAME/.txt/.chunk_${SLURM_ARRAY_TASK_ID}.txt}

```

####clk nodes:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
PARALLEL=20 #define the desired value:

sbatch --array=1-$PARALLEL /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/fi_parallel_provean_remaining.sh

```

###Calculate average time:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/fi_provean_output
rm fi_duration.txt
for file in $(find *.provean -mtime -100)
  do
  if grep -q SCORE $file; then
    #echo $file
    START=$(grep "\[" $file | head -n1 | awk -F'\\[|\\]' '{print $2}')
    FINISH=$(grep "\[" $file | tail -n1 | awk -F'\\[|\\]' '{print $2}')
    if [[ $FINISH > $START ]]
      then
      DURATION=$(( $(date -d "$FINISH" "+%s") - $(date -d "$START" "+%s") ))
      else
      DURATION=$(( $(date -d "$FINISH" "+%s") + 86400 - $(date -d "$START" "+%s") ))
      if [[ $DURATION < 0 ]]
        then
        DURATION=$(($DURATION + 86400))
      fi
    fi
    echo -e "${file/.provean/}\t$DURATION" >> fi_duration.txt
  fi
  done

echo "$(find *.provean -mtime -100 | wc -l) genes have been or are being processed"
N_GENES_RAW=$(wc -l < fi_duration.txt)
echo "$N_GENES_RAW genes have been processed"

#Remove negative values (due to day change) since they are the result of bad calculation:
#awk -F"\t" '{OFS = FS} { sub(/-./,"", $2); print }' duration.txt > duration_fixed.txt
#awk -F"\t" '{OFS = FS} !($2 ~ /-/) { print }' duration.txt > duration_fixed.txt
#mv duration_fixed.txt duration.txt

N_GENES=$(wc -l < fi_duration.txt)
echo "calculating average using $N_GENES genes"
SUM=$(cut -f2 fi_duration.txt | paste -sd+ | bc)
AVERAGE_DURATION_SECS=$(echo "scale=6; $SUM/$N_GENES" | bc)
echo "average seconds per gene equals $AVERAGE_DURATION_SECS, and average minutes per gene equals:"
echo "scale=6; $AVERAGE_DURATION_SECS/60" | bc

```

###Check whether files have been correctly processed:
```{bash}

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/
GENES=$(cat fi_gene_list.txt) #define file with the list of genes to check.
for GENE in ${GENES[@]}
  do
  if [ ! -f fi_provean_output/${GENE}.provean ]
    then echo "$GENE NOT PROCESSED YET *************"
    else 
      if grep -q "PROVEAN scores" fi_provean_output/${GENE}.provean
        then echo $GENE "done"
      elif grep -q "No variations entered" fi_provean_output/${GENE}.provean
        then echo $GENE "no valid variation ***"
        else echo $GENE "processing or interrupted ***************************************"
      fi
  fi
  done

```

##Process the Provean output and separate tolerated from deleterious.
```{bash}

#From the cluster:
cd /share/rdata2/dani_k/consanguinidad_rapida/variants/provean
VCF="/share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf"
grep '^#' $VCF > fast_inbreeding_nonsynonymous.vcf
grep -e 'refGene=exonic;.*nonsynonymous' $VCF >> fast_inbreeding_nonsynonymous.vcf #66610
scp fast_inbreeding_nonsynonymous.vcf uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation

#From CESGA:
module load bedtools/2.30.0 

cd /mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation
VCF=fast_inbreeding_nonsynonymous.vcf #66610
sort -f -k3,3 -k5,5 fast_inbreeding_nonsynonymous_gene_names.txt > fast_inbreeding_nonsynonymous_gene_names.gene_aa_sorted.txt #23916

#Combine info for each gene and mutation:
rm fast_inbreeding_missense_variants_provean_scores.gene_aa_sorted.txt
COUNTER=0
GENE_LIST=$(ls fi_provean_output/*.provean | awk -F "/|\\\\.provean" '{print $2}')
TOTAL=$(ls fi_provean_output/*.provean | wc -l)
for gen in ${GENE_LIST[@]}
  do
  echo "${gen}"
  join -i -1 5 -2 1 <(awk -v gene=$gen '$3==gene' fast_inbreeding_nonsynonymous_gene_names.gene_aa_sorted.txt) <(grep -Ev '#|\[' fi_provean_output/"$gen".provean | sort -f -k1,1) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $2,$3,$4,$5,$1,$6)}' >> fast_inbreeding_missense_variants_provean_scores.gene_aa_sorted.txt #23371
  ((COUNTER++))
  if [ $(( $COUNTER % 100 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $TOTAL"
  fi
  done

#Combine the information for the new/changed mutations in this dataset, with the previously obtained information for the rest of mutations:
bedtools intersect -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' fast_inbreeding_missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b $VCF > fast_inbreeding_missense_variants_provean_scores.fast_inbreeding.bed #23371 (new output, that is, positions in the fast inbreeding VCF which have been processed for the first time)
bedtools subtract -a $VCF -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' fast_inbreeding_missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) | wc -l #33790 (positions in the fast inbreeding VCF but not in the new output, that is, those which were processed before for the slow inbreeding project)
bedtools subtract -a $VCF -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' fast_inbreeding_missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -header | bedtools intersect -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b stdin > fast_inbreeding_missense_variants_provean_scores.slow_inbreeding_new_ones.bed #1557 (positions in the fast inbreeding VCF but not in the new output, which are also included in the latest version of the slow inbreeding output)
bedtools subtract -a $VCF -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' fast_inbreeding_missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -header | bedtools intersect -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b stdin | bedtools subtract -a stdin -b fast_inbreeding_missense_variants_provean_scores.slow_inbreeding_new_ones.bed > fast_inbreeding_missense_variants_provean_scores.slow_inbreeding_old_ones.bed #30926 (positions in the fast inbreeding VCF but not in the new output, which are also included in the old version of the slow inbreeding output but not in the latest version of the inbreeding output, since those were already included in the former step)
cat fast_inbreeding_missense_variants_provean_scores.fast_inbreeding.bed fast_inbreeding_missense_variants_provean_scores.slow_inbreeding_new_ones.bed fast_inbreeding_missense_variants_provean_scores.slow_inbreeding_old_ones.bed | awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$3,$4,$5,$6,$7)}' | sort -k3,3 > fast_inbreeding_missense_variants_provean_scores.gene_aa_sorted_complete.txt #55854 (which is the correct result of 23371 + 1557 + 30926)

#If these numbers aren't clear, see the following sanity checks and explanations:
#Sanity checks:
#I haven't repeated these after losing the original version of the script. All sanity checks were fine. If they need to be repeated, adapt the code from the slow inbreeding "all_sites_pipeline.Rmd" project. Keep in mind that now three sources need to be accounted for: the new fast inbreeding project sites, the slow inbreeding project latest output, and the slow inbreeding project original output (with the second taking priority over the third when sites are included in both).


#Now generate another version with fixed gene names (i.e. those with parentheses), which is useful for the sanity checks:
sed -e 's/(/_/g;s/)/_/g;s/\[//g;s/\]//g' fast_inbreeding_nonsynonymous_gene_names.gene_aa_sorted.txt > fast_inbreeding_nonsynonymous_gene_names.gene_aa_sorted.bis.txt 
#Combine info for each gene and mutation:
rm fast_inbreeding_missense_variants_provean_scores.gene_aa_sorted.bis.txt
COUNTER=0
GENE_LIST=$(ls fi_provean_output/*.provean | awk -F "/|\\\\.provean" '{print $2}')
TOTAL=$(ls fi_provean_output/*.provean | wc -l)
for gen in ${GENE_LIST[@]}
  do
  echo "${gen}"
  join -i -1 5 -2 1 <(awk -v gene=$gen '$3==gene' fast_inbreeding_nonsynonymous_gene_names.gene_aa_sorted.bis.txt) <(grep -Ev '#|\[' fi_provean_output/"$gen".provean | sort -f -k1,1) | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $2,$3,$4,$5,$1,$6)}' >> fast_inbreeding_missense_variants_provean_scores.gene_aa_sorted.bis.txt #23630
  ((COUNTER++))
  if [ $(( $COUNTER % 100 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $TOTAL"
  fi
  done


#Now let's repat the process for the genes with parentheses in their names, which weren't included neither in the old dataset nor in the new one so far:
#Combine info for each gene and mutation:
rm /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt
rm missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt
rm fast_inbreeding_missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt
COUNTER=0
GENE_LIST=$(cut -f3 fast_inbreeding_nonsynonymous_gene_names.gene_aa_sorted.txt | grep "(" | sort | uniq)
TOTAL=$(echo "${GENE_LIST}" | wc -l)
for gen in ${GENE_LIST[@]}
  do
  gen_bis=$(echo "${gen}" | tr '()' '__')
  #Slow inbreeding old dataset:
  join -i -1 5 -2 1 <(awk -v gene=$gen '$3==gene' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/pools_individuals_nonsynonymous_gene_names.gene_aa_sorted.txt) <(grep -Ev '#|\[' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/provean_output/"$gen_bis".provean | sort -f -k1,1) | awk -v gene=$gen_bis '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $2,$3,gene,$5,$1,$6)}' >> /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt
  #Slow inbreeding new dataset:
  join -i -1 5 -2 1 <(awk -v gene=$gen '$3==gene' pools_individuals_nonsynonymous_gene_names.gene_aa_sorted.txt) <(grep -Ev '#|\[' provean_output/"$gen_bis".provean | sort -f -k1,1) | awk -v gene=$gen_bis '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $2,$3,gene,$5,$1,$6)}' >> missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt
  #Fast inbreeding dataset:
  join -i -1 5 -2 1 <(awk -v gene=$gen '$3==gene' fast_inbreeding_nonsynonymous_gene_names.gene_aa_sorted.txt) <(grep -Ev '#|\[' fi_provean_output/"$gen_bis".provean | sort -f -k1,1) | awk -v gene=$gen_bis '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $2,$3,gene,$5,$1,$6)}' >> fast_inbreeding_missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt
  ((COUNTER++))
  if [ $(( $COUNTER % 10 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $TOTAL"
  fi
  done

#Convert to bed:
sort -k1,1 -k2,2n /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt | uniq | awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' > /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.bed #499 slow inbreeding old dataset:
sort -k1,1 -k2,2n missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt | uniq | awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' > missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.bed #54 slow inbreeding new dataset:
sort -k1,1 -k2,2n fast_inbreeding_missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt | uniq | awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' > fast_inbreeding_missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.bed #259 fast inbreeding dataset:


#Combine the information for the new/changed mutations in this dataset, with the previously obtained information for the rest of mutations:
bedtools intersect -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' fast_inbreeding_missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b $VCF > fast_inbreeding_missense_variants_provean_scores.fi_parentheses_fast_inbreeding.bed #259 (new output, that is, positions in the fast inbreeding VCF which have been processed for the first time)
bedtools subtract -a $VCF -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' fast_inbreeding_missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -header | bedtools intersect -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b stdin > fast_inbreeding_missense_variants_provean_scores.fi_parentheses_slow_inbreeding_new_ones.bed #21 (positions in the fast inbreeding VCF but not in the new output, which are also included in the latest version of the slow inbreeding output)
bedtools subtract -a $VCF -b <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' fast_inbreeding_missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -header | bedtools intersect -a <(awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' /mnt/netapp2/Store_uni/home/uvi/bg/dkr/provean_annotation/missense_variants_provean_scores.fi_parentheses_gene_aa_sorted.txt | sort -k1,1 -k2,2n | uniq) -b stdin | bedtools subtract -a stdin -b fast_inbreeding_missense_variants_provean_scores.fi_parentheses_slow_inbreeding_new_ones.bed > fast_inbreeding_missense_variants_provean_scores.fi_parentheses_slow_inbreeding_old_ones.bed #237
cat fast_inbreeding_missense_variants_provean_scores.fi_parentheses_fast_inbreeding.bed fast_inbreeding_missense_variants_provean_scores.fi_parentheses_slow_inbreeding_new_ones.bed fast_inbreeding_missense_variants_provean_scores.fi_parentheses_slow_inbreeding_old_ones.bed | awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$3,$4,$5,$6,$7)}' | sort -k3,3 > fast_inbreeding_missense_variants_provean_scores.fi_parentheses_gene_aa_sorted_complete.txt #517 (which is the correct result of 259 + 21 + 237)

#If these numbers aren't clear, see the following sanity checks and explanations:
#Sanity checks:
#I haven't repeated these after losing the original version of the script. All sanity checks were fine. If they need to be repeated, adapt the code from the slow inbreeding "all_sites_pipeline.Rmd" project. Keep in mind that now three sources need to be accounted for: the new fast inbreeding project sites, the slow inbreeding project latest output, and the slow inbreeding project original output (with the second taking priority over the third when sites are included in both).


#Now combine all previously obtained entries (without and with parenthesis) into a single file, and convert to bed:
cat fast_inbreeding_missense_variants_provean_scores.gene_aa_sorted_complete.txt fast_inbreeding_missense_variants_provean_scores.fi_parentheses_gene_aa_sorted_complete.txt | sort -k1,1 -k2,2n | awk -F "\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6)}' > fast_inbreeding_missense_variants_provean_scores.final_complete.bed


#Finally, classify variants into tolerated and deleterious based on threshold of choice (default = -2.5):
THRESHOLD=-2.5
awk -F"\t" -v thres=$THRESHOLD '$7 <= thres {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$7)}' fast_inbreeding_missense_variants_provean_scores.final_complete.bed | bedtools sort > fast_inbreeding_missense_variants_provean_scores_deleterious.bed #11488 (20.4% of the total 56371)
awk -F"\t" -v thres=$THRESHOLD '$7 > thres {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$7)}' fast_inbreeding_missense_variants_provean_scores.final_complete.bed | bedtools sort > fast_inbreeding_missense_variants_provean_scores_tolerated.bed #44883 (79.6% of the total 56371)

```

#9. Carry out 4-fold annotation.
##Prepare list of genes with synonymous mutations.
```{bash}

mkdir /share/rdata2/dani_k/consanguinidad_rapida/variants/4fold
cd /share/rdata2/dani_k/consanguinidad_rapida/variants/4fold

rm pools_gen0-6_synonymous_vcf.txt
VCF="/share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf"

#Extract list of sites which are annotated as synonymous:
grep -e ';ExonicFunc.refGene=synonymous' $VCF >> pools_gen0-6_synonymous_vcf.txt

#Generate list with coordinates, gene and transcript names, and nucleotid changes:
awk -F"\t|;AAChange.refGene=|;ALLELE_END" '{printf ("%s\t%s\t%s\n", $1,$2,$9)}' pools_gen0-6_synonymous_vcf.txt | awk -F"\t|:|," '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$6)}' | awk -F"\t" '{OFS = FS} { gsub(/c\./,"", $5); print }' | grep -v "RNA" | sort -k3,3 -k1,1 -k2,2n > pools_gen0-6_synonymous_gene_names.txt

#Sanity checks:
cut -f3 pools_gen0-6_synonymous_gene_names.txt | sort -u | wc -l #11735 genes (3 less than in the previous dataset, because new genes that have been included due to the different polarisation are compensated by the exclusion of chr4 for this dataset)
cut -f4 pools_gen0-6_synonymous_gene_names.txt | sort -u | wc -l #11735 transcripts
#If the number of unique gene names and transcript names is the same, the script worked. In a previous version both numbers were different, which allowed me to discover that some genes with parenthesis in their names were introducing bugs. I modified the code to the current version, and now everything checks.

```

##Retrieve the whole nucleotide sequence.
```{bash}

cd /share/rdata2/dani_k/consanguinidad_rapida/variants/4fold

#First generate a more readable version of the non-redundant annotation file, which keeps only necessary data, and transforms coordinates from 1-based (GTF format) to 0-based (BED format):
awk -F'\t|gene_id \"|"; transcript_id |; exon_id "|"; gene_name' '($1 == "chr2L" || $1 == "chr2R" || $1 == "chr3L" || $1 == "chr3R" || $1 == "chr4" || $1 == "chrX") && $3=="CDS" {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n"),$1,$4-1,$5,$7,$8,$10,$12}' /share/rdata/ramon.pouso/reference/indexed_reference/dm6nr.refGene.gtf > dm6nr.refGene.txt

#Then cross it with the list of genes with synonymous variants to obtain coordinates for all CDS from all genes of interest. I tried to do it faster using grep -Fwf but some genes have special characters (such as "-") which are not considered part of a word, so it introduces some mistakes. So it's best to use this loop instead:
GENES=$(cat pools_gen0-6_synonymous_gene_names.txt | cut -f 3 | sort -u) #11735
COUNTER=0
rm pools_gen0-6_synonymous.cds_list.dm6nr.refGene.txt
for gen in ${GENES[@]}
  do
  #echo "${gen}"
  awk -v gene_name=$gen '$6 == gene_name' dm6nr.refGene.txt >> pools_gen0-6_synonymous.cds_list.dm6nr.refGene.txt
  ((COUNTER++))
  if [ $(( $COUNTER % 100 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $(echo "$GENES" | wc -l)"
  fi
  done
awk -F"\t" '{OFS = FS} { gsub(/chr/,"", $1); print }' pools_gen0-6_synonymous.cds_list.dm6nr.refGene.txt > pools_gen0-6_synonymous.cds_list.dm6nr.refGene.bed #Remove the "chr" from the chromosome names to convert them into the same format that the fasta uses.

  ##Sanity checks:
  cut -f6 pools_gen0-6_synonymous.cds_list.dm6nr.refGene.bed | uniq | wc -l #11616 genes instead of the 11735 found in pools_gen0-6_synonymous_gene_names.txt because some of the genes in the annovar database are not included in the UCSC .gtf file. 
  comm -3 <(cut -f3 pools_gen0-6_synonymous_gene_names.txt | sort -u) <(cut -f6 pools_gen0-6_synonymous.cds_list.dm6nr.refGene.bed | sort -u) | wc -l #119, which is the correct result of 12117-11997 
  comm -3 <(cut -f3 pools_gen0-6_synonymous_gene_names.txt | sort -u) <(cut -f6 pools_gen0-6_synonymous.cds_list.dm6nr.refGene.bed | sort -u) | less -S #All results are displayed in the first column, which means that all missing entries are missing in the second file, and none from the second file are missing in the first one.

#Retrieve reference sequences for all CDS (from the ancestral fasta to account for polarisation).
module load gcc/7.2.0
module add gcc/7.2.0
bedtools getfasta -fi /share/rdata/ramon.pouso/reference/indexed_reference/two_parsimony_ancestral-all-chromosome-r6.14.fa -bed pools_gen0-6_synonymous.cds_list.dm6nr.refGene.bed -fo pools_gen0-6_synonymous.cds_sequence.fa

  ##Sanity checks:
  grep -v '>' pools_gen0-6_synonymous.cds_sequence.fa | wc -l #47489, which is the same number of CDS (lines) in the file pools_gen0-6_synonymous.cds_list.dm6nr.refGene.bed.

#Paste each CDS' sequence with the rest of the information.
paste pools_gen0-6_synonymous.cds_list.dm6nr.refGene.bed <(grep -v '>' pools_gen0-6_synonymous.cds_sequence.fa) > pools_gen0-6_synonymous.cds_list_and_sequence.dm6nr.refGene.bed

  ##Sanity checks:
  awk '{printf ("%s\t%s\n"),$3-$2,length($8)}' pools_gen0-6_synonymous.cds_list_and_sequence.dm6nr.refGene.bed | awk '$1==$2' | wc -l #47489, which means that all retrieved sequences have the correct length (the same as the difference between their start and their end points).

#Fuse all exons from each gene and store them in a file together with the gene name and the strand information.
GENES=$(cat pools_gen0-6_synonymous.cds_list_and_sequence.dm6nr.refGene.bed | cut -f 6 | sort -u)
TOTAL=$(echo "$GENES" | wc -l)
COUNTER=0
rm pools_gen0-6_synonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed
for gen in ${GENES[@]}
  do
  #echo "${gen}"
  STRAND=$(awk -F"\t" -v gen=$gen '$6 == gen' pools_gen0-6_synonymous.cds_list_and_sequence.dm6nr.refGene.bed | shuf -n1 | cut -f 4)
  CODING_SEQUENCE=$(awk -F"\t" -v gen=$gen '$6 == gen {print $8}' pools_gen0-6_synonymous.cds_list_and_sequence.dm6nr.refGene.bed | tr -d '\n')
  echo -e "$gen\t$STRAND\t$CODING_SEQUENCE" >> pools_gen0-6_synonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed
  ((COUNTER++))
  if [ $(( $COUNTER % 50 )) == 0 ]
    then
    echo "processed $COUNTER genes out of $(echo "$GENES" | wc -l)"
  fi
  done

```

##Retrieve codons:
```{bash}

cd /share/rdata2/dani_k/consanguinidad_rapida/variants/4fold

#First join the synonymous variants and the gene information:
join -1 3 -2 1 <(sort -k3,3 pools_gen0-6_synonymous_gene_names.txt) pools_gen0-6_synonymous.cds_list_and_sequence_combined.dm6nr.refGene.bed | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $2, $3-1, $3, $1, $4, $6, $5, $7)}' > pools_gen0-6_synonymous.cds_list_and_sequence_combined.complete_info.dm6nr.refGene.bed #152171

#Then for each variant retrieve the codon it belongs to:
rm pools_gen0-6_synonymous.cds_list_and_sequence_combined.codons.dm6nr.refGene.bed
TOTAL=$(cat pools_gen0-6_synonymous.cds_list_and_sequence_combined.complete_info.dm6nr.refGene.bed | wc -l)
COUNTER=0
while read -r CHR START END GENE TRANSCRIPT STRAND SNP_CHANGE SEQUENCE; do
  SNP=$(echo "${SNP_CHANGE:1:${#SNP_CHANGE}-2}")
  if [ $STRAND == "+" ]
    then
    if [ $(( $SNP % 3 )) == 0 ]
      then 
      OLD_CODON=$(echo $SEQUENCE | cut -c$(($SNP-2))-$SNP)
      NEW_CODON=$(echo "${OLD_CODON:0:2}${SNP_CHANGE: -1}")
    elif [ $(( $SNP % 3 )) == 2 ]
      then 
      OLD_CODON=$(echo $SEQUENCE | cut -c$(($SNP-1))-$(($SNP+1)))
      NEW_CODON=$(echo "${OLD_CODON:0:1}${SNP_CHANGE: -1}${OLD_CODON:2:3}")
    elif [ $(( $SNP % 3 )) == 1 ]
      then 
      OLD_CODON=$(echo $SEQUENCE | cut -c$SNP-$(($SNP+2)))
      NEW_CODON=$(echo "${SNP_CHANGE: -1}${OLD_CODON:1:3}")
    fi
  elif [ $STRAND == "-" ]
    then
    REVERSE_SEQUENCE=$(echo $SEQUENCE | tr ACGT TGCA | rev) #this code obtains the reverse complementary sequence
    if [ $(( $SNP % 3 )) == 0 ]
      then 
      OLD_CODON=$(echo $REVERSE_SEQUENCE | cut -c$(($SNP-2))-$SNP)
      NEW_CODON=$(echo "${OLD_CODON:0:2}${SNP_CHANGE: -1}")
    elif [ $(( $SNP % 3 )) == 2 ]
      then 
      OLD_CODON=$(echo $REVERSE_SEQUENCE | cut -c$(($SNP-1))-$(($SNP+1)))
      NEW_CODON=$(echo "${OLD_CODON:0:1}${SNP_CHANGE: -1}${OLD_CODON:2:3}")
    elif [ $(( $SNP % 3 )) == 1 ]
      then 
      OLD_CODON=$(echo $REVERSE_SEQUENCE | cut -c$SNP-$(($SNP+2)))
      NEW_CODON=$(echo "${SNP_CHANGE: -1}${OLD_CODON:1:3}")
    fi
  fi
  echo -e "$CHR\t$START\t$END\t$GENE\t$TRANSCRIPT\t$STRAND\t$SNP_CHANGE\t$OLD_CODON\t$NEW_CODON" >> pools_gen0-6_synonymous.cds_list_and_sequence_combined.codons.dm6nr.refGene.bed
  ((COUNTER++))
  if [ $(( $COUNTER % 1000 )) == 0 ]
    then
    echo "processed $COUNTER SNPs out of" $TOTAL
  fi
done < pools_gen0-6_synonymous.cds_list_and_sequence_combined.complete_info.dm6nr.refGene.bed

```

##Extract 4-fold degenerate codons:
```{bash}

cd /share/rdata2/dani_k/consanguinidad_rapida/variants/4fold

#First, save the list of 4-fold degenerate codons (obtained from https://github.com/seenstevo/Four-fold_degenerate_bedmaker/blob/master/FFDS_bedmaker.py) to a file:
echo "CTT","CTA","CTG","CTC","GTT","GTC","GTA","GTG","TCT","TCC","TCA","TCG","CCT","CCC","CCA","CCG","ACT","ACC","ACA","ACG","GCT","GCC","GCA","GCG","CGT","CGC","CGA","CGG","GGT","GGC","GGA","GGG" | tr ',' '\n' > 4fold_codons.txt

#Then filter the file obtained in the previous section, which contains the codon for each variant in the dataset, and filter in only those which are 4-fold degenerate (i.e., those from the 4fold file which appear both in column 8 and column 9).
awk 'NR==FNR { A[$1]=1 ; next }; ($8 in A && $9 in A) { print }' 4fold_codons.txt pools_gen0-6_synonymous.cds_list_and_sequence_combined.codons.dm6nr.refGene.bed > pools_gen0-6_synonymous.cds_list_and_sequence_combined.4fold_codons.dm6nr.refGene.bed

cut -f-4 pools_gen0-6_synonymous.cds_list_and_sequence_combined.4fold_codons.dm6nr.refGene.bed > pools_gen0-6_synonymous_variants_4fold.bed #82941

#Note:
cut -f9 pools_gen0-6_synonymous.cds_list_and_sequence_combined.codons.dm6nr.refGene.bed | sort -u #this reveals that there are single-letter new codons, and (see next line)...
cut -f8 pools_gen0-6_synonymous.cds_list_and_sequence_combined.codons.dm6nr.refGene.bed | sort -u #this reveals that there are empty old codons.
#After analysing this up-stream, I concluded that these aren't due to an error in these sections' code. Instead, they owe to ANNOVAR using the transcripts instead of the CDS for its annotation procedures, which results in "empty" old codons (those after the stop codon) being replaced by the single SNP change that appears in the VCF. Fortunately this doesn't interfere in the identification of 4fold degenerate codons.

```

#10. Carry out recombination annotation.
##Copy and unzip the programmes.
```{bash}

#This section doesn't need to be repeated.

<!-- #From outside the server, copy to the server the two necessary programmes, which Humberto sent me by e-mail: -->

<!-- scp /Users/dani/Downloads/coordinates_converter.zip ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/recombination/ -->
<!-- scp /Users/dani/Downloads/RRC2.zip ramon.pouso@rua2.uvigo.es://share/rdata/ramon.pouso/recombination/ -->

<!-- #From inside the server, then unzip both files and their contents, and rename folders. This will be the path: -->
<!-- cd /share/rdata/ramon.pouso/recombination/ -->

```

##Convert coordinates from the RRC files from dm5 to dm6:
```{bash}

#This section doesn't need to be repeated.

<!-- #Convert the RRC comeron coordinates to the format required by the coordinate converter: -->
<!-- cd /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables -->
<!-- mkdir -p dm5 -->
<!-- mv Comeron_100kb_chr*.txt dm5 -->
<!-- cd dm5 -->
<!-- FILES=$(ls Comeron_100kb_chr*.txt | grep -v "chr4" | grep -v 'dm') -->
<!-- for file in ${FILES[@]} -->
<!--   do -->
<!--   echo $file -->
<!--   FILENAME=$(echo $file | cut -d'_' -f3 | cut -d'.' -f1 | sed "s/chr//g") -->
<!--   awk -v chr=$FILENAME '{printf ("%s:%s..%s\t%s\n",chr,$1,$1+99999,$2)}' <(head -n -1 $file) > ${file/.txt/.dm5.txt} -->
<!--   awk -v chr=$FILENAME '{printf ("%s\t%s\t%s\t%s\n",chr,$1,$1+99999,$2)}' <(head -n -1 $file) > ${file/.txt/.dm5.bed} -->
<!--   done -->

<!-- #Then save them in a file and use the following script to obtain the v5 to v6 conversion: -->
<!-- mkdir -p /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables/dm6 -->
<!-- FILES=$(ls Comeron_100kb_chr*.txt | grep -v "chr4" | grep -v 'dm') -->
<!-- for file in ${FILES[@]} -->
<!--   do -->
<!--   echo ${file/.txt/.dm5.txt} -->
<!--   new_name=$(echo ${file/.txt/.dm5_to_dm6.txt}) -->
<!--   cut -f1 ${file/.txt/.dm5.txt} | /share/rdata/ramon.pouso/recombination/coordinates_converter/bulkfile-scripts-master/dmel_r5_to_r6/dmel_r5_to_r6_converter.pl > /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables/dm6/$new_name -->
<!--   grep -v '^#' /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables/dm6/$new_name | awk -F":|\\\\.\\\\.|\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n",$1,$2,$3,$4,$5,$6)}' > /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables/dm6/${new_name/.txt/.bed} -->
<!--   done -->

<!-- #Next use bedtools intersect to cross the file with old coordinates and recombination values with the file with both old and new coordinates: -->
<!-- cd /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables -->
<!-- module load gcc/7.2.0 -->
<!-- module add gcc/7.2.0 -->
<!-- FILES=$(ls dm5/Comeron_100kb_chr*.dm5.bed | grep -v "chr4" | cut -d'/' -f2) -->
<!-- for file in ${FILES[@]} -->
<!--   do -->
<!--   bedtools intersect -a dm5/$file -b dm6/${file/.dm5.bed/.dm5_to_dm6.bed} -wa -wb | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\n",$8,$9,$10,$4)}' > dm6/${file/.dm5.bed/.dm6.bed} -->
<!--   cut -f2,4 dm6/${file/.dm5.bed/.dm6.bed} > ${file/.dm5.bed/.txt} -->
<!--   done -->
<!-- cat dm6/Comeron_100kb_chr*.dm6.bed > dm6/Comeron_100kb_allchr.dm6.bed -->

<!-- #Later on I realised that there are 1-base gaps between all bins (because bedtools works with 0-based coordinates), so use this to fix it: -->
<!-- awk '{printf ("%s\t%s\t%s\t%s\n",$1,$2-1,$3,$4)}' dm6/Comeron_100kb_allchr.dm6.bed > dm6/Comeron_100kb_allchr.dm6.0based.bed -->

```

##Retrieve recombination value for each SNP:
```{bash}

cd /share/rdata2/dani_k/consanguinidad_rapida/variants
module load gcc/7.2.0
module add gcc/7.2.0

FILE=crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.bed
bedtools intersect -a $FILE -b /share/rdata/ramon.pouso/recombination/RRC2/Comeron_tables/dm6/Comeron_100kb_allchr.dm6.0based.bed -wb | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\n",$1,$2,$3,$8)}' > ${FILE/.bed/.recombination.bed}

#Retrieve high recombination and low recombination quartiles.
TOTAL=$(wc -l < ${FILE/.bed/.recombination.bed})
QUARTILE=$((TOTAL/4))

shuf ${FILE/.bed/.recombination.bed} | sort -k4,4n | head -n$QUARTILE | sort -k1,1 -k2,2n > ${FILE/.bed/.low_recombination.bed}
shuf ${FILE/.bed/.recombination.bed} | sort -k4,4n | tail -n$QUARTILE | sort -k1,1 -k2,2n > ${FILE/.bed/.high_recombination.bed}

```

#11. Combine and import all annotations into the VCF.
##Process and combine SIFT and Provean output.
```{bash}

scp uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/fast_inbreeding_missense_variants_provean_scores_tolerated.bed /share/rdata2/dani_k/consanguinidad_rapida/variants/provean
scp uvibgdkr@ft3.cesga.es://mnt/lustre/scratch/nlsas/home/uvi/bg/dkr/provean_annotation/fast_inbreeding_missense_variants_provean_scores_deleterious.bed /share/rdata2/dani_k/consanguinidad_rapida/variants/provean

module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata2/dani_k/consanguinidad_rapida/variants/

#Both tolerated:
bedtools intersect -a ./provean/fast_inbreeding_missense_variants_provean_scores_tolerated.bed -b gen0-6_all_sites_missense_variants_SIFT_scores_tolerated.bed | awk '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > ./../counts/missense_variants_provean_SIFT_tolerated.bed
wc -l < ./../counts/missense_variants_provean_SIFT_tolerated.bed #37954
#Both deleterious:
bedtools intersect -a ./provean/fast_inbreeding_missense_variants_provean_scores_deleterious.bed -b gen0-6_all_sites_missense_variants_SIFT_scores_deleterious.bed | awk '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > ./../counts/missense_variants_provean_SIFT_deleterious.bed
wc -l < ./../counts/missense_variants_provean_SIFT_deleterious.bed #7665
#PROV tol, SIFT del:
bedtools intersect -a ./provean/fast_inbreeding_missense_variants_provean_scores_tolerated.bed -b gen0-6_all_sites_missense_variants_SIFT_scores_deleterious.bed | wc -l #6832
#SIFT tol, PROV del:
bedtools intersect -a ./provean/fast_inbreeding_missense_variants_provean_scores_deleterious.bed -b gen0-6_all_sites_missense_variants_SIFT_scores_tolerated.bed | wc -l #3803

```

##Import all annotations into the VCF.
```{bash}

module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata2/dani_k/consanguinidad_rapida/variants/

VCF=crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.vcf

rm ${VCF/vcf/custom_unsorted.vcf}
#Fourfold:
bedtools intersect -a $VCF -b ./4fold/pools_gen0-6_synonymous_variants_4fold.bed | awk '{gsub("NP=20;","CUSTOM=fourfold;NP=20;"); print}' >> ${VCF/vcf/custom_unsorted.vcf}
#Tolerated:
bedtools intersect -a $VCF -b ./../counts/missense_variants_provean_SIFT_tolerated.bed | awk '{gsub("NP=20;","CUSTOM=tolerated;NP=20;"); print}' >> ${VCF/vcf/custom_unsorted.vcf}
#Deleterious:
bedtools intersect -a $VCF -b ./../counts/missense_variants_provean_SIFT_deleterious.bed | awk '{gsub("NP=20;","CUSTOM=deleterious;NP=20;"); print}' >> ${VCF/vcf/custom_unsorted.vcf}
#LoF:
grep -E ';ExonicFunc.refGene=stopgain;|;ExonicFunc.refGene=stoploss;' $VCF | awk '{gsub("NP=20;","CUSTOM=LoF;NP=20;"); print}' >> ${VCF/vcf/custom_unsorted.vcf}

#Sort the VCF and add the headers:
cat <(grep "^#" $VCF) <(sort -k1,1 -k2,2n ${VCF/vcf/custom_unsorted.vcf}) > ${VCF/vcf/custom.vcf}

```

#12. Split the VCFs at the pool level:
##Exclude AF=0:
###All sites:
```{R, engine='bash'}

mkdir -p /share/rdata2/dani_k/consanguinidad_rapida/counts
cd /share/rdata2/dani_k/consanguinidad_rapida/counts

module load bcftools/1.9

VCF="/share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom.vcf"
POOLS=$(bcftools query -l "${VCF}")
for p in ${POOLS[@]}
  do
  echo "${p}"
  #ID=$(echo "${p}")
  #POOL_NAME=$(echo "${p}")
  FIELD_NUMBER=$(grep "^#" $VCF | grep -v '##' | tr "\t" "\n" | grep -nw $p | cut -d':' -f1)
  paste <(grep -v '^#' $VCF | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6,$7,$8)}') <(grep -v '^#' $VCF | cut -f$FIELD_NUMBER | awk -F ":" '{printf ("%s:%s:%s\n", $4,$5,$6)}' | awk -F":|," '{printf ("%s\t%s\n", $1+$3+$5,$2+$4+$6)}') | awk '$11 > 0' > "${p}"_gen0-6_pool.txt
  done

```

###Low/High recombination sites:
```{R, engine='bash'}

REC=low #low #high

module load gcc/7.2.0 
module add gcc/7.2.0

cd /share/rdata2/dani_k/consanguinidad_rapida/counts

POOLS=$(ls *gen0-6_pool.txt)
for p in ${POOLS[@]}
  do
  echo "${p}"
  bedtools intersect -a ${p} -b crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.${REC}_recombination.bed > ${p/.txt/.${REC}_recombination.txt}
  done

```

##Include AF=0:
```{R, engine='bash'}

mkdir -p /share/rdata2/dani_k/consanguinidad_rapida/counts
cd /share/rdata2/dani_k/consanguinidad_rapida/counts

module load bcftools/1.9

VCF="/share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.custom.vcf"
POOLS=$(bcftools query -l "${VCF}")
for p in ${POOLS[@]}
  do
  echo "${p}"
  #ID=$(echo "${p}")
  #POOL_NAME=$(echo "${p}")
  FIELD_NUMBER=$(grep "^#" $VCF | grep -v '##' | tr "\t" "\n" | grep -nw $p | cut -d':' -f1)
  paste <(grep -v '^#' $VCF | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$3,$4,$5,$6,$7,$8)}') <(grep -v '^#' $VCF | cut -f$FIELD_NUMBER | awk -F ":" '{printf ("%s:%s:%s\n", $4,$5,$6)}' | awk -F":|," '{printf ("%s\t%s\n", $1+$3+$5,$2+$4+$6)}') > "${p}"_gen0-6_pool.all.txt
  done

```

#13. Retrieve counts.
##Total observed counts.
###Exclude AF=0 VCFs:
####Retrieve derived counts per category:
#####All sites:
```{R, engine='bash'}

REGION="autosomes" #all #autosomes #Xchr

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata2/dani_k/consanguinidad_rapida/counts/

rm counts_pool_gen0-6_${REGION}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > counts_pool_gen0-6_${REGION}_summary.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-6_pool.txt' -print`))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
  MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
  MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
  LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> counts_pool_gen0-6_${REGION}_summary.txt
  done

#From the local environment:
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata2/dani_k/consanguinidad_rapida/counts_pool_gen0-6_${REGION}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/counts/

```

#####Low/High recombination subset:
```{R, engine='bash'}

RECOMBINATION="low" #low #high
REGION="autosomes" #all #autosomes #Xchr

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata2/dani_k/consanguinidad_rapida/counts/

rm counts_pool_gen0-6_${REGION}_summary.${RECOMBINATION}_recombination.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > counts_pool_gen0-6_${REGION}_summary.${RECOMBINATION}_recombination.txt
POOL_LIST=($(ls -v `find . -name '*_gen0-6_pool.'${RECOMBINATION}'_recombination.txt' -print`))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'/' -f2 | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | wc -l)
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | wc -l)
  MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | wc -l)
  MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | wc -l)
  LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> counts_pool_gen0-6_${REGION}_summary.${RECOMBINATION}_recombination.txt
  done

#From the local environment:
RECOMBINATION="high" #low #high
REGION="autosomes" #all #autosomes #Xchr
scp ramon.pouso@rua2.uvigo.es://share/rdata2/dani_k/consanguinidad_rapida/counts/counts_pool_gen0-6_${REGION}_summary.${RECOMBINATION}_recombination.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/counts/

```

##Rarefied counts.
###Find valid sites and generate depth tables:
```{R, engine='bash'}

for index in {10..46}
do
  head -n1 all_samples_gen0-6_pool.all.depth_table.txt | cut -f$index
  tail -n+2 all_samples_gen0-6_pool.all.depth_table.txt | awk -v col=$index '{ sum += $col } END { if (NR > 0) print sum / NR }'
done

^?

module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata2/dani_k/consanguinidad_rapida/counts/

#Create dataframe with the info from each site in the VCF:
echo -e "CHR\tSTART\tEND\tID\tANCESTRAL\tDERIVED\tQUAL\tFILTER\tINFO" > all_samples_gen0-6_pool.all.depth_table.txt
cat <$(ls pool*gen0-6_pool.all.txt | head -n1) | cut -f-9 | grep -v "^X" >> all_samples_gen0-6_pool.all.depth_table.txt

#Extract counts from each pool.
POOLS=$(ls pool*gen0-6_pool.all.txt)
for p in ${POOLS[@]}
  do
  echo "${p}"
  SAMPLE=$(echo $p | cut -d'_' -f-2)
  paste all_samples_gen0-6_pool.all.depth_table.txt <(cat <(echo $SAMPLE) <(grep -v "^X" "${p}" | awk -F"\t" '{printf ("%s\n", $10+$11)}')) > all_samples_gen0-6_pool.all.depth_table.temp.txt && mv all_samples_gen0-6_pool.all.depth_table.temp.txt all_samples_gen0-6_pool.all.depth_table.txt
  done

DEPTH=50 #input the desired target depth
#Count valid (1, if depth ≥ $DEPTH) and invalid (0, if depth < $DEPTH) sites per population (if any pool from that population doesn't reach the depth threshold, the site is invalid).
##Create dataframe with the info from each site in the VCF:
echo -e "CHR\tSTART\tEND\tID\tANCESTRAL\tDERIVED\tQUAL\tFILTER\tINFO" > all_samples_gen0-6_pool.all.depth_${DEPTH}_table.bool
cat <$(ls pool*gen0-6_pool.all.txt | head -n1) | cut -f-9 | grep -v "^X" >> all_samples_gen0-6_pool.all.depth_${DEPTH}_table.bool
POOLS=$(head -n1 all_samples_gen0-6_pool.all.depth_table.txt | tr '\t' '\n' | grep "pool" | cut -d'_' -f-1 | sort -u)
for pool in ${POOLS[@]}
  do
  echo "$pool"
  COLUMN_0=$(head -n1 all_samples_gen0-6_pool.all.depth_table.txt | tr '\t' '\n' | grep -nE "${pool}_gen0" | awk -F":" '{printf ("%s\n", $1)}')
  COLUMN_6=$(head -n1 all_samples_gen0-6_pool.all.depth_table.txt | tr '\t' '\n' | grep -nE "${pool}_gen6" | awk -F":" '{printf ("%s\n", $1)}')
  paste all_samples_gen0-6_pool.all.depth_${DEPTH}_table.bool <(cat <(echo "$pool") <(tail -n+2 all_samples_gen0-6_pool.all.depth_table.txt | awk -v gen0="$COLUMN_0" -v gen6="$COLUMN_6" -v target_depth="$DEPTH" -F"\t" '{ if (($gen0 >= target_depth) && ($gen6 >= target_depth)) {print 1} else {print 0} }' | grep -v "^X")) > all_samples_gen0-6_pool.all.depth_${DEPTH}_table.temp.bool && mv all_samples_gen0-6_pool.all.depth_${DEPTH}_table.temp.bool all_samples_gen0-6_pool.all.depth_${DEPTH}_table.bool
  done


#Summary statistics (for DEPTH=50)
DEPTH=50
##Total sites:
tail -n+2 all_samples_gen0-6_pool.all.depth_${DEPTH}_table.bool | wc -l #116562
##Valid in at least 60% of the lines:
awk '$10+$11+$12+$13+$14+$15+$16+$17+$18+$19 >= 6' all_samples_gen0-6_pool.all.depth_${DEPTH}_table.bool | sort -k1,1 -k2,2n -u > all_samples_gen0-6_pool.all.depth_${DEPTH}_valid.txt #109540 valid, which means 7022 invalid; the sort -u command was added to exclude 5 repeated sites


```

###Extract valid sites for each pool:
```{R, engine='bash'}

DEPTH=50 #input the desired target depth

module load gcc/7.2.0
module add gcc/7.2.0
cd /share/rdata2/dani_k/consanguinidad_rapida/counts

POOLS=$(ls pool*gen0-6_pool.all.txt)
for p in ${POOLS[@]}
  do
  echo "${p}"
  bedtools intersect -a <(sort -k1,1 -k2,2n -u "${p}") -b all_samples_gen0-6_pool.all.depth_${DEPTH}_valid.txt > ${p/.txt/.depth_${DEPTH}_valid.txt} #sort -k1,1 -k2,2n -u "${p}" this part of the code removes the few duplicate rows that have been passed down since the VCF. All resulting files have now 109540 sites for depth 50.
  done

```

###Extract state from all reads:
####extract_state_reads.sh
```{R, engine='bash'}

DEPTH=$1
cd /share/rdata2/dani_k/consanguinidad_rapida/counts
POOL=$(ls pool*gen0-6_pool.all.depth_${DEPTH}_valid.txt | head -n$SGE_TASK_ID | tail -n1)

rm ${POOL/.txt/_mod.txt}
while read -r CHR START STOP ID ANC_STATE DER_STATE QUALITY TAG INFO ANC_COUNT DER_COUNT
  do
  TOT_COUNT=$((ANC_COUNT + DER_COUNT))
  READS=$(echo "$(for i in $(seq 1 $ANC_COUNT); do printf "$ANC_STATE" ; done)""$(for i in $(seq 1 $DER_COUNT); do printf "$DER_STATE" ; done)")
  echo -e "$CHR\t$START\t$STOP\t$ANC_STATE\t$DER_STATE\t$ANC_COUNT\t$DER_COUNT\t$TOT_COUNT\t$READS" >> ${POOL/.txt/_mod.txt}
  done < $POOL

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/counts/extract_state_reads.sh

```

####Send the array-jobs:
```{R, engine='bash'}

#Run it as follows:
DEPTH=50 #Input the desired target depth
cd /share/rdata2/dani_k/consanguinidad_rapida/counts

POOL_N=$(ls pool*gen0-6_pool.all.depth_${DEPTH}_valid.txt | wc -l)
qsub -cwd -l h=compute-0-9 -t 1-$POOL_N /share/rdata2/dani_k/consanguinidad_rapida/counts/extract_state_reads.sh $DEPTH

```

###Generate rarefied counts:
####rarefied_counts.sh
```{R, engine='bash'}

DEPTH=$1
cd /share/rdata2/dani_k/consanguinidad_rapida/counts
POOL=$(ls pool*gen0-6_pool.all.depth_${DEPTH}_valid_mod.txt | head -n$SGE_TASK_ID | tail -n1)

for boot in {1..100}
  do
  N_BOOT=$(printf "%03d" ${boot})
  awk -v depth=$DEPTH -F"\t" 'BEGIN {"date +%N" | getline seed; srand(seed);} {if($8 >= depth) {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t", $1,$2,$3,$4,$5,$6,$7,$8); len=length($9); for(i=1;i<=depth;) {k=int(rand()*len)+1; if(!(k in N)) {N[k]; printf "%s", substr($9,k,1); i++;}} split("", N); print ""} else {printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,0,0,0,"N")}}' $POOL | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$7,$8,$9,gsub($4, "", $9),gsub($5, "", $9))}' > ./rarefied_counts/depth${DEPTH}/${POOL/.txt/.boot_${N_BOOT}.txt}
  done

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/rarefied_counts.sh

```

####Send the array-jobs:
```{R, engine='bash'}

#Run it as follows:
DEPTH=50 #Input the desired target depth
mkdir -p /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth${DEPTH}
cd /share/rdata2/dani_k/consanguinidad_rapida/counts

POOL_N=$(ls pool*gen0-6_pool.all.depth_${DEPTH}_valid_mod.txt | wc -l)
qsub -cwd -l h=compute-0-9 -t 1-$POOL_N /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/rarefied_counts.sh $DEPTH

```

###Obtain the average rarefied values:
```{bash}

DEPTH=50

cd /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth$DEPTH
module load gcc/7.2.0
module add gcc/7.2.0

#Generate file with the other columns from the VCF (the coordinates and other stuff):
cut -f-5 /share/rdata2/dani_k/consanguinidad_rapida/counts/all_samples_gen0-6_pool.all.depth_${DEPTH}_valid.txt > coordinates.txt.kaka
cut -f-9 /share/rdata2/dani_k/consanguinidad_rapida/counts/all_samples_gen0-6_pool.all.depth_${DEPTH}_valid.txt > coordinates_complete_vcf.txt.kaka

#For each pool, obtain average for columns 10 and 11 (rarefied ancestral and derived allele counts) between all 100 rarefied files, as well as a boolean column to indicate whether the site has enough coverage and is thus valid (1) or not (0), and, finally, the proportion of derived alleles relative to total alleles (in order to avoid a division by 0 fatal error, a ternary expression is used here to assign a 0 if the site is invalid, or run the operation otherwise):
for pop in $(ls /share/rdata2/dani_k/consanguinidad_rapida/counts/*.all.depth_${DEPTH}_valid_mod.txt | grep -v "all_samples" | rev | cut -d'/' -f1 | rev | cut -d'_' -f-2)
  do
  echo $pop
  ls ${pop}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.boot_*[[:digit:]]*.txt > ${pop}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.Nboot_100.list
  paste coordinates.txt <(gawk -v nboot=100 '{for (i=10;i<=NF;i++) total[FNR","i]+=$i;} END {for (j=1;j<=FNR;j++) {for (i=10;i<=NF;i++) printf "%.2f\t ",total[j","i]/nboot; print "";}}' $(<${pop}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.Nboot_100.list)) | awk -v depth=$DEPTH '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$5,$6,$7,($6+$7)/depth,(($6+$7)?$7/($6+$7):0))}' > ${pop}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.average.txt
  done

#Next, obtain the averages across all lines, considering only valid sites from each pool:
for gen in $(ls pool*depth_${DEPTH}_valid_mod.average.txt | cut -d'_' -f2 | sort -u)
  do
  echo $gen
  ls pool*_${gen}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.average.txt > ${gen}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.average.list
  paste coordinates.txt <(gawk '{for (i=6;i<=NF;i++) total[FNR","i]+=$i;} END {for (j=1;j<=FNR;j++) {printf("%.2f\t%.2f\t%d\t%.2f\n",total[j","6]/total[j","8],total[j","7]/total[j","8],total[j","8],total[j","9]/total[j","8])}}' $(<${gen}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.average.list)) > ${gen}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.lines_average.txt
  done

##Test if it has worked fine:
LINE=14 #input any number
gen="gen0" #gen0 gen6
for file in $(ls pool*${gen}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.average.txt)
  do
  head -n$LINE $file | tail -n1
  done
  head -n$LINE ${gen}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.lines_average.txt | tail -n1
#Check it against: "tail -n+2 /share/rdata2/dani_k/consanguinidad_rapida/counts/all_samples_gen0-6_pool.all.depth_${DEPTH}_table.bool | head -n$LINE | tail -n1" (where a 0 denotes that the site hasn't enough coverage in any of the two pools, that is, the gen0 or the gen6 one).

#Finally, include the other fields:
POOL_LIST=$(ls pool*gen0-6_pool.all.depth_${DEPTH}_valid_mod.average.txt)
for pool in ${POOL_LIST[@]}
  do
  echo "${pool}"
  bedtools intersect -a coordinates_complete_vcf.txt -b "${pool}" -wa -wb | cut -f-9,15- > ${pool/.txt/_complete.txt.kaka}
  done

##Additional tests to check counts in all rarefied files:
POOL_BOOT=$(ls pool01_gen0_gen0-6_pool.all.depth_${DEPTH}_valid_mod.boot_*.txt)
grep "CUSTOM=deleterious;" pool01_gen0_gen0-6_pool.all.depth_50_valid_mod.average_complete.txt | cut -f-3 > misdel.bed
grep "CUSTOM=LoF;" pool01_gen0_gen0-6_pool.all.depth_50_valid_mod.average_complete.txt | cut -f-3 > LoF.bed
rm pool01_gen0_gen0-6_pool.all.depth_${DEPTH}_valid_mod.LoF.count
for pool in ${POOL_BOOT[@]}
  do
  echo "${pool}"
  MISDEL_DER_COUNT=$(bedtools intersect -a ${pool} -b misdel.bed -wa | cut -f11 | paste -sd+ | bc)
  LOF_DER_COUNT=$(bedtools intersect -a ${pool} -b LoF.bed -wa | cut -f11 | paste -sd+ | bc)
  echo -e "$pool\t$MISDEL_DER_COUNT\t$LOF_DER_COUNT" >> pool01_gen0_gen0-6_pool.all.depth_${DEPTH}_valid_mod.LoF.count
  done

```

###Retrieve counts:
####Whole dataset:
#####Retrieve derived counts per category:
######All sites:
```{R, engine='bash'}

REGION="all" #all #autosomes #Xchr
DEPTH=50

cd /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth$DEPTH/
rm rarefied_depth_${DEPTH}_counts_pool_gen0-6_${REGION}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > rarefied_depth_${DEPTH}_counts_pool_gen0-6_${REGION}_summary.txt
POOL_LIST=($(ls pool*gen0-6_pool.all.depth_${DEPTH}_valid_mod.average_complete.txt))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | awk '$11 > 0' | wc -l)
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | awk '$11 > 0' | wc -l)
  MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | awk '$11 > 0' | wc -l)
  MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | awk '$11 > 0' | wc -l)
  LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> rarefied_depth_${DEPTH}_counts_pool_gen0-6_${REGION}_summary.txt
  done

#From the local environment:
REGION="all" #all #autosomes #Xchr
DEPTH=50
scp ramon.pouso@rua2.uvigo.es://share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth${DEPTH}/rarefied_depth_${DEPTH}_counts_pool_gen0-6_${REGION}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/counts/rarefied/depth${DEPTH}/

```

######Low/High recombination sites:
```{R, engine='bash'}

RECOMBINATION="low" #low #high
REGION="all" #all
DEPTH=50

module load gcc/7.2.0
module add gcc/7.2.0

cd /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth$DEPTH/
rm rarefied_depth_${DEPTH}_counts_pool_gen0-6_${REGION}_summary.${RECOMBINATION}_recombination.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > rarefied_depth_${DEPTH}_counts_pool_gen0-6_${REGION}_summary.${RECOMBINATION}_recombination.txt
POOL_LIST=($(ls pool*gen0-6_pool.all.depth_${DEPTH}_valid_mod.average_complete.txt))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  bedtools intersect -a $pool -b /share/rdata2/dani_k/consanguinidad_rapida/variants/crisp_all_pools_gen0-6.all_sites.orthologs.confident.bcf_filtered.masked.DP_EM_filtered.polarisable.polarized.nr_annovar.dm6nr_multianno.${RECOMBINATION}_recombination.bed > ${pool/.txt/.${RECOMBINATION}_recombination.txt}
  p=${pool/.txt/.${RECOMBINATION}_recombination.txt}
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | awk '$11 > 0' | wc -l)
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | awk '$11 > 0' | wc -l)
  MISTOL_D=$(grep "CUSTOM=tolerated;" $p | awk '{print $11}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | awk '$11 > 0' | wc -l)
  MISDEL_D=$(grep "CUSTOM=deleterious;" $p | awk '{print $11}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | awk '$11 > 0' | wc -l)
  LOF_D=$(grep "CUSTOM=LoF;" $p | awk '{print $11}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> rarefied_depth_${DEPTH}_counts_pool_gen0-6_${REGION}_summary.${RECOMBINATION}_recombination.txt
  done

#From the local environment:
RECOMBINATION="low" #low #high
REGION="all" #all #autosomes #Xchr
DEPTH=50
scp ramon.pouso@rua2.uvigo.es://share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth${DEPTH}/rarefied_depth_${DEPTH}_counts_pool_gen0-6_${REGION}_summary.${RECOMBINATION}_recombination.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/counts/rarefied/depth${DEPTH}/

```

#####Retrieve total counts per category:
```{R, engine='bash'}

REGION="all" #all #autosomes #Xchr
DEPTH=50

cd /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth$DEPTH/
rm rarefied_depth_${DEPTH}_ancestralplusderived_counts_pool_gen0-6_${REGION}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_T\ttolerated_V\ttolerated_T\tdeleterious_V\tdeleterious_T\tLoF_V\tLoF_T" > rarefied_depth_${DEPTH}_ancestralplusderived_counts_pool_gen0-6_${REGION}_summary.txt
POOL_LIST=($(ls pool*gen0-6_pool.all.depth_${DEPTH}_valid_mod.average_complete.txt))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    if [ ! -f ${pool/.txt/_${REGION}.txt} ]
      then
      grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    fi
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    if [ ! -f ${pool/.txt/_${REGION}.txt} ]
      then
      grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    fi
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" $p | awk '$12 > 0' | wc -l)
  FOURFOLD_T=$(grep "CUSTOM=fourfold;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" $p | awk '$12 > 0' | wc -l)
  MISTOL_T=$(grep "CUSTOM=tolerated;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" $p | awk '$12 > 0' | wc -l)
  MISDEL_T=$(grep "CUSTOM=deleterious;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" $p | awk '$12 > 0' | wc -l)
  LOF_T=$(grep "CUSTOM=LoF;" $p | awk '{print ($10 + $11)}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_T\t$MISTOL_V\t$MISTOL_T\t$MISDEL_V\t$MISDEL_T\t$LOF_V\t$LOF_T" >> rarefied_depth_${DEPTH}_ancestralplusderived_counts_pool_gen0-6_${REGION}_summary.txt
  done

#From the local environment:
REGION="all" #all #autosomes #Xchr
DEPTH=50
scp ramon.pouso@rua2.uvigo.es://share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth$DEPTH/rarefied_depth_${DEPTH}_ancestralplusderived_counts_pool_gen0-6_${REGION}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/counts/rarefied/depth$DEPTH/

```

#####Retrieve proportion of derived counts per category:
```{R, engine='bash'}

REGION="all" #all #autosomes #Xchr
DEPTH=50

cd /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth$DEPTH/
rm rarefied_depth_${DEPTH}_proportion_pool_gen0-6_${REGION}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_P\ttolerated_V\ttolerated_P\tdeleterious_V\tdeleterious_P\tLoF_V\tLoF_P" > rarefied_depth_${DEPTH}_proportion_pool_gen0-6_${REGION}_summary.txt
POOL_LIST=($(ls pool*gen0-6_pool.all.depth_${DEPTH}_valid_mod.average_complete.txt))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    if [ ! -f ${pool/.txt/_${REGION}.txt} ]
      then
      grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    fi
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    if [ ! -f ${pool/.txt/_${REGION}.txt} ]
      then
      grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    fi
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  FOURFOLD_VALID=$(grep "CUSTOM=fourfold;" $p | awk '$12 == 1' | wc -l)
  FOURFOLD_PROP_SUM=$(grep "CUSTOM=fourfold;" $p | awk '{print $13}' | paste -sd+ | bc)
  FOURFOLD_PROP_AVE=$(echo "scale=3; $FOURFOLD_PROP_SUM/$FOURFOLD_VALID" | bc)
  MISTOL_VALID=$(grep "CUSTOM=tolerated;" $p | awk '$12 == 1' | wc -l)
  MISTOL_PROP_SUM=$(grep "CUSTOM=tolerated;" $p | awk '{print $13}' | paste -sd+ | bc)
  MISTOL_PROP_AVE=$(echo "scale=3; $MISTOL_PROP_SUM/$MISTOL_VALID" | bc)
  MISDEL_VALID=$(grep "CUSTOM=deleterious;" $p | awk '$12 == 1' | wc -l)
  MISDEL_PROP_SUM=$(grep "CUSTOM=deleterious;" $p | awk '{print $13}' | paste -sd+ | bc)
  MISDEL_PROP_AVE=$(echo "scale=3; $MISDEL_PROP_SUM/$MISDEL_VALID" | bc)
  LOF_VALID=$(grep "CUSTOM=LoF;" $p | awk '$12 == 1' | wc -l)
  LOF_PROP_SUM=$(grep "CUSTOM=LoF;" $p | awk '{print $13}' | paste -sd+ | bc)
  LOF_PROP_AVE=$(echo "scale=3; $LOF_PROP_SUM/$LOF_VALID" | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_VALID\t$FOURFOLD_PROP_AVE\t$MISTOL_VALID\t$MISTOL_PROP_AVE\t$MISDEL_VALID\t$MISDEL_PROP_AVE\t$LOF_VALID\t$LOF_PROP_AVE" >> rarefied_depth_${DEPTH}_proportion_pool_gen0-6_${REGION}_summary.txt
  done

#From the local environment:
REGION="all" #all #autosomes #Xchr
DEPTH=50
scp ramon.pouso@rua2.uvigo.es://share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth$DEPTH/rarefied_depth_${DEPTH}_proportion_pool_gen0-6_${REGION}_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/counts/rarefied/depth$DEPTH/

```

####Sites from each line:
#####Retrieve derived counts per category:
######count_derived_copies_from_line_sites_all.sh:
```{R, engine='bash'}

export PATH=$PATH:/share/apps/bedtools2/bin:/share/apps/est-sfs-release-2.03/:/share/apps/BAMTOOLS/bin:/share/apps/bedtools2/bin
module load gcc/7.2.0
module add gcc/7.2.0

REGION="all" #all #autosomes #Xchr
DEPTH=$1
POOL=$(printf "%02d" ${SGE_TASK_ID})

cd /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth$DEPTH/
rm sitesinline${POOL}_rarefied_depth_${DEPTH}_counts_pool_gen0-6_${REGION}_summary.txt
echo -e "sample\tgeneration\tfourfold_V\tfourfold_D\ttolerated_V\ttolerated_D\tdeleterious_V\tdeleterious_D\tLoF_V\tLoF_D" > sitesinline${POOL}_rarefied_depth_${DEPTH}_counts_pool_gen0-6_${REGION}_summary.txt
POOL_LIST=($(ls pool*gen0-6_pool.all.depth_${DEPTH}_valid_mod.average_complete.txt))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  if [ $REGION == "autosomes" ]
    then
    grep -v "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "Xchr" ]
    then
    grep "^X" $pool > ${pool/.txt/_${REGION}.txt}
    p=${pool/.txt/_${REGION}.txt}
  elif [ $REGION == "all" ]
    then
    p=${pool}
  fi
  bedtools intersect -a $p -b sitesinline${POOL}_${GEN}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.bed > ${p/pool/sitesinline${POOL}_pool}
  FOURFOLD_V=$(grep "CUSTOM=fourfold;" ${p/pool/sitesinline${POOL}_pool} | wc -l)
  FOURFOLD_D=$(grep "CUSTOM=fourfold;" ${p/pool/sitesinline${POOL}_pool} | awk '{print $11}' | paste -sd+ | bc)
  MISTOL_V=$(grep "CUSTOM=tolerated;" ${p/pool/sitesinline${POOL}_pool} | wc -l)
  MISTOL_D=$(grep "CUSTOM=tolerated;" ${p/pool/sitesinline${POOL}_pool} | awk '{print $11}' | paste -sd+ | bc)
  MISDEL_V=$(grep "CUSTOM=deleterious;" ${p/pool/sitesinline${POOL}_pool} | wc -l)
  MISDEL_D=$(grep "CUSTOM=deleterious;" ${p/pool/sitesinline${POOL}_pool} | awk '{print $11}' | paste -sd+ | bc)
  LOF_V=$(grep "CUSTOM=LoF;" ${p/pool/sitesinline${POOL}_pool} | wc -l)
  LOF_D=$(grep "CUSTOM=LoF;" ${p/pool/sitesinline${POOL}_pool} | awk '{print $11}' | paste -sd+ | bc)
  echo -e "$SAMPLE\t$GEN\t$FOURFOLD_V\t$FOURFOLD_D\t$MISTOL_V\t$MISTOL_D\t$MISDEL_V\t$MISDEL_D\t$LOF_V\t$LOF_D" >> sitesinline${POOL}_rarefied_depth_${DEPTH}_counts_pool_gen0-6_${REGION}_summary.txt
  done

#Save this code as: /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth$DEPTH/count_derived_copies_from_line_sites_all.sh

```

######Generate list of sites from each line:
```{R, engine='bash'}

DEPTH=50
cd /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth$DEPTH/

POOL_LIST=($(ls pool*gen0-6_pool.all.depth_${DEPTH}_valid_mod.average_complete.txt))
for pool in "${POOL_LIST[@]}"
  do
  echo "${pool}"
  SAMPLE=$(echo "${pool}" | cut -d'_' -f1 | cut -c5-6)
  GEN=$(echo "${pool}" | cut -d'_' -f2)
  awk '$11 > 0 {printf ("%s\t%s\t%s\n", $1,$2,$3)}' ${pool} > sitesinline${SAMPLE}_${GEN}_gen0-6_pool.all.depth_${DEPTH}_valid_mod.bed
  done

POOL_N=$(ls pool*_gen0-6_pool.all.depth_${DEPTH}_valid_mod.average_complete.txt | cut -d'_' -f-1 | sort -u | wc -l)
qsub -cwd -l h=compute-0-9 -t 1-$POOL_N /share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth$DEPTH/count_derived_copies_from_line_sites_all.sh $DEPTH


#To download the resulting files, from the local environment:
REGION="all" #all #autosomes #Xchr
DEPTH=50
scp ramon.pouso@rua2.uvigo.es://share/rdata2/dani_k/consanguinidad_rapida/counts/rarefied_counts/depth${DEPTH}/sitesinline*_rarefied_depth_${DEPTH}_counts_pool_gen0-6_all_summary.txt /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/counts/rarefied/depth${DEPTH}/

```


#14. Plot counts.
##Derived count statistics:
###Derived count ratios (relative to 4fold and gen0):
####Rarefied data:
#####Whole dataset:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


#Define variables and read raw counts file:
depth <- 50
type <- "autosomes" #all #autosomes #Xchr

wd_path <- paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/counts/rarefied/depth",depth,"/")
pool_counts <- read_tsv(paste0(wd_path,"rarefied_depth_",depth,"_counts_pool_gen0-6_",type,"_summary.txt")) %>% rename(population = sample)

pool_counts$population = factor(pool_counts$population)
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

#Relativise by fourfold category:
pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

#Relativise by generation 0:
r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  for (p in unique(pool_counts_copies_4FR$population)) {
    r_average <- filter(pool_counts_copies_4FR,r==ratio & population==p & generation==0) %>% select(value) %>% unlist(.,use.names=F)
    r_average_vector <- c(r_average_vector,rep(r_average,2))
  }
}
print(r_average_vector)
relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, gen0_relative_value=value/r_average_vector)

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function
average_relativised_pool_counts_copies_4FR <- data_frame("generation"=character(0),"ratio"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe
for (g in unique(relativised_pool_counts_copies_4FR$generation)) {
#species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
  for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
    print(r)
    pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g) %>% select(gen0_relative_value) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," average is ",pop_mean))
    pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g) %>% select(gen0_relative_value) %>% unlist(.,use.names=F) %>% se()
    #print(paste0(pop," feature ",r," std error is ",pop_se))
    row_data <- cbind(g,r,pop_mean,pop_se)
    colnames(row_data) <- c("generation","ratio","avg_value","se_value")
    average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
  }
}
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_value)
average_relativised_pool_counts_copies_4FR$se_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_value)
average_relativised_pool_counts_copies_4FR


#Average version:
average_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,ratio!="fourfold"), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=avg_value-2*se_value, ymax=avg_value+2*se_value, colour=generation),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative\n to that of generation 0") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  #scale_shape_manual(values=c(1,16)) +
  ggtitle(paste0("Average of pools, rarefied data (cov. ",depth,")")) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
average_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("rarefied_depth_",depth,"_pool_avg_relativised_counts_copies_4FR_",type,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)


#Each line separate version:
average_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(relativised_pool_counts_copies_4FR,ratio!="fourfold"), aes(population,gen0_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  #geom_errorbar(aes(ymin=avg_value-2*se_value, ymax=avg_value+2*se_value, colour=generation),size=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=generation),size=2) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative\n to that of generation 0") +
  #ylim(0.8,1.1) +
  scale_y_continuous(breaks = seq(0.8, 1.2, by = 0.1), limits=c(0.78, 1.1)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle(paste0("Separate pools, rarefied data (cov. ",depth,")")) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10, angle=90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
average_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("rarefied_depth_",depth,"_pool_sep_relativised_counts_copies_4FR_",type,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

```

#####Each line dataset:
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)


#Define variables and read raw counts file:
lines <- c(1:10)
depth <- 50
type <- "autosomes" #all #autosomes #Xchr

for (l in seq(lines)) {
line <- sprintf("%02d",l)
wd_path <- paste0("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/counts/rarefied/depth",depth,"/")
pool_counts <- read_tsv(paste0(wd_path,"sitesinline",line,"_rarefied_depth_",depth,"_counts_pool_gen0-6_",type,"_summary.txt")) %>% rename(population = sample)

pool_counts$population = factor(pool_counts$population)
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

#Relativise by fourfold category:
pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

#Relativise by generation 0:
r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  for (p in unique(pool_counts_copies_4FR$population)) {
    r_average <- filter(pool_counts_copies_4FR,r==ratio & population==p & generation==0) %>% select(value) %>% unlist(.,use.names=F)
    r_average_vector <- c(r_average_vector,rep(r_average,2))
  }
}
print(r_average_vector)
relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, gen0_relative_value=value/r_average_vector)

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function
average_relativised_pool_counts_copies_4FR <- data_frame("generation"=character(0),"ratio"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe
for (g in unique(relativised_pool_counts_copies_4FR$generation)) {
#species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
  for (r in unique(relativised_pool_counts_copies_4FR$ratio)) {
    print(r)
    pop_mean <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g) %>% select(gen0_relative_value) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," average is ",pop_mean))
    pop_se <- filter(relativised_pool_counts_copies_4FR,ratio==r & generation==g) %>% select(gen0_relative_value) %>% unlist(.,use.names=F) %>% se()
    #print(paste0(pop," feature ",r," std error is ",pop_se))
    row_data <- cbind(g,r,pop_mean,pop_se)
    colnames(row_data) <- c("generation","ratio","avg_value","se_value")
    average_relativised_pool_counts_copies_4FR <- rbind(average_relativised_pool_counts_copies_4FR,row_data,stringsAsFactors=F)
  }
}
average_relativised_pool_counts_copies_4FR$ratio = factor(average_relativised_pool_counts_copies_4FR$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_relativised_pool_counts_copies_4FR$generation <- as.factor(as.numeric(average_relativised_pool_counts_copies_4FR$generation))
average_relativised_pool_counts_copies_4FR$avg_value <- as.numeric(average_relativised_pool_counts_copies_4FR$avg_value)
average_relativised_pool_counts_copies_4FR$se_value <- as.numeric(average_relativised_pool_counts_copies_4FR$se_value)
average_relativised_pool_counts_copies_4FR

#Relativise by the average of generation 0:
r_average_vector <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  for (gen in unique(pool_counts_copies_4FR$generation)) {
    r_average <- filter(pool_counts_copies_4FR,r==ratio & generation==0) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
    r_average_vector <- c(r_average_vector,rep(r_average,length(levels(pool_counts_copies_4FR$population))))
  }
}
print(r_average_vector)
avg_relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, avg_gen0_relative_value=value/r_average_vector)


#Average version:
average_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(average_relativised_pool_counts_copies_4FR,ratio!="fourfold"), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=avg_value-2*se_value, ymax=avg_value+2*se_value, colour=generation),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative\n to that of generation 0") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  #scale_shape_manual(values=c(1,16)) +
  ggtitle(paste0("Average of pools, rarefied data (cov. ",depth,") from line ",line)) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
average_relativised_pool_counts_copies_4FR_ggplot
#ggsave(paste0("rarefied_depth_",depth,"_pool_avg_relativised_counts_copies_4FR_",type,".sitesinline",line,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)


#Each line separate version, all gen0 values at 1:
sep_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(relativised_pool_counts_copies_4FR,ratio!="fourfold"), aes(population,gen0_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  #geom_errorbar(aes(ymin=avg_value-2*se_value, ymax=avg_value+2*se_value, colour=generation),size=0.5,width=0.5) +
  geom_point(aes(colour=population,shape=generation),size=2) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative\n to that of generation 0") +
  #ylim(0.8,1.1) +
  scale_y_continuous(breaks = seq(0.8, 1.2, by = 0.1)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle(paste0("Separate pools, rarefied data (cov. ",depth,") from line ",line)) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10, angle=90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
sep_relativised_pool_counts_copies_4FR_ggplot
#ggsave(paste0("rarefied_depth_",depth,"_pool_sep_relativised_counts_copies_4FR_",type,".sitesinline",line,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)


#Each line separate version, relativised by the average of gen0:
sep_avg_relativised_pool_counts_copies_4FR_ggplot <- ggplot(data=filter(avg_relativised_pool_counts_copies_4FR,ratio!="fourfold"), aes(population,avg_gen0_relative_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  #geom_errorbar(aes(ymin=avg_value-2*se_value, ymax=avg_value+2*se_value, colour=generation),size=0.5,width=0.5) +
  geom_point(aes(colour=generation,shape=generation),size=2) + 
  #ggtitle("Proportion of reads at different NM") +
  ylab("Derived count relative\n to that of generation 0") +
  #ylim(0.8,1.1) +
  scale_y_continuous(breaks = seq(0.8, 1.2, by = 0.1)) +
  scale_shape_manual(values=c(1,16)) +
  ggtitle(paste0("Separate pools, rarefied data (cov. ",depth,") from line ",line)) +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        axis.title=element_text(size=16),
        axis.text=element_text(size=10,colour="black"),
        axis.text.x=element_text(colour="black",size=10, angle=90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        #panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0.5,0.5,0.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.title=element_blank()
  )
sep_avg_relativised_pool_counts_copies_4FR_ggplot
ggsave(paste0("rarefied_depth_",depth,"_pool_sep_avg0_relativised_counts_copies_4FR_",type,".sitesinline",line,".pdf"), width=15, height=12, units="cm", device="pdf", path=wd_path)

}

```

####Simulations (fecundity model), ratio of averages, with replicate errors:
#####U=0.04, K=1000, sthres=0.5:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_control","L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_epistasia") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_control") {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_epistasia") {
  average_combined_tidy_purging_epistasia <- average_combined_tidy_bis
}
}



#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging model") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging + epistasis model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))

ggsave("20240115_simulations_Pb12_rel.ratio_of_averages.pdf", width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)

#Stop
STOP

```

######Relative to li-12: only lines, all relative to Pb-12 (like with the empirical ones)
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_control","L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_epistasia") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt")) %>% filter((population!="average"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  for (p in unique(pool_counts_copies_4FR$population)) {
    r_average <- filter(pool_counts_copies_4FR,r==ratio & population==p & generation==12) %>% select(value) %>% unlist(.,use.names=F)
    r_average_vector <- c(r_average_vector,rep(r_average,7))
    r_average_errors <- c(r_average_errors,rep(r_average,7))
  }
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, gen0_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt")) %>% filter((population!="average"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,gen0_relative_value,value.y) %>% filter((population!="Pb"))
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")


#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function
average_combined_tidy <- data_frame("generation"=character(0),"ratio"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe
for (g in unique(combined_tidy$generation)) {
#species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
  for (r in unique(combined_tidy$ratio)) {
    print(r)
    pop_mean <- filter(combined_tidy,ratio==r & generation==g) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," average is ",pop_mean))
    pop_se <- filter(combined_tidy,ratio==r & generation==g) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," std error is ",pop_se))
    row_data <- cbind(g,r,pop_mean,pop_se)
    colnames(row_data) <- c("generation","ratio","avg_value","se_value")
    average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
  }
}
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$avg_value <- as.numeric(average_combined_tidy$avg_value)
average_combined_tidy$se_value <- as.numeric(average_combined_tidy$se_value)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Store each dataframe separately for the combined figure:
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_control") {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.Purging_epistasia") {
  average_combined_tidy_purging_epistasia <- average_combined_tidy_bis
}
}


#Plot the data (all models combined):

##All gens:
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value, colour=generation),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  #scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging model") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value, colour=generation),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging + epistasis model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to li-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))

ggsave("20240115_simulations_li12_rel.ratio_of_averages.all.pdf", width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)




##Only gens 0 (12) and 6 (18):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold",ratio!="m. tolerated",(generation==12 | generation==18)), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value, colour=generation),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  #scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging model") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold",ratio!="m. tolerated",(generation==12 | generation==18)), aes(generation,avg_value)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value, colour=generation),size=0.5,width=0.5) +
  geom_point(aes(colour=generation),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging + epistasis model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to li-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))

ggsave("20240115_simulations_li12_rel.ratio_of_averages.0-6.pdf", width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)

```

#####U=0.04, K=1000, sthres=0.75:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.75.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.75.Purging") {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.75.Purging_epistasia") {
  average_combined_tidy_purging_epistasia <- average_combined_tidy_bis
}
}



#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging model") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control


Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging + epistasis model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))
ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))

ggsave("20240131_simulations_Pb12_rel.sthres0.75.ratio_of_averages.pdf", width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)


#Stop
STOP

```

#####U=0.04, K=1000, sthres=0.99:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging") {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging_epistasia") {
  average_combined_tidy_purging_epistasia <- average_combined_tidy_bis
}
}



#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging model") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control


Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging + epistasis model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))
ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))

ggsave(paste0("20240301_simulations_Pb12_rel.",parameters_list,".ratio_of_averages.pdf"), width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)


#Stop
STOP

```

#####U=0.04, K=1000, s0.01.s0.5.s0.99:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.s0.01.s0.5.s0.99.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
#if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging") {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
#} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging_epistasia") {
#  average_combined_tidy_purging_epistasia <- average_combined_tidy_bis
#}
}



#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle(parameters_list) + #ggtitle("Purging model") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control


Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging + epistasis model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))
ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))

ggsave(paste0("20240301_simulations_Pb12_rel.",parameters_list,".ratio_of_averages.pdf"), width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)


#Stop
STOP

```

#####U=0.04, K=1000, s0.05.s0.5.s0.99:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.s0.05.s0.5.s0.99.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
#if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging") {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
#} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging_epistasia") {
#  average_combined_tidy_purging_epistasia <- average_combined_tidy_bis
#}
}



#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle(parameters_list) + #ggtitle("Purging model") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control


Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging + epistasis model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))
ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))

ggsave(paste0("20240313_simulations_Pb12_rel.",parameters_list,".ratio_of_averages.pdf"), width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)


#Stop
STOP

```

#####U=0.04, K=1000, regular mating system, s0.05.s0.5.s0.99:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.s0.05.s0.5.s0.99.regular_mating.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
#if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging") {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
#} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging_epistasia") {
#  average_combined_tidy_purging_epistasia <- average_combined_tidy_bis
#}
}



#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle(parameters_list) + #ggtitle("Purging model") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control


Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging + epistasis model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))
ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))

ggsave(paste0("20240313_simulations_Pb12_rel.",parameters_list,".ratio_of_averages.pdf"), width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)


#Stop
STOP

```

#####U=0.2, K=2000, s0.01.s0.5.s0.99:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("L0.2.L_lethal0.015.K2000.beta0.33.s0.2.h0.283.s0.01.s0.5.s0.99.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
#if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging") {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
#} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging_epistasia") {
#  average_combined_tidy_purging_epistasia <- average_combined_tidy_bis
#}
}



#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle(parameters_list) + #ggtitle("Purging model") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control


Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging + epistasis model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))
ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))

ggsave(paste0("20240301_simulations_Pb12_rel.",parameters_list,".ratio_of_averages.pdf"), width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)


#Stop
STOP

```

#####B=1, U=0.2, K=2000, s0.01.s0.5.s0.99:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("L0.2.L_lethal0.015.K2000.beta1.s0.2.h0.283.s0.01.s0.5.s0.99.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
#if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging") {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
#} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging_epistasia") {
#  average_combined_tidy_purging_epistasia <- average_combined_tidy_bis
#}
}



#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle(parameters_list) + #ggtitle("Purging model") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control


Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging + epistasis model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))
ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))

ggsave(paste0("20240308_simulations_Pb12_rel.",parameters_list,".ratio_of_averages.pdf"), width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)


#Stop
STOP

```

#####B=2, U=0.2, K=2000, s0.0001.s0.1.s0.99:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("L0.2.L_lethal0.015.K2000.beta2.s0.2.h0.283.s0.0001.s0.1.s0.99.Purging") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
#if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging") {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
#} else if (parameters=="L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.sthres0.99.Purging_epistasia") {
#  average_combined_tidy_purging_epistasia <- average_combined_tidy_bis
#}
}



#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle(parameters_list) + #ggtitle("Purging model") +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control


Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold",ratio!="m. tolerated"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0.6, 1.2, by = 0.2), limits=c(0.5, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging + epistasis model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

#ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))
ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))

ggsave(paste0("20240319_simulations_Pb12_rel.",parameters_list,".ratio_of_averages.pdf"), width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)


#Stop
STOP

```

####Simulations (viability model), ratio of averages, with replicate errors:
#####Purging with and without epistasia:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls via_L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("via_L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.s0.s0.05.s1.Purging","via_L0.04.L_lethal0.015.K1000.beta0.33.s0.2.h0.283.s0.s0.05.s1.Purging_epistasia") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt"))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt"))
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (grepl("epistasia",parameters)) {
  average_combined_tidy_purging_epistasia <- average_combined_tidy_bis
  } else {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
  }
}


#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.4,1.2) +
  scale_y_continuous(breaks = seq(0.4, 1.2, by = 0.2), limits=c(0.3, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Purging model") + #ggtitle(parameters_list[1]) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control


Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia <- ggplot(data=filter(average_combined_tidy_purging_epistasia,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) +
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.4,1.2) +
  scale_y_continuous(breaks = seq(0.4, 1.2, by = 0.2), limits=c(0.3, 1.3)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Epistasia model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia


library(grid)
library(gridExtra)
library(egg)

#Purging and epistasia:
ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_epistasia,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))
ggsave(paste0("20240506_simulations_Pb12_rel.",parameters_list,".epistasia.ratio_of_averages.pdf"), width=27, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)

#Only purging:
ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))
ggsave(paste0("20240506_simulations_Pb12_rel.",parameters_list,".ratio_of_averages.pdf"), width=19.5, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)

#Stop
STOP

```

#####Purging vs additive vs neutral:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls via_L*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("via_L0.2.L_lethal0.015.K2000.beta0.33.s0.2.h0.283.s0.s0.05.s0.9.Purging","via_L0.2.L_lethal0.015.K2000.beta0.33.s0.2.h0.5.s0.s0.05.s0.9.Additive","via_L0.2.L_lethal0.015.K2000.beta0.33.s0.2.h0.283.s0.s0.05.s0.9.Neutral") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,parameters,"_derived_count.txt")) %>% filter(population!="average")
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Errors:
pool_errors <- read_tsv(paste0(wd_path,parameters,"_derived_count_se_relative.txt")) %>% filter(population!="average")
pool_errors$population = factor(pool_errors$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
  #line_correct_data <- filter(pool_counts,population!="Pb") %>% select(population) %>% unlist(.,use.names=F) #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
  #pool_errors$population[c(6:nrow(pool_errors))] <- line_correct_data #use this only to fix the population names for files that show "Pb" for all entries due to a bug in the simulations programme.
pool_errors$generation <- as.numeric(gsub("gen","",pool_errors$generation))
pool_errors <- pool_errors %>% arrange(generation)
pool_errors$generation = factor(pool_errors$generation)
pool_errors <- pool_errors %>% arrange(population,generation)

pool_errors_copies <- pool_errors %>% mutate(fourfold=fourfold_D_rel,tolerated=tolerated_D_rel,deleterious=deleterious_D_rel,LoF=LoF_D_rel) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_errors_copies <- pool_errors_copies %>% mutate(group=ifelse(population=="Pb","Pb","lines"))
pool_errors_copies$group = factor(pool_errors_copies$group,levels=c("Pb","lines"))
pool_errors_copies


#Combined:
combined_tidy <- left_join(relativised_pool_counts_copies_4FR,pool_errors_copies,by=c("population","generation","ratio","group")) %>% select(group,population,generation,ratio,Pb_relative_value,value.y)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean","error")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0),"error"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean,pop_se)
      colnames(row_data) <- c("population","generation","ratio","mean","error")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy$error <- as.numeric(average_combined_tidy$error)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (grepl("Neutral",parameters)) {
  average_combined_tidy_neutral <- average_combined_tidy_bis
  } else if (grepl("Additive",parameters)) {
  average_combined_tidy_additive <- average_combined_tidy_bis
  } else {
  average_combined_tidy_purging_control <- average_combined_tidy_bis
  }
}


#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral <- ggplot(data=filter(average_combined_tidy_neutral,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.2,1.8) +
  scale_y_continuous(breaks = seq(0.2, 1.8, by = 0.4), limits=c(0.1, 1.9)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Neutral model") + #ggtitle(parameters_list[1]) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,0,0,-2.5),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive <- ggplot(data=filter(average_combined_tidy_additive,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.2,1.8) +
  scale_y_continuous(breaks = seq(0.2, 1.8, by = 0.4), limits=c(0.1, 1.9)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Additive model") + #ggtitle(parameters_list[1]) +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_blank(),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.3,1.15),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.75,0.95,0.75),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive

Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control <- ggplot(data=filter(average_combined_tidy_purging_control,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) +
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.2,1.8) +
  scale_y_continuous(breaks = seq(0.2, 1.8, by = 0.4), limits=c(0.1, 1.9)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  #ggtitle("Purging model") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0,0,0.5,-2.5),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        #legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control


library(grid)
library(gridExtra)
library(egg)

#Purging and epistasia:
ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_neutral,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_additive,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_purging_control,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=1,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.38,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2),right=textGrob(expression(bold("Neutral model                                         Additive model                                      Purging model")),rot=-90,gp=gpar(fontsize=11,fontface="bold"),x=-5,vjust=0,hjust=0.51))
ggsave(paste0("20240429_simulations_Pb12_rel.",parameters_list[1],".additive.neutral.ratio_of_averages.pdf"), width=16.5, height=22.5, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)

#Stop
STOP

```

#####Test sample with and without replacement:
######Relative to Pb-12:
```{r Plot variant count results}

#We obtain errors from the distribution of double ratios across replicates. The raw count average is obtained across replicates, and then relativised twice.

#In this method we calculate the SE (sqrt(variance(N)/N)) of all replicas for each population, including the lines and the Pb. Then we represent the average of the upper and lower values in the case of the 19 lines.

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)

#To make the input file work, do the following:
#cd /Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/
#FILES=$(ls test_derived*.dat)
#for file in ${FILES[@]}; do echo "$file"; cat ${file} | tr -s " " | tr " " "\t" | sed 's/[[:space:]]*$//' > ${file/.dat/.txt}; done

wd_path <- ("/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/")

parameters_list <- c("_with_replacement.txt","_without_replacement.txt") 

for (parameters in parameters_list) {
print(parameters)

#Averages:
pool_counts <- read_tsv(paste0(wd_path,"test_derived_count",parameters))
pool_counts$population = factor(pool_counts$population,levels=c("Pb","Line1","Line2","Line3","Line4","Line5","Line6","Line7","Line8","Line9","Line10"))
pool_counts$generation <- as.numeric(gsub("gen","",pool_counts$generation))
pool_counts <- pool_counts %>% arrange(generation)
pool_counts$generation = factor(pool_counts$generation)
pool_counts <- pool_counts %>% arrange(population,generation)

pool_counts_copies_4FR <- pool_counts %>% mutate(fourfold=fourfold_D/fourfold_D,tolerated=tolerated_D/fourfold_D,deleterious=deleterious_D/fourfold_D,LoF=LoF_D/fourfold_D) %>% select(!contains(c("_V","_D","sample"))) %>% gather(ratio,value,-generation,-population,factor_key=T)
pool_counts_copies_4FR

r_average_vector <- c()
r_average_errors <- c()
for (r in unique(pool_counts_copies_4FR$ratio)) {
  print(r)
  r_average <- filter(pool_counts_copies_4FR,r==ratio & population=="Pb" & generation==12) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(pool_counts_copies_4FR,r==ratio))))
  r_average_errors <- c(r_average_errors,rep(r_average,2))
}
print(r_average_vector)
print(r_average_errors)

relativised_pool_counts_copies_4FR <- mutate(pool_counts_copies_4FR, Pb_relative_value=value/r_average_vector, group=ifelse(population=="Pb","Pb","lines"))
relativised_pool_counts_copies_4FR$group = factor(relativised_pool_counts_copies_4FR$group,levels=c("Pb","lines"))


#Combined:
combined_tidy <- relativised_pool_counts_copies_4FR %>% select(group,population,generation,ratio,Pb_relative_value)
colnames(combined_tidy) <- c("group","population","generation","ratio","mean")

#Combined, lines average:
average_combined_tidy <- data_frame("population"=character(0),"generation"=character(0),"ratio"=character(0),"mean"=character(0)) #next, create the empty dataframe

for (pop in unique(combined_tidy$group)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  for (g in unlist(unique(select(filter(combined_tidy,group==pop),generation)),use.names=F)) {
  #species <- filter(relativised_pool_counts_copies_4FR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
    for (r in unique(combined_tidy$ratio)) {
      print(r)
      pop_mean <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(mean) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_mean))
      #pop_se <- filter(combined_tidy,ratio==r & generation==g & group==pop) %>% select(error) %>% unlist(.,use.names=F) %>% mean()
      #print(paste0(pop," feature ",r," average is ",pop_se))
      row_data <- cbind(pop,g,r,pop_mean)
      colnames(row_data) <- c("population","generation","ratio","mean")
      average_combined_tidy <- rbind(average_combined_tidy,row_data,stringsAsFactors=F)
    }
  }
}
average_combined_tidy$population = factor(average_combined_tidy$population,levels=c("Pb","lines"))
average_combined_tidy$ratio = factor(average_combined_tidy$ratio,levels=c("fourfold","tolerated","deleterious","LoF"))
average_combined_tidy$generation <- as.factor(as.numeric(average_combined_tidy$generation))
average_combined_tidy$mean <- as.numeric(average_combined_tidy$mean)
average_combined_tidy

average_combined_tidy_bis <- average_combined_tidy
average_combined_tidy_bis$generation <- as.numeric(as.character(average_combined_tidy$generation))
average_combined_tidy_bis$ratio <- factor(average_combined_tidy$ratio, levels = c("fourfold", "tolerated", "deleterious", "LoF"), labels = c("fourfold", "m. tolerated", "m. deleterious", "LoF"))

#From here on out, use average_combined_tidy for discrete generations in the plots, and average_combined_tidy_bis for a continuous distribution.

#Replace NaN with 0:
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
average_combined_tidy_bis[is.nan(average_combined_tidy_bis)] <- 0

#Store each dataframe separately for the combined figure:
if (grepl("without",parameters)) {
  average_combined_tidy_purging_without <- average_combined_tidy_bis
  } else {
  average_combined_tidy_purging_with <- average_combined_tidy_bis
  }
}


#Plot the data (all models combined):
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_with <- ggplot(data=filter(average_combined_tidy_purging_with,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) + 
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0,4) +
  scale_y_continuous(breaks = seq(0, 4, by = 0.2), limits=c(0, 4)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("With replacement") + #ggtitle(parameters_list[1]) +
  guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        legend.position="none",
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_with


Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_without <- ggplot(data=filter(average_combined_tidy_purging_without,ratio!="fourfold"), aes(generation,mean)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error, group=population), position=position_dodge(0.4),linewidth=0.5,width=0.2) +
  geom_point(aes(colour=population,shape=population),size=2,position=position_dodge(0.4)) +
  #ggtitle("Proportion of reads at different NM") +
  #ylab("Simulated derived count\n relative to Pb-083 4-fold syn.") +
  ylim(0.6,1.2) +
  scale_y_continuous(breaks = seq(0, 4, by = 0.2), limits=c(0, 4)) +
  scale_shape_manual(values=c(16,18)) +
  #scale_x_continuous(breaks = c(83,103,113,123,223), limits = c(81,225)) +
  #scale_x_discrete(breaks = levels(combined_tidy$generation),limits = c(levels(combined_tidy$generation)[1],"skip",levels(combined_tidy$generation)[c(2:4)],c(rep("skip",3)),levels(combined_tidy$generation)[5])) +
  ggtitle("Without replacement") +
  #guides(colour="none") +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
        rect=element_rect(size=1),
        axis.line=element_line(colour="black"),
        #axis.title=element_text(size=10,colour="black"),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text=element_text(size=8,colour="black"),
        axis.text.x=element_text(colour="black", angle=-90, vjust=0.5),
        axis.text.y=element_blank(),
        #axis.text.y=element_text(size=24,colour="black",margin=margin(t=0.5,unit="cm")),
        #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
        panel.background=element_blank(),
        panel.border=element_rect(colour="black"),
        panel.grid=element_blank(),
        #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
        plot.margin=unit(c(0.5,-0.5,0,-1),"cm"),
        plot.title=element_text(hjust=0.5),
        legend.background=element_rect(linetype="solid", colour="black", size=.5),
        #legend.justification=c(0,0),
        legend.key=element_rect(colour="white"),
        #legend.key.size=unit(1.3,"cm"),
        #legend.position="none",
        legend.box.margin=margin(c(0.95,0.5,0.95,0),unit="cm"),
        legend.title=element_blank()
  )
Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_without


library(grid)
library(gridExtra)
library(egg)

ggplot_combined <- grid.arrange(set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_with,width=unit(3.5,"cm"),height=unit(6,"cm")),set_panel_size(Pb_lines_relativised_pool_counts_copies_errors_4FR_ggplot_without,width=unit(3.5,"cm"),height=unit(6,"cm")),ncol=2,bottom=textGrob(expression(bold("Generations")),gp=gpar(fontsize=10,fontface="bold"),x=0.40,hjust=0),left=textGrob(expression(bold("Derived count relative to Pb-12 and 4-fold syn.")),rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=2))
ggsave(paste0("20240424_simulations_Pb12_rel.",parameters_list,".ratio_of_averages.pdf"), width=27, height=9, units="cm", device="pdf", path="/Users/dani/Documents/dani/Post-docs/2022_contrato_Vigo/drosophila_load/consanguinidad_rapida/simulations/",ggplot_combined)

#Stop
STOP

```